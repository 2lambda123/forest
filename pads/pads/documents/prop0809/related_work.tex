


\subsection{Comparison with Other Research}
\label{ssec:related}

One of the oldest and most widely-used protocols for general monitoring
is SNMP, the simple network management protocol~\cite{snmprfc1157},
which is supported by commercial tools such as HP's
OpenView~\cite{openview} and free tools such as MRTG~\cite{mrtg}. It
provides an open protocol format that can be used to monitor a variety
of different types of equipment, using a vendor-supplied management
information base (MIB) that provides the specifics of the kinds of
monitoring provided by each piece of hardware. SNMP's hierarchical
MIBs plus associated control software, while flexible, have many of
the same drawbacks as XML -- space, complexity, and poor support for
ad hoc data.

For Grid environments, a popular monitoring tool is
Ganglia~\cite{ganglia}, which has also been adapted for use with
PlanetLab. It presents much of the system monitoring information
provided by OS tools like vmstat, iostat, uptime, etc. For data
transmission, Ganglia uses an XDR wire format, with raw data for all
of its native fields.  It can be extended by adding XML-encapsulated
fields for any other node-level measurements. 

What distinguishes this proposal from systems like SNMP or Ganglia is
that we want to be able to automatically parse and monitor virtually
any kind of ad hoc data, from node-level information like that
collected by Ganglia or SNMP, all the way down to application-level
data as well as protocol-level data. These areas are the ones that are
not well-served by today's general-purpose monitoring
systems. Moreover, the ability to use the same data description to
automatically build parsers, in-situ tools, and monitoring systems
represents an ease of use that we believe is not available in other
systems.

Another monitoring system of interest is PsEPR~\cite{psepr} (formerly
known as Trumpet), which focuses on finding problems via several tests
to gauge node health. What makes PsEPR interesting to consider is that
its design is completely decentralized, and all information is pushed
to all participating nodes via a publish/subscribe mechanism in the
Jabber protocol~\cite{jabber}. While this approach can be more
scalable in theory, it currently appears to be hitting the limits of
Jabber messaging servers. In the event that we decide to support
fully distributed monitoring (as opposed to replicated monitoring at
several sites), we will examine the lessons of PsEPR when deciding how
to proceed.


The oldest tools for describing data formats are parser generators such as
Lex and Yacc.  While excellent for parsing programming languages, Lex and Yacc
are too heavyweight for parsing the simpler ad hoc data formats one
runs into in the sciences.   
Unlike PADS, whose syntax is based on types from the well-known C language,
the syntax of Lex and Yacc is somewhat foreign.  Perhaps more importantly,
users must write a lexer, write a
grammar, and construct the in-memory representations by hand.  In
addition, they only work for ASCII data, they do not easily
accommodate data-dependent parsing, and they do not provide auxiliary
services such as an archiver, a query engine or a display tool.
Some more modern parser generators such as ANTLR~\cite{antlr} alleviate
a few of these problems, but they still do not automatically generate auxiliary tools
useful that help systems implementers solve the monitoring problem. 

The closest related work includes domain-specific
languages such as PacketTypes~\cite{sigcomm00} and DataScript~\cite{gpce02} 
for parsing and printing binary data, particularly packets
from common networking protocols such as \textsc{TCP/IP} and also
\java{} jar-files.  Like \pads{}, these languages have a type-directed
approach to describing ad hoc data and permit the user to define
semantic constraints.  In contrast to our work, these systems handle
only binary data and assume the data is error-free or halt parsing if
an error is detected.  Not only are ASCII formats a common part of
many software monitoring systems, parsing non-binary data poses additional
challenges because of the need to handle delimiter values and to
express richer termination conditions on sequences of data. 
PacketTypes and DataScript also focus exclusively on the 
parsing/printing problem,
whereas our research will exploit the declarative nature of our data
descriptions to automatically generate additional useful tools and
programming libraries.  \pads{} substantial 
collection of automatically-generated tools and libraries is 
one of the key incentives that will make it
worth a programmer's while to use \pads to generate monitoring infrastructure.

The Binary Format Description language (BFD)~\cite{bfd} is a fragment of
XML that allows programmers to specify binary and ASCII formats.  BFD
is able to convert the raw data into XML-tagged data where it can then be
processed using XML-processing tools.  While this is useful for many
tasks, conversion to XML can be prohibitively expensive:  such conversion
often results in an 8-10 times blowup in data size over the native form.
\pads{}, on the other hand, avoids this blowup by processing data in its 
native form.

Currently, the Global Grid Forum is working on a standard
data-format description language for describing ad hoc data formats,
called DFDL~\cite{dfdl-proposal,dfdl-primer}.  Like \pads{},
DFDL{} has a rich collection of base types and supports a variety of
ambient codings.  Unlike \pads{}, DFDL{} does not support semantic
constraints on types nor dependent types, \eg{}, it is not possible to
specify that the length of an array is determined by some previously parsed field in the
data.  Our practical experience indicates that many ad hoc formats,
particularly binary formats, absolutely require dependent types in their
specifications.  DFDL{} is an annotated subset of XML{} Schema, which means
that the XML{} view of the ad hoc data is implicit in a DFDL{}
description.  DFDL{} is still being specified, so no DFDL-aware
parsers or data analyzers exist yet.  

% There are parallels between PADS types and some of the elements of parser
% combinator libraries found in languages like
% Haskell~\cite{burge:parser-combinators,hutton+:parser-combinators}. 
% However, as with most other general-purpose parsing tools, one cannot
% simply put together a collection of Haskell's parser combinators and
% automatically generate domain-specific programs such as 
% an XML converter or a histogram generator, for instance.  

A somewhat different class of languages includes
\textsc{ASN.1}~\cite{asn} and \textsc{ASDL}~\cite{asdl}.  Both of
these systems specify the {\em logical\/} in-memory representation of
data and then automatically generate a {\em physical\/} on-disk
representation.  Although useful for many purposes, this technology
does not help process data that arrives in predetermined, ad hoc
formats.  Another language in this category is the Hierarchical Data
Format 5 (HDF5)~\cite{hdf5}.  This file format allows users to store
scientific data, but it does not help users deal with legacy ad hoc
formats like PADS does.

% There are probably hundreds of tools that one might use if their data were
% in \xml.  However, the point of PADS is to allow scientists whose data is {\em not}
% already in \xml to get work done, particularly when that data contains errors,
% as ad hoc data often does.  Since many processes, machines, programs and other devices
% currently output data and a whole most of

XSugar~\cite{brabrand+:xsugar2005} allows user to specify an
alternative non-XML syntax for XML languages using a context-free
grammar.  This tool automatically generates conversion between XML and
non-XML syntax. It also guarantees that conversion will be invertible.
However, it does not use theory of Galois connections, but instead
introduces a notion of ``ignorable'' grammar components (inferred
based on properties of grammar) and proves bijection modulo these
ignorable elements.  Once again, we remark that XML conversion is
too expensive for many applications.

XDTM~\cite{zhao+:sigmod05,xdtm} uses XML Schema to describe the
locations of a collection of sources spread across a local file system
or distributed across a network of computers.  However, XDTM has no
means of specifying the contents of files, so XDTM and PADS solve
complementary problems.  Nevertheless, the XDTM design may provide
ideas to us as we extend PADS from a single-source system to a
multi-source system. The METS schema~\cite{mets} is similar to XDTM as
it describes metadata for objects in a digital library, including a
hierarchy such objects.

Commercial database products provide support for
parsing data in external formats so the data can be imported into
their database systems, but they typically support a limited number of
formats, \eg{}, COBOL copybooks.  Also, no declarative description of the
original format is exposed to the user for their own use, and they
have fixed methods for coping with erroneous data.  For these reasons,
PADS is complementary to database systems.  We strongly believe that
in the future, commercial database systems could and should support a 
PADS-like description language that allows users to import information from
almost any format.  We hope that our research will make a broad
impact in this area.

On the theoretical front, the scientific community's understanding of
type-based languages for data description is much less mature.  To the
best of our knowledge, our work on the DDC is the first to provide a
formal interpretation of dependent types as parsers and to study the
properties of these parsers including error correctness and type
safety.  Regular expressions and context-free grammars, the basis for
Lex and Yacc have been well-studied, but they do not have dependency,
a key feature necessary for expressing constraints and parsing ad hoc
scientific data.  {\em Parsing Expression Grammars} (PEGs), studied in
the early seventies~\cite{birman+:parsing}, revitalized more recently
by Ford~\cite{ford:pegs} and implemented using ``packrat parsing''
techniques~\cite{ford:packrat,grimm:packrat}, are somewhat more
similar to PADS recursive descent parsers. However, PADS does not use
packrat parsing techniques as the space overhead is too high for large
data sets.  Moreover, our multiple interpretations of types
in the DDC makes our theory substantially different from the theory of
PEGs.

%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%

% %\documentclass[11pt]{article}
% %\usepackage{xspace,code,url}
% %\include{rwdefs}

% %\begin{document}

% \section{NSF 05}

% Given the importance of the problem, it is perhaps surprising that
% more tools do not exist to solve it.  \xml{} and relational databases
% only help with data already in well-behaved formats.  Lex and Yacc are
% both over- and under- kill.  Overkill because the division into a
% lexer and a context free grammar is not necessary for many ad hoc data
% sources, and under-kill in that such systems require the user to build
% in-memory representations manually, support only ASCII sources, and
% don't provide extra tools.  ASN.1~\cite{asn} and related
% systems~\cite{asdl} allow the user to specify an in-memory
% representation and generate an on-disk format, but this doesn't help
% when given a particular on-disk format.  Existing ad hoc description
% languages~\cite{gpce02,sigcomm00,erlang} are steps in the right
% direction, but they focus on binary, error-free data and they do not
% provide auxiliary tools.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% There are many tools for describing data formats. For example,
% \textsc{ASN.1}~\cite{asn} and \textsc{ASDL}~\cite{asdl} are both
% systems for declaratively describing data and then generating
% libraries for manipulating that data.  In contrast to \pads{},
% however, both of these systems specify the {\em logical\/} representation
% and automatically generate a {\em physical\/} representation.
% Although useful for many purposes, this technology does not help
% process data that arrives in predetermined, ad hoc formats.

% Lex and yacc-based tools generate parsers from declarative
% descriptions, but they require users to write both a lexer and a
% grammar and to construct the in-memory representations by hand.  In
% addition, they only work for ASCII data, they do not easily
% accommodate data-dependent parsing, and they do not provide auxiliary
% services.

% More closely related work includes \erlang{}'s bit syntax~\cite{erlang} and
% the \packettypes{}~\cite{sigcomm00} and
% DATASCRIPT{} languages~\cite{gpce02}, 
% all of which allow declarative descriptions of physical data.  These projects were motivated by parsing protocols,
% \textsc{TCP/IP} packets, and \java{} jar-files, respectively.  Like
% \pads{}, these languages have a type-directed approach to
% describing ad hoc data and permit the user to define semantic constraints.
% In contrast to our
% work, these systems handle only binary data and assume the data is
% error-free or halt parsing if an error is detected. 
% Parsing non-binary data poses additional challenges because of the need
% to handle delimiter values and to express richer termination conditions
% on sequences of data. These systems also
% focus exclusively on the parsing/printing problem, whereas we have 
% leveraged the declarative nature of
% our data descriptions to build additional useful tools.


% Recently, a standardization effort has been started whose stated goals are quite similar to those of the \pads{} project~\cite{dfdl}. The description
% language seems to be \xml{} based, but at the moment, more details are 
% not available.

% \section{POPL 06}

% To our knowledge, we are the first to attempt to specify a semantics for
% type-based data description languages such as \packettypes{},
% DATASCRIPT{}, or \pads.  
% %Prior to our work, this family of languages 
% %was described informally and by example.  There was no precise
% %connection to formal dependent type theory.

% Of course, there are other formalisms for
% defining parsers, most famously, regular expressions and
% context-free grammars.  In terms of recognition power,
% these formalisms differ from our type theory
% in that they have nondeterministic choice, but do not have
% dependency or constraints.  We have found that 
% dependency and constraints are essential for
% describing the ad hoc data sources we have studied.
% Perhaps more importantly, unlike standard theories of
% context-free grammars,
% we do not treat our type theory merely as a recognizer for
% a collection of strings.  Our type-based descriptions 
% define {\em both} external data formats {\em and} 
% rich invariants on %(\ie{} types for)
% the internal parsed data structures.  This dual interpretation
% of types lies at the heart of tools such as \pads, DATASCRIPT{}, and
% \packettypes{}.  
% %\pads{} programmers, for instance, demand that
% %representations produced by their \pads{} parsers have the expected type and 
% %count on the fact that the associated PD is accurately correlated
% %with the representation.  
% %Existing formalisms simply do not address
% %this elements of data description languages.

% {\em Parsing Expression Grammars} (PEGs),
% studied in the early seventies~\cite{birman+:parsing} and revitalized more 
% recently by Ford~\cite{ford:pegs}, 
% evolved from context-free grammars but
% have deterministic, prioritized choice like DDC{} as opposed to
% nondeterministic choice.  Though PEGs have syntactic lookahead operators,
% they may be parsed in linear time through the use of
% ``packrat parsing'' techniques~\cite{ford:packrat,grimm:packrat}.
% Once again, the dual interpretation of types in DDC{} as both
% data descriptions and classifiers for internal representations
% make our theory substantially different from the theory of PEGs.
% %In practice, PEGs has not been used to parse ad hoc data.

% {\sc antlr}~\cite{antlr}, a popular programming language parsing tool, 
% uses top-down recursive descent
% parsing and appears roughly similar in recognition power to PEGs and DDC.
% {\sc antlr} also allows programmers to place annotations
% in the grammar definitions to guide construction of an abstract syntax
% tree. However, all nodes in the abstract syntax tree have a 
% single type, hence the guidance is coarse when compared with
% the richly-typed structures that can be constructed using
% DDC.


% % Practical experience indicates that
% % tools based on these formalisms, such as the many variations of
% % Lex and Yacc, are highly effective for processing
% % programming language syntax.  However, there is also ample evidence
% % that these tools are a poor fit for processing
% % ad hoc data --- simply put, {\em no one ever uses Lex or Yacc for 
% % these tasks}.
% % Unfortunately, the nondeterminism and lack of
% % dependency in these formalisms limit their suitability to formalizing
% % data description languages. While the parsing expression grammars
% % (PEG) formalism~\cite{ford:parsing-expression-grammars} is
% % significantly closer to the DDC{}, it too lacks the necessary
% % dependency.

% % Less related, but still relevant, are Haskell's parsing
% % combinators. While these are not a formalism, they do provide an
% % elegant manner in which to express parsers. Hence, while we chose to
% % define our parsing semantics in the polymorphic lambda calculus,they
% % potentialy provide a more elegant alternative.

% There are many parallels between DDC{} and {\it parser
% combinators}~\cite{burge:parser-combinators,hutton+:parser-combinators}. 
% In particular, DDC{}'s dependent sum construct is 
% reminiscent of the bind operator in the monadic formulation of parser
% combinators.  Indeed, we can model dependent sums in Haskell as:
% \begin{code}
% \mbox{}
% sigma :: P s -> (s->P t) -> P (s,t)
% sigma m q = do \{x <- m; y <- q x; return (x,y)\}
% \mbox{}
% \end{code}%
% \noindent
% Parser combinators, however, are a general approach to specifying
% recursive descent parsing, whereas we have targeted DDC{}
% to the domain of parsing ad hoc data. This focus leads to 
% many features not found in parser combinators, including the implicit
% type/value correspondence, the error response mechanism, and 
% arrays. Each of these features is as fundamental to DDC{} as 
% dependent sums. These two approaches
% demonstrate the idea of a spectrum of domain-specificity in
% languages. The relationship between parser combinators and DDC{} is
% like the relationship between a general purpose language and parser
% combinators themselves. That is, while parser combinators form an
% (embedded) domain-specific language, DDC{} constructs form a language 
% that is even more domain-specific. 

% \section{PADX PLAN-X}

% The PADX{} system solves important data-management tasks: it supports
% declarative description of ad hoc data formats, its descriptions serve
% as living documentation, and it permits exploration of ad hoc data and
% vetting of erroneous data using a standard query language.  The
% resulting \pads{} descriptions and queries are robust to changes that
% may occur in the data format, making it possible for more than one
% person to profitably use and understand a PADX{} description and
% related queries.

% A PADX{} query corrall is an example of partially compiled query
% engine, because its concrete data model is customized for a particular
% data format, but its queries are interpreted over an abstract data
% model that delegates to the concrete model.  This architecture places
% PADX{} on the continuum between query architectures that provide
% fully interpreted query plans applied to generic data models to
% architectures that provide fully compiled query plans applied to
% customized data model instances~\cite{daytona}.  The latter
% architectures provide very high performance on large scale data.
% PADX{} has some of the benefits of such architectures but does not
% have the overhead of a complete database system. 

% Others share our interest in declarative descriptions of ad hoc data
% formats.  \cut{Transparent, reusable descriptions of ad hoc data formats,
% in particular binary formats, is a hot topic in the Grid
% community~\cite{dfdl}.}  Currently, the Global Grid Forum is working on a standard
% data-format description language for describing ad hoc data formats,
% called DFDL{}~\cite{dfdl-proposal,dfdl-primer}.  Like \pads{},
% DFDL{} has a rich collection of base types and supports a variety of
% ambient codings.  Unlike \pads{}, DFDL{} does not support semantic
% constraints on types nor dependent types, \eg{}, it is not possible to
% specify that the length of an array is determined by some field in the
% data.  DFDL{} is an annotated subset of XML{} Schema, which means
% that the XML{} view of the ad hoc data is implicit in a DFDL{}
% description.  DFDL{} is still being specified, so no DFDL{}-aware
% parsers or data analyzers exist yet.  We expect that bi-directional
% translation between \pads{} and DFDL{} to be straightforward.  Such a
% translation would make it possible for DFDL{} users to use 
% PADX{} to query their ad hoc data sources.

% % Architecture style and strategy
% \cut{The PADX{} architecture is designed to handle with large scale data
% sources without sacrificing the flexibility and generality provided by
% a standard query language. }

% % Related work
% The steps in a data-management workflow that PADX{} addresses
% typically precede the steps that require a high-performance database
% system, \eg{}, asking complex OLAP queries applied to long-lived,
% archived data.  Commercial database products do provide support for
% parsing data in external formats so the data can be imported into
% their database systems, but they typically support a limited number of
% formats, \eg{}, COBOL copybooks, no declarative description of the
% original format is exposed to the user for their own use, and they
% have fixed methods for coping with erroneous data.  For these reasons,
% PADX{} is complementary to database systems.

% \section{ML Workshop}

% As DATATYPE{} supports both data description and transformation, we
% will divide related work between these two functions. It is
% interesting to note that, to the best of our knowledge, there are no
% other languages that synthesize these two functions as DATATYPE{}
% does.

% %\noindent
% \subsection{Data Description}
% %One might wonder why we do not choose to base our descriptions on
% %regular expressions or context-free grammars. First, r
% Regular
% expressions and context-free grammars, while excellent formalisms for
% describing programming language syntax, are not ideal for describing
% the sort of ad hoc data we have discussed in this paper.  The main
% reason for this is that regular expressions and context free grammars
% do not support polymorphism, dependency or semantic constraints ---
% key features for describing many ad hoc data formats.

% ASN.1~\cite{asn} and related systems~\cite{asdl} allow the user to
% specify the {\em logical} in-memory representation and
% automatically generate some 
% {\em physical} on-disk format. 
% Unfortunately, this doesn't help in the slightest when the user is
% given a fixed, physical on-disk format and needs to parse or transform
% that specific format.  DATATYPE{} helps solve
% the latter problem.

% More closely related work includes Erlang{}'s bit
% syntax~\cite{erlang} as well as languages like PacketTypes~\cite{sigcomm00},
% DATASCRIPT~\cite{gpce02}, and ~BLT\cite{eger:blt}. 
% All these systems allow users to write declarative
% descriptions of physical data.  These projects were motivated by
% parsing networking protocols, \textsc{TCP/IP} packets, and \java{} 
% jar-files.  Like DATATYPE, these languages have a type-directed
% approach to describing ad hoc data and permit the user to define
% semantic constraints.  In contrast to our work, these systems 
% do not have recursion or polymorphism, handle
% only binary data and assume the data is error-free.
% In addition, they are designed for imperative or object-oriented host
% languages, while we have focused here on data descriptions appropriate for a
% functional setting.

% %\noindent
% \subsection{Data Transformation}
% There are a number of languages that focus on transforming \xml{}
% data including XDuce~\cite{hosoya+:xduce-journal}, 
% Cduce~\cite{benzaken+:cduce}, and 
% Xtatic~\cite{gapeyev+:XtaticRuntime}, to name just a few.
% The closest work to our own is the XDuce
% language~\cite{hosoya+:xduce-journal} as it considers
% \xml-processing in the context of a
% statically typed, functional language with pattern matching. 
% However, the types needed for describing \xml{} are quite different
% from the types needed to describe ad hoc data.  Moreover,
% these languages simply reject ill-formed \xml.  On the whole,
% we view DATATYPE{} as completely complementary to this work ---
% one can easily imagine a system in which DATATYPE{} is used to translate
% ad hoc data into \xml{} and then one of these other tools takes over.
 
% The Harmony project~\cite{foster+:lenses} is also engaged in 
% data transformation.  This time for the purpose of synchronizing
% disparate views of the same logical data. 
% However, Harmony operates at a higher 
% level of abstraction than DATATYPE.  Once again, the relationship 
% with Harmony appears more cooperative than competitive:  One can 
% imagine using DATATYPE{} as a front end that translates data into 
% a format Harmony can understand whenceforth Harmony uses
% its technology for synchronization.  

% \section{Based on XDTM}

% METS schema:Mets: an overview and
% tutorial. http://www.loc.gov/standards/mets/METSOverview.v2.html, 2003.

% Binary Format Description (BFD):J. Myers and A. Chappell. Binary
% format description (bfd)
% language.http://collaboratory.emsl.pnl.gov/sam/bfd/, 2000.

% Hierarchical Data Format 5, HDF5, ``is a file format (and associated
% software library) for storing large and complex scientific and
% engineering data....
% HDF5 introduces a virtual file layer that allows applications to
% specify particular file storage media such as network, memory, or
% remote file systems or to specify special-purpose I/O mechanisms such
% as parallel I/Os. The virtual file layer bears some similarity with
% our mapping, but focuses on run-time access to data rather than
% physical encoding.''

% \section{New material}

% XSugar~\cite{brabrand+:xsugar2005}: Allows user to specify non-\xml
% syntax for \xml languages with CFG. Automatically generates conversion
% tools between \xml and non-\xml versions. Also guarantees that
% conversion will be invertable. However, does not use theory of Galois
% connections, but instead introduces notion of ``ignorable'' grammar
% components (inferred based on properties of grammar) and proves
% bijection modulo these ignorable elements.

% Dave: key points are 1) they focus on describing languages and hence
% use CFG. In this they are parallel to our work on describing data. 2)
% They focus in ensuring invertibility. In this they are tackling the
% same problem, albeit for perhaps simpler domain (insofar as they
% dealing with well behaved parse trees with clear notion of terminals,
% non terminals, literals,etc.) Read section 3 of paper for more details.
 


% %\end{document}
