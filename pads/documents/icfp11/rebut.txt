Thank you for the helpful reviews.  We understand that because this
paper is primarily a language design paper, it is more difficult to
evaluate than performance-oriented papers or program analysis papers,
for which there are clearer criteria for judging results.  To help
reviewers evaluate our design, we included the following elements:

 1. Simple and compositional high-level syntax that extends our
 prior work on PADS and can be closely integrated with it.  If the
 design seems obvious, that is the result of trying out many
 different designs and choosing the one that fits most seamlessly with
 Pads and Haskell.
 
 2. A full prototype implementation that is available from the 
 Pads website, showing that the design can be implemented.
 
 3. Experience with a number of example programs ranging from the
 smaller ones described in the paper to several more substantial
 ones that solve real-world problems. (Also mention generic tools
 here.) Space constraints prevented us from describing these in
 detail, however they are included in the appendix.    (One of the
 reviewers mentioned difficulty obtaining the appendix.  It should
 be available through the HotCrp system.  We submitted it with the
 paper.  If it is unavailable there or difficult to locate for some
 reason, please ask the program chair or visit
 http://www.cs.princeton.edu/~dpw/papers/forest-draft-0411.pdf which
 contains the original, unmodified submission including the
 appendix) 

 4. A formal semantics for the core of the language and theorems
 that capture correctness conditions on how Forest must treat data
 from the file system.  (KF: I think we should mention some of the
 complexities of the formal system here, to emphacize that that is a
 deep contribution in its own right.)

Reviewer B suggested several ways in which we could reallocate our use
of space to deemphasize or omit some of the above elements that were
deemed less important in order to expand on our discussion of others.
Reviewer A asked for some clarification on certain points.  Given the
usual extra 2 pages that may be purchased to extend an accepted
SIGPLAN paper, there should be room for clarification.

The remainder of this response contains answers to the most important
questions raised by individual reviewers.

--------
Review A
--------

> My first question has to do with whether Forest provides the database
> world's usual ACID guarantees or related properties.

Forest does not provide ACID guarantees.  None of the filestores we
have encountered in practice are implemented in a system that provides
such support; users instead have extra-linguistic mechanisms to make
sure they do not corrupt their data with ill-timed concurrent reads
and writes.  That said, the language design, which is the focus of the
paper, does not preclude an implementation from providing such
guarantees. We consider this issue very interesting future work.
Addressing all of the surrounding issues would likely be a substantial
paper on its own.


> I don't understand how laziness is used to avoid loading unneeded
> parts of the filestore.  Perhaps this uses some standard Haskell
> feature that I'm unaware of, but I'd like to see more discussion,
> probably in the "Implementation" section.

The implementation uses unsafeInterleaveIO to load each file only
when values from it are demanded by the user.  Haskell's usual
lazyness mechanism keeps track of when those values are demanded. 


> What's the complexity of the operation to save changes to a
> filestore?  Is it proportional to the change size or the size of the
> whole filestore?

Load and store functions are generated for every named type in a
description.  Hence, updates may be made at any granularity for which
there is a named type, which is typically down to the individual file
level.  We have discussed a scheme in which only files that have
changed are actually rewritten.  This strategy is straightforward to
implement, but we have not yet done it. For a given file that must be
updated, the complexity is proportional to the entire file, not the
changes.  Given that the files are in user-controlled formats, a more
optimized strategy would be difficult to find. (KSF: is this too much
detail?) 


> The generic tools in Section 5 don't seem to provide any value over
> tools that work directly on conventional, schema-less filesystem
> directory trees. ...  In general, I'd like to understand why someone
> would want to use these schema-generic tools instead of conventional
> UNIX tools.

A Forest "schema" slices out an arbitrary fragment of a file system.
These slices may be constructed in sophisticated ways -- e.g., by
delving into configuration files and using file system metadata.  This
is much more targetted than typical glob patterns used in conventional
command-line UNIX tools.  Thus, even for simple commands such as the
Forest versions of grep, ls, tar, etc., Forest provides advantages
over the conventional UNIX ones.  For example, this facility makes it
easy to tar or grep only the files relevant to a particular semantic
application, rather than all the files that happen to live under a
particular directory.

-- JNF: I think we should also add a few lines pointing out that we
-- have real generic infrastructure as well and tools that do not
-- merely operate on "schema"-less structures such as metadata trees.

> For the other tools, is it worth implementing them with Forest only
> because of some advantage that comes from working with in-memory
> data structures?

It is extremely convenient that Forest generates in-memory data and
meta-data structures in Haskell.  This makes it easy to leverage the
power of Haskell and its many libraries when developing tools.  For
example, Haskell's generic programming infrastructure, particularly
the listify function, allows for very simple implementations of many
tools. In addition, the tool-writer has easy, uniform access to all
the meta-data and validation information associated with the on-disk
structure.  Wihtout Forest, the user has to hand-code access to all
this information.  We also find programming in Haskell more pleasant
and less error prone than coding in shell scripting languages, which
is the current state of the art.

-- JNF: I don't understand this reply. Don't we also want to mention
-- things like validation, overcoming limitations of shell scripts
-- (such as hard limits on #s of arguments) etc. as well?

> Does the use of schema-specialized data structures improve
> efficiency in practice?

The main advantage of generating typed data structures from
descriptions is not performance, it is ease of use and robustness of
programs.  These advantages arise for the usual reasons that
programming with typed data structures is advantageous.

-- JNF: but this is an interesting avenue for future work, especially
-- if one gets serious about building tools for manipulating huge
-- filestores.

> Haskell strings are represented as lists, right?  If so, doesn't
> that mean your in-memory representation of text files uses an order
> of magnitude more memory than necessary (with 64-bit next pointers,
> header words, etc.), and it also doesn't support constant-time
> access to character positions within a string?

The representation of text files depends upon the Pads base type used
to describe the file.  There is an option to represent a text file as
a ByteString, in which case there is not a huge performance cost.  

> A footnote says that the generated types and functions for a
> particular filestore format form a single instance of a type class.
> Have you thought about using a type class where each record type is an
> instance, so that you don't need to declare a *_load and *_manifest
> function for each type, but rather make these operations methods of
> the new type class?

We do what you are describing.  The Forest type class has load and
manifest functions, among others.  The Forest compiler makes each new
Forest data type declaration an instance of this Forest class.  We
also generate type-specific *_load and *_manifest functions, but
programmers do not need to use those versions directly if they do not
want to.

--------
Review B
--------

> Section 3 reads like a reference manual - as a long list of
> features.  I'd like to hear more about why this list of features was
> chosen - were these just useful in practice?  Or is there some kind
> of theoretical argument for why these features are "good"?

As with Pads, the features of the Forest language are based on an
underlying type theory, illustrated in the formal development.  The
syntax of the features is motivated by (1) making it easy to express
common idioms in practice and (2) smoothly integrating with Pads and Haskell.
The list comprehension notation was inspired by Wadler's work on
Monads and comprehensions.  We felt the best way to explain the design
was to give a number of small examples in the text of the paper with
larger ones in the appendix. The examples are organized by type, in an
effort to show the connection with the underlying theory.

The theoretical argument for the "goodness" of the features is that
all of their meanings can be described in a uniform semantic
framework.  The features are also shown to be "good" by virtue of
satisfying important round-tripping (printing/parsing) laws.


> Forest defines a dependent type system, but there's no mention of
> any practical issues (e.g., type equality) that arise from programming
> with it - do these just not show up in practice?  Or are they hidden
> somewhere?  Is there any particular feature that you wish Haskell's
> type system had?

Forest checks that a particular *first-order value* (ie: the file
system) has a given dependent type.  Type equality is typically
required when one checks that a more general *expression* or
*higher-order value* has a particular type.  Hence, Forest does not
need to decide dependent type equality.  If Haskell had full-blown
Forest dependent types and dependent type checking then Haskell
programs that transform file systems (ie: scripts) could be checked
for a lack of any kind of transformation error at compile time.

-- JNF: here, I think we need to spell out when typechecking happens,
   etc. Several reviewers were confused by this but I think we should
   just respond to each in-line rather than raising it up to the top
   level.

> It's unclear exactly how Forest gets translated into Haskell, and if
> this process depends crucially on the kind of approach to generics
> used (TemplateHaskell vs SYB vs..).

Forest uses Haskell's quasi-quoting infrastructure to convert Forest
declarations into Haskell declarations.  This quasi-quoting mechanism
passes to the Forest compiler a string representation of the Forest
code, and expects the compiler to return a TemplateHaskell data
structure describing the Haskell code that should be spliced in at the
location of the Forest code.  This forces us to use TemplateHaskell.
In addition, the Forest compiler needs to generate new data type
declarations; this consideration also forces us to use TemplateHaskell
rather than other generic programming mechanisms because those types
must be generated at compile time.

> Forest uses staged compilation, but descriptions of when each type
> of error (e.g, Forest-type error, filestore constraint violation, ...)
> can occur are scattered throughout the text.  I'd like to see a list
> of the kinds of things that can go wrong and when (and how) those
> errors are dealt with.

The Forest compiler checks the syntax of Forest declarations.  Syntax
errors are reported by the Forest compiler before the quasi-quoter
invokes GHC. If there are no syntax errors, GHC takes the generated
TemplateHaskell declarations and type checks this representation of
Haskell declarations before performing the splice.  So, type errors in
the Forest description are reported at splice time.  (We would like to
do the type checking ourselves.  This requires enriching the
TemplateHaskell API; Simon Peyton Jones has a proposal out do 
exactly this, partly motivated by Forest).  Errors in the filestore
are dynamic; they are noted when the user first touches something that
requires a bit of the filestore that exhibits the problem.  These
errors are recorded in the associated meta-data, allowing the user to
respond to such errors programmatically. 


> It's a little unclear how Forest interacts with Pads.  This is
> probably just an issue with presentation.  For example, the first
> example Forest declaration (on page 3) basically reads "data Student =
> <pads decl>" but at this point in the paper, we don't know what's
> supposed to go on the RHS of the equality, so it's difficult to
> understand what is meant by this.

Basically, whereever Forest allows a type to describe a file, the user
can supply the name of a Pads type describing the contents of that
file.  Forest uses the pads-generated parser to load the contents of
that file.  Forest uses the pads-generated data structure to store the
contents of the file. Due to space constraints, we omitted almost all
discussion of Pads/Haskell in the body of the paper; the appendix has
examples of Pads/Haskell descriptions and illustrates how they are
referenced in Forest descriptions. We will expand this in the final
version.




> I'm hoping extra space can also be used to expand Section 7.  Is
> this formal semantics exactly what would would expect from an informal
> intuition of how filesystems work?  Or is the model itself a large
> contribution?  I can imagine re-using this model in a mechanical
> setting (e.g., in Coq) would be useful in certifying the lower-levels
> of the software stack.

We agree that the formal development in Section 7 is an important
contribution in its own right, specfying a semantics for lenses over
graph-structured data in addition to providing a formal semantics for
Forest.   We plan to expand our discussion of the semantics. 

----------
Reviewer C
----------

> One aspect of the language that I was not clear on is how symbolic
> links work.  Based on the mini-semantics, a symbolic link to a
> directory does not extend the set of valid paths in the file system,
> though a Unix shell, for example, typically treats them that way.  How
> does Forest handle them?

-- KF: the formal model assumes the entire file store, so nothing can
   expand the set of valid paths, right?  

The implementation of Forest treats symbolic links in the same way as
the file system.  If a given file or directory is actually a symbolic
link, Forest will follow the link automaticaly, and treat the target
of the link as the "content" of the link location.  The Forest user
can be completely oblivious that there was a symbolic link involved.
If the Forest user wants to specify aspects of the link itself, such
as where it is pointing, the user can use the SymLink type to specify
such constraints.

----------
Reviewer D
----------

> One claim that I am not entirely convinced is how the type system can
> help to prevent errors. Is the claim that Forest type system is able
> to statically detect some 'impossible' defintions? Or just that it can
> detect non-conformance to the defined format at runtime? Detecting
> non-conformance would not be very interesting, but if Forest does more
> than that an example might help to illustrate the point. Also, the
> authors claim that Forest has a "dependent type system". I am not sure
> how this can be true unless the declared interface somehow changes
> when the physical file system is explored.
 
> For example, can I say:
> type d = Directory
>  ( sub_a is "*" :: Sub_A
>  , sub_b is "*" :: Sub_B )
> and have Forest decide which sub-directory matches Sub_A and which
> matches Sub_B? 

> What is the performance overhead of Forest? I suspect it would be
> quite minimal since the matching does not do any intense computation,
> but it would be great if the authors can state it explicitly.

[We can say that we've used our (pretty much wholly unoptimized)
implementation on filestores of a few GB?]
