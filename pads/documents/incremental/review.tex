\section{\pads{} and the Original \learnpads{}} 
\label{sec:review}

\begin{figure*}[th]
{\small 
\begin{verbatim}
207.136.97.49  - - [05/May/2009:16:37:20 -0400] "GET /README.txt HTTP/1.1" 404 216
ks38.kms.com - kim [10/May/2009:18:38:35 -0400] "GET /doc/prev.gif HTTP/1.1" 304 576 
\end{verbatim}                  
}
\vskip -2ex
\caption{A fragment from a web server log in \ai{} format}
\label{fig:ai}
\end{figure*}

We use a simple web server log format, which we call
\ai{}, to illustrate the principal features of the \pads{} data
description language.  \figref{fig:ai} shows a fragment of such data, which
is comprised of a sequence of records, separated by newlines.
Each record contains a number of fields delimited by white space. For example,
the first record starts with an IP address, then has two dashes, a time stamp enclosed in
square brackets, a quoted HTTP message, and finally two
integers.  The second record shows some variation:
the IP address becomes a hostname and the second dash becomes an identifier.


\begin{figure}[t]
{\small 
\begin{code}
\kw{Punion} client_t \{
  Pip       ip;      // 207.136.97.49
  Phostname host;    // ks38.kms.com
\};
\kw{Punion} auth_id_t \{
  Pchar unauthorized : unauthorized == '-'; 
  Pstring(:' ':) id;                        
\};
\kw{Pstruct} request_t \{
   "GET ";    Ppath    path;
   " HTTP/";  Pfloat   http_ver; 
   '"';
\};
\kw{Precord} \kw{Pstruct} entry_t \{
         client_t       client;          
   ' ';  auth_id_t      remoteID;        
   ' ';  auth_id_t      auth;            
   " ["; Pdate          date;   
   ':';  Ptime          time;     
   "] "; request_t      request;         
   ' ';  Pint           response;     
   ' ';  Pint           length; 
\};
\end{code}
\vskip -2ex
}
\caption{\padsc{} description for the \ai{} format}
\label{fig:ai.p}
\end{figure}
\pads{} uses a type-based metaphor to
describe ad hoc data.  Each \pads{} type plays a dual role: it
specifies a grammar by which to parse the data and a data-specific
data structure in which to store the results of the parse. 
\padsc{} is the variant of \pads{} that uses \C{} as its host
language.  Hence, \padsc{} types are drawn by analogy from \C{}, and
the generated data structures and parsing code are in \C{}.

\figref{fig:ai.p} shows a \padsc{} specification that describes each
of the records in \figref{fig:ai}.  The specification consists of a
series of declarations. Types must be declared before they are used,
so the last declaration \cd{entry\_t} describes the entirety of a
record, while the earlier declarations describe data fragments.  Type
\cd{entry\_t} is a \kw{Precord}, meaning it comprises a full line in
the input, and is a \kw{Pstruct}, meaning it consists of a sequence of
named fields, each with its own type.  For convenience, \cd{Pstruct}s
can also contain anonymous literal fields, such as \cd{" ["}, which
denote constants in the input source.  The generated representation
for \cd{entry\_t} will be a \C{} struct with one field for each of the
named fields in the declaration.
The type \cd{client\_t} is a \kw{Punion}, meaning the described data
matches \textit{one} of its branches, by analogy with \C{} unions. In
particular, a \cd{client\_t} is either an IP address (\cd{Pip}) or a
host name (\cd{Phostname}), where \cd{Pip} and \cd{Phostname} are
\padsc{} \textit{base types} describing IP addresses and hostnames,
respectively.  

In general, base types describe atomic pieces of data such as integers
(\cd{Pint}) and floats (\cd{Pfloat}), characters (\cd{Pchar}) and
strings (\cd{Pstring(:' ':)}), dates (\cd{Pdate}) and times
(\cd{Ptime}), paths (\cd{Ppath}), \etc{} Strings represent an
interesting case because in theory they could go on forever, so
\cd{Pstring} takes a parameter which specifies when the string stops:
in this case, when it reaches a space.  To account for more general
stopping conditions, the base type \cd{Pstring_ME} takes as a
parameter a regular expression.  With this type, the corresponding
string is the longest that matches the regular expression.
The first branch of the \kw{Punion} \cd{auth\_id\_t} illustrates the
use of a \textit{constraint}.  It specifies that the \cd{unauthorized}
character must be equal to \cd{'-'}.  If the constraint fails to hold,
the next branch of the union will be considered.  

In addition to the features illustrated in \figref{fig:ai.p}, \pads{}
provides arrays, which describe sequences of data all of the same
type; options, which describe data that may be present; and
switched unions, which describe unions where a value earlier in the
data determines which branch to take.  Such unions illustrate that
\pads{} supports \textit{dependencies}: earlier portions of the data
can determine how to parse later portions.

The goal of the \learnpads{} format inference engine is to infer a
\pads{} description like the one in \figref{fig:ai.p} from raw data.
From such a description, the \pads{} compiler can produce end-to-end
processing tools fully automatically.  A full description of the
\learnpads{} algorithm appears in an earlier
paper~\cite{Fisher+:dirttoshovels}.  We give only a brief summary
here.  

\learnpads{} assumes that the input data is a sequence of
newline-terminated records and that each record is an instance of the
desired description.  From such an input, it uses a a three-phase
algorithm to produce a description.  In the {\em tokenization} phase,
\learnpads{} converts each input line into a sequences of tokens,
where each token type is defined by a regular expression.
Intuitively, these tokens correspond to \pads{} base types.
%
\cut{
The sequences of
tokens (shown in brackets) converted from the two example lines 
in Figure \ref{fig:ai} are:

{\small
\begin{verbatim}
[ip] [ ] [-] [ ] [-] [ ] [[] [date] [:] 
   [time] []] [ ] ["] [str] [ ] [path] [ ] 
   [str] [/] [float] ["] [ ] [int] [ ] [int]

[host] [ ] [-] [ ] [str] [ ] [[] [date] [:] 
   [time] []] [ ] ["] [str] [ ] [path] [ ] 
   [str] [/] [float] ["] [ ] [int] [ ] [int]
\end{verbatim}
}
}%end cut
%
In the {\em structure discovery} phase, \learnpads{} computes a
frequency distribution for each token type and then uses that
information to determine if the top-level structure of the data source
is a base type, \kw{Pstruct}, \kw{Parray}, or \kw{Punion}.  Based on
that determination, the algorithm partitions the data into new
contexts and recursively analyzes each of those contexts, constructing
the corresponding description as it recurses.  This phase terminates
with a candidate description.  In the {\em format refinement} phase,
the algorithm uses an information-theoretic scoring function to guide the
application of rewriting rules.
These rules seek to minimize the size of the description while
improving its precision by performing structural transformations (such
as merging adjacent \kw{Pstruct}s),  adding data dependencies, and
constraining the range of various base types, \eg{}, converting a
general integer to a 32-bit integer.  

The scoring function, which is based on the \textit{minimum
  description length principle}~\cite{mdlbook}, 
measures how well a description describes data by calculating
the number of bits necessary to transmit both the description and the
data \textit{given the description}.  We use the terms \textit{type}
  and \textit{data complexity} to refer to the number of bits necessary to
encode the description and to encode the data given the description,
respectively.  This function penalizes overly
general descriptions, such as \kw{Pstring}, which have an extremely
low type complexity but a very high data complexity.  It also
penalizes overly specific descriptions that painstakingly describe
each character in the data.  Such descriptions have a low data
complexity, but a high type complexity.


This inference algorithm produces good results for the set of small
log files that we have experimented with, but it has two limitations:
performance and adaptabity.  In terms of performance, the algorithm
requires space quadratic in the input file size to perform the data
dependency analysis, so it cannot be used on log files larger than the
square of the size of usable memory.  In terms of adaptability, the
algorithm only considers its input data in constructing a description.
Hence if tomorrow's log file has a new kind of record, the algorithm
has no way to modify an existing description, but instead must start
from scratch.


%
% - PADS description
%
% - How LearnPADS works
%
% - LearnPADS Limitations: 
%	1) main-memory algo can't handle very large data sources
%        2) formats learned from a subset of data may not be correct (ai.3000 with a POST)
%	3) can't handle continuous data
%	4) formats learned can be un-intuitive (needs some human guidance)
%
% - hence we developed the incremental learning algorithm
