\section{Evaluation}
\label{sec:eval}
The following experiments were done on a PowerBook G4 with a 1.67GHz PowerPC
CPU and 2G memory running on Mac OS X 10.4. 
Table \ref{tab:results} compares the performance results between
the original \learnpads{} system and the incremental system. 
The benchmarks used are 12 system logs with various sizes. Column 2
shows the number of lines in each log. The time columns record the total
running time in seconds, and the TC columns record the type complexity
of the final description learned. In general, lower type complexity means
more compact description. For all benchmarks, the initial learn size $N$ is 500 lines 
and the incremental learn size $M$ is 100 lines. 
The slight twist is that the initial learn chunk is not the first $N$ records in the
data, but a mix of the $N/3$ consecutive records taken from the beginning, middle,
and end of the data source. 
Where it takes more than half an hour for the original \learnpads{}
system to learn a description, a ``-'' is put in those cells to 
indicate there is no result.

\begin{table*}[th]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}\hline
& & & \multicolumn{2}{|c|}{original} & \multicolumn{2}{|c|}{incremental} \\ \cline{4-7}
\raisebox{1.5ex}[0pt]{Formats} & \raisebox{1.5ex}[0pt]{Lines} & \raisebox{1.5ex}[0pt]{KB} & 
	Time & CT & Time & CT \\ \hline \hline
interface & 1253&185		& 48.5	& 741.4	& 2.9	& 1184.6 \\ \hline
asl.log  &	1500&552	& 31.9	& 960.1	& 13.5 	& 1585.7 \\ \hline
apache.txt  &	2087&442	& 66.4 & 1746.1 & 7.9 	& 2277.6 \\ \hline
ai.3000	&	3000&286	& 26	& 412.6	& 2.2	& 440.6	\\ \hline
error\_log  &	4510&409	& 93.1	& 101.9	& 0.9	& 107.9 \\ \hline
access\_log  &	8188&551 	& 130.5	& 351.2	& 2.8	& 321.2	\\ \hline
coblitz	     & 9421&2561   & -	& -	& 31.9 & 3005.2 \\ \hline
pws	&	 17365&3432	& -	& - 	& 133  & 5869 \\ \hline
ai.big	&	57368&5608	& -	& -	& 26.2	& 543 \\ \hline
exlog & 260796&76720 	& -	& -	& 610 & 3088.3 \\ \hline
redirect & 302554&102404 & -	& -	& 1852 & 17567.7 \\ \hline
getbig & 550409&92192   & -	& -	& 668 & 9008.1 \\ \hline
\end{tabular}
\caption{Execution times (secs) and type complexity (bits)} 
\label{tab:results}
\end{center}
\end{table*}


% - parse metric
% - initial learn size and chunk size - these can affect results
% - update chunk by chunk 
% - optimizations/heuristics
%   due to performance concerns:
%   - memoization
%   - the clean function (to reduce the number of parses)
%   - control of aggregate size
%   - parses cut-off: kill a parse if it has more than n consecutive failures in a struct
%   due to quality of description concerns (and also performance)
%   - deterministic unions
%   - longest match in arrays
%   - merge adjacent const strings (only punctuation and white spaces)
%   - error recovery
%
%- Experiments
%	1) comparison with old LearnPADS on several large datasets (ai.3000, asl.log, apache.txt, access\_log, error\_log, interface.loop)
%	   compare exec time and type complexity. For increment, use
%	   initial learn chunk of 100 and incremental error chunks of 100
%	2) use ai format, do a table with 1000 5000 10000,...,1M miles
%	   using orig learning system and the new system with various optimization turned on and off.
%

