Although PADS descriptions can make managing ad hoc data much easier,
there remains the problem of writing the description in the first
place.  Writing such descriptions can be tedious and time consuming.
It often requires iteratively writing a description of as much of the
data as the analyst understands, and then generating and running
analysis tools to find the unknown parts of the data.  After
understanding those parts, the analyst refines the description and
repeats, until all the data either conforms to the description or 
constitutes an actual error.  While the web server log may seem simple
enough to write a description or even a parser by hand, the system log
is much more complex because it has much more variation.  Having a
tool to help produce such a description would be enormously helpful.

Several observations suggest that we might be able to infer
descriptions automatically.   
First, ad hoc data for which we want to infer descriptions is
voluminous and tends to be structured as a sequence of records.
Consequently, we can view each record as an independent instance of
the desired description.  We can then leverage the similarities across
records to derive the structure of the description.  The large
volume minimizes the influence of errors in the data, which
we assume to be relatively rare.

Second, ad hoc data tends to contain distinctive atomic data such as
dates, IP addresses, file system path names, urls, email addresses,
MAC addresses, etc.  We can leverage the distinctiveness of these data
formats to identify them with high confidence. If a given portion of
each record parses correctly as an IP address, we can assume with high
confidence that that portion of the data is actually an IP address.

Third, ad hoc data formats typically contain *punctuation*, tokens in
the data that serve to delimit the *payload*.  For example, in web
server logs, white space divides the data into columns.  Furthermore,
brackets delimit the date field while quotation marks frame the
request.  In the system log example, white space and colons delimit
fields while various key words serve to demark information of interest
to particular applications.  Given a large enough data source, the
frequency of punctuation dominates the frequency of payload.  Hence we
can automatically discover the punctuation. 

Viewing identified base types and punctuation as tokens, we 
can find token clusters that occur with the same frequency in all
records.  In the simplest case, we identify tokens that appear in
every record.  In the web server log example, such a cluster would
include the brackets with their contained date, the white space, the
quotations, and the url embedded in the request.  
We merge tokens that appear immediately next to each other in every record. 
From this set of top level tokens, we can create a PADS Pstruct
specification.  The punctuation tokens become literals in the Pstruct,
while each distinctive base type becomes a simple field with the
associated type.  Each pair of adjacent tokens defines a *context* for
further exploration if other data appears between those tokens.  

Given such a context, we calculate token clusters for
just the data occurring in that context.  This technique allows us to
disentangle delimiters that appear in different roles in the data
source. If a given cluster appears zero or more times in a given
context, then we introduce an Parray into the inferred description.
If there is no single cluster that appears in all records in the
relevant context, we take each cluster that appears with a significant
frequency and introduce a Punion into the description.  If there are
no high-frequency clusters, we assume that the context must correspond
to a base type, at which point we look for the most descriptive base
type for the observed data.  In either the Parray or the Punion case,
the choice of the constructor introduces new contexts that can be
recursively analyzed until we are left with only base types.

Arasu and Garcia-Molena used similar techniques to recover data from
web pages generated from a template and data from a database 
\cite{Arasu-GarciaMolena}. Although their domain is considerable
simpler because of the verbosity of XML tags and the lack of errors in
their data, the success of their approach suggests that our
proposed techniques will succeed. 





