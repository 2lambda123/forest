\documentclass[11pt]{article}
\usepackage{xspace,code,url}
\include{rwdefs}

\begin{document}

\section{NSF 05}

Given the importance of the problem, it is perhaps surprising that
more tools do not exist to solve it.  \xml{} and relational databases
only help with data already in well-behaved formats.  Lex and Yacc are
both over- and under- kill.  Overkill because the division into a
lexer and a context free grammar is not necessary for many ad hoc data
sources, and under-kill in that such systems require the user to build
in-memory representations manually, support only ASCII sources, and
don't provide extra tools.  ASN.1~\cite{asn} and related
systems~\cite{asdl} allow the user to specify an in-memory
representation and generate an on-disk format, but this doesn't help
when given a particular on-disk format.  Existing ad hoc description
languages~\cite{gpce02,sigcomm00,erlang} are steps in the right
direction, but they focus on binary, error-free data and they do not
provide auxiliary tools.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

There are many tools for describing data formats. For example,
\textsc{ASN.1}~\cite{asn} and \textsc{ASDL}~\cite{asdl} are both
systems for declaratively describing data and then generating
libraries for manipulating that data.  In contrast to \pads{},
however, both of these systems specify the {\em logical\/} representation
and automatically generate a {\em physical\/} representation.
Although useful for many purposes, this technology does not help
process data that arrives in predetermined, ad hoc formats.

Lex and yacc-based tools generate parsers from declarative
descriptions, but they require users to write both a lexer and a
grammar and to construct the in-memory representations by hand.  In
addition, they only work for ASCII data, they do not easily
accommodate data-dependent parsing, and they do not provide auxiliary
services.

More closely related work includes \erlang{}'s bit syntax~\cite{erlang} and
the \packettypes{}~\cite{sigcomm00} and
\datascript{} languages~\cite{gpce02}, 
all of which allow declarative descriptions of physical data.  These projects were motivated by parsing protocols,
\textsc{TCP/IP} packets, and \java{} jar-files, respectively.  Like
\pads{}, these languages have a type-directed approach to
describing ad hoc data and permit the user to define semantic constraints.
In contrast to our
work, these systems handle only binary data and assume the data is
error-free or halt parsing if an error is detected. 
Parsing non-binary data poses additional challenges because of the need
to handle delimiter values and to express richer termination conditions
on sequences of data. These systems also
focus exclusively on the parsing/printing problem, whereas we have 
leveraged the declarative nature of
our data descriptions to build additional useful tools.


Recently, a standardization effort has been started whose stated goals are quite similar to those of the \pads{} project~\cite{dfdl}. The description
language seems to be \xml{} based, but at the moment, more details are 
not available.

\section{POPL 06}

To our knowledge, we are the first to attempt to specify a semantics for
type-based data description languages such as \packettypes{},
\datascript{}, or \pads.  
%Prior to our work, this family of languages 
%was described informally and by example.  There was no precise
%connection to formal dependent type theory.

Of course, there are other formalisms for
defining parsers, most famously, regular expressions and
context-free grammars.  In terms of recognition power,
these formalisms differ from our type theory
in that they have nondeterministic choice, but do not have
dependency or constraints.  We have found that 
dependency and constraints are essential for
describing the ad hoc data sources we have studied.
Perhaps more importantly, unlike standard theories of
context-free grammars,
we do not treat our type theory merely as a recognizer for
a collection of strings.  Our type-based descriptions 
define {\em both} external data formats {\em and} 
rich invariants on %(\ie{} types for)
the internal parsed data structures.  This dual interpretation
of types lies at the heart of tools such as \pads, \datascript{}, and
\packettypes{}.  
%\pads{} programmers, for instance, demand that
%representations produced by their \pads{} parsers have the expected type and 
%count on the fact that the associated PD is accurately correlated
%with the representation.  
%Existing formalisms simply do not address
%this elements of data description languages.

{\em Parsing Expression Grammars} (PEGs),
studied in the early seventies~\cite{birman+:parsing} and revitalized more 
recently by Ford~\cite{ford:pegs}, 
evolved from context-free grammars but
have deterministic, prioritized choice like \ddc{} as opposed to
nondeterministic choice.  Though PEGs have syntactic lookahead operators,
they may be parsed in linear time through the use of
``packrat parsing'' techniques~\cite{ford:packrat,grimm:packrat}.
Once again, the dual interpretation of types in \ddc{} as both
data descriptions and classifiers for internal representations
make our theory substantially different from the theory of PEGs.
%In practice, PEGs has not been used to parse ad hoc data.

{\sc antlr}~\cite{antlr}, a popular programming language parsing tool, 
uses top-down recursive descent
parsing and appears roughly similar in recognition power to PEGs and \ddc.
{\sc antlr} also allows programmers to place annotations
in the grammar definitions to guide construction of an abstract syntax
tree. However, all nodes in the abstract syntax tree have a 
single type, hence the guidance is coarse when compared with
the richly-typed structures that can be constructed using
\ddc.


% Practical experience indicates that
% tools based on these formalisms, such as the many variations of
% Lex and Yacc, are highly effective for processing
% programming language syntax.  However, there is also ample evidence
% that these tools are a poor fit for processing
% ad hoc data --- simply put, {\em no one ever uses Lex or Yacc for 
% these tasks}.
% Unfortunately, the nondeterminism and lack of
% dependency in these formalisms limit their suitability to formalizing
% data description languages. While the parsing expression grammars
% (PEG) formalism~\cite{ford:parsing-expression-grammars} is
% significantly closer to the \ddc{}, it too lacks the necessary
% dependency.

% Less related, but still relevant, are Haskell's parsing
% combinators. While these are not a formalism, they do provide an
% elegant manner in which to express parsers. Hence, while we chose to
% define our parsing semantics in the polymorphic lambda calculus,they
% potentialy provide a more elegant alternative.

There are many parallels between \ddc{} and {\it parser
combinators}~\cite{burge:parser-combinators,hutton+:parser-combinators}. 
In particular, \ddc{}'s dependent sum construct is 
reminiscent of the bind operator in the monadic formulation of parser
combinators.  Indeed, we can model dependent sums in Haskell as:
\begin{code}
\mbox{}
sigma :: P s -> (s->P t) -> P (s,t)
sigma m q = do \{x <- m; y <- q x; return (x,y)\}
\mbox{}
\end{code}%
\noindent
Parser combinators, however, are a general approach to specifying
recursive descent parsing, whereas we have targeted \ddc{}
to the domain of parsing ad hoc data. This focus leads to 
many features not found in parser combinators, including the implicit
type/value correspondence, the error response mechanism, and 
arrays. Each of these features is as fundamental to \ddc{} as 
dependent sums. These two approaches
demonstrate the idea of a spectrum of domain-specificity in
languages. The relationship between parser combinators and \ddc{} is
like the relationship between a general purpose language and parser
combinators themselves. That is, while parser combinators form an
(embedded) domain-specific language, \ddc{} constructs form a language 
that is even more domain-specific. 

\section{PADX PLAN-X}

The \padx{} system solves important data-management tasks: it supports
declarative description of ad hoc data formats, its descriptions serve
as living documentation, and it permits exploration of ad hoc data and
vetting of erroneous data using a standard query language.  The
resulting \pads{} descriptions and queries are robust to changes that
may occur in the data format, making it possible for more than one
person to profitably use and understand a \padx{} description and
related queries.

A \padx{} query corrall is an example of partially compiled query
engine, because its concrete data model is customized for a particular
data format, but its queries are interpreted over an abstract data
model that delegates to the concrete model.  This architecture places
\padx{} on the continuum between query architectures that provide
fully interpreted query plans applied to generic data models to
architectures that provide fully compiled query plans applied to
customized data model instances~\cite{daytona}.  The latter
architectures provide very high performance on large scale data.
\padx{} has some of the benefits of such architectures but does not
have the overhead of a complete database system. 

Others share our interest in declarative descriptions of ad hoc data
formats.  \cut{Transparent, reusable descriptions of ad hoc data formats,
in particular binary formats, is a hot topic in the Grid
community~\cite{dfdl}.}  Currently, the Global Grid Forum is working on a standard
data-format description language for describing ad hoc data formats,
called \dfdl{}~\cite{dfdl-proposal,dfdl-primer}.  Like \pads{},
\dfdl{} has a rich collection of base types and supports a variety of
ambient codings.  Unlike \pads{}, \dfdl{} does not support semantic
constraints on types nor dependent types, \eg{}, it is not possible to
specify that the length of an array is determined by some field in the
data.  \dfdl{} is an annotated subset of \Xml{} Schema, which means
that the \Xml{} view of the ad hoc data is implicit in a \dfdl{}
description.  \dfdl{} is still being specified, so no \dfdl{}-aware
parsers or data analyzers exist yet.  We expect that bi-directional
translation between \pads{} and \dfdl{} to be straightforward.  Such a
translation would make it possible for \dfdl{} users to use 
\padx{} to query their ad hoc data sources.

% Architecture style and strategy
\cut{The \padx{} architecture is designed to handle with large scale data
sources without sacrificing the flexibility and generality provided by
a standard query language. }

% Related work
The steps in a data-management workflow that \padx{} addresses
typically precede the steps that require a high-performance database
system, \eg{}, asking complex OLAP queries applied to long-lived,
archived data.  Commercial database products do provide support for
parsing data in external formats so the data can be imported into
their database systems, but they typically support a limited number of
formats, \eg{}, COBOL copybooks, no declarative description of the
original format is exposed to the user for their own use, and they
have fixed methods for coping with erroneous data.  For these reasons,
\padx{} is complementary to database systems.

\section{ML Workshop}

As \datatype{} supports both data description and transformation, we
will divide related work between these two functions. It is
interesting to note that, to the best of our knowledge, there are no
other languages that synthesize these two functions as \datatype{}
does.

%\noindent
\subsection{Data Description}
%One might wonder why we do not choose to base our descriptions on
%regular expressions or context-free grammars. First, r
Regular
expressions and context-free grammars, while excellent formalisms for
describing programming language syntax, are not ideal for describing
the sort of ad hoc data we have discussed in this paper.  The main
reason for this is that regular expressions and context free grammars
do not support polymorphism, dependency or semantic constraints ---
key features for describing many ad hoc data formats.

ASN.1~\cite{asn} and related systems~\cite{asdl} allow the user to
specify the {\em logical} in-memory representation and
automatically generate some 
{\em physical} on-disk format. 
Unfortunately, this doesn't help in the slightest when the user is
given a fixed, physical on-disk format and needs to parse or transform
that specific format.  \datatype{} helps solve
the latter problem.

More closely related work includes \erlang{}'s bit
syntax~\cite{erlang} as well as languages like \packettypes~\cite{sigcomm00},
\datascript~\cite{gpce02}, and \blt~\cite{eger:blt}. 
All these systems allow users to write declarative
descriptions of physical data.  These projects were motivated by
parsing networking protocols, \textsc{TCP/IP} packets, and \java{} 
jar-files.  Like \datatype, these languages have a type-directed
approach to describing ad hoc data and permit the user to define
semantic constraints.  In contrast to our work, these systems 
do not have recursion or polymorphism, handle
only binary data and assume the data is error-free.
In addition, they are designed for imperative or object-oriented host
languages, while we have focused here on data descriptions appropriate for a
functional setting.

%\noindent
\subsection{Data Transformation}
There are a number of languages that focus on transforming \xml{}
data including XDuce~\cite{hosoya+:xduce-journal}, 
Cduce~\cite{benzaken+:cduce}, and 
Xtatic~\cite{gapeyev+:XtaticRuntime}, to name just a few.
The closest work to our own is the XDuce
language~\cite{hosoya+:xduce-journal} as it considers
\xml-processing in the context of a
statically typed, functional language with pattern matching. 
However, the types needed for describing \xml{} are quite different
from the types needed to describe ad hoc data.  Moreover,
these languages simply reject ill-formed \xml.  On the whole,
we view \datatype{} as completely complementary to this work ---
one can easily imagine a system in which \datatype{} is used to translate
ad hoc data into \xml{} and then one of these other tools takes over.
 
The Harmony project~\cite{foster+:lenses} is also engaged in 
data transformation.  This time for the purpose of synchronizing
disparate views of the same logical data. 
However, Harmony operates at a higher 
level of abstraction than \datatype.  Once again, the relationship 
with Harmony appears more cooperative than competitive:  One can 
imagine using \datatype{} as a front end that translates data into 
a format Harmony can understand whenceforth Harmony uses
its technology for synchronization.  

\section{Based on XDTM}

METS schema:Mets: an overview and
tutorial. http://www.loc.gov/standards/mets/METSOverview.v2.html, 2003.

Binary Format Description (BFD):J. Myers and A. Chappell. Binary
format description (bfd)
language.http://collaboratory.emsl.pnl.gov/sam/bfd/, 2000.

Hierarchical Data Format 5, HDF5, ``is a file format (and associated
software library) for storing large and complex scientific and
engineering data....
HDF5 introduces a virtual file layer that allows applications to
specify particular file storage media such as network, memory, or
remote file systems or to specify special-purpose I/O mechanisms such
as parallel I/Os. The virtual file layer bears some similarity with
our mapping, but focuses on run-time access to data rather than
physical encoding.''

\section{New material}

XSugar~\cite{brabrand+:xsugar2005}: Allows user to specify non-\xml
syntax for \xml languages with CFG. Automatically generates conversion
tools between \xml and non-\xml versions. Also guarantees that
conversion will be invertable. However, does not use theory of Galois
connections, but instead introduces notion of ``ignorable'' grammar
components (inferred based on properties of grammar) and proves
bijection modulo these ignorable elements.

Dave: key points are 1) they focus on describing languages and hence
use CFG. In this they are parallel to our work on describing data. 2)
They focus in ensuring invertibility. In this they are tackling the
same problem, albeit for perhaps simpler domain (insofar as they
dealing with well behaved parse trees with clear notion of terminals,
non terminals, literals,etc.) Read section 3 of paper for more details.
 


{\bibliographystyle{abbrv}
\bibliography{pads-long,pads,../galax}
}
\end{document}
