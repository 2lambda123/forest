\section{From \padsmlbig{} to \ocamlbig{}}
\label{sec:padsml-impl}
The \padsml{} compiler takes descriptions and generates \ocaml{}
modules that can be used by any \ocaml{} program.  In this section, we
describe the generated modules and illustrate their use.

\subsection{Types as Modules}
\label{sec:gen-code}

We use the \ocaml{} module system to structure the libraries generated
by the \padsml{} compiler.  Each \padsml{} base type is implemented as
an \ocaml{} module.  For each \padsml{} type in a description, the
\padsml{} compiler generates an \ocaml{} module containing the types,
functions, and nested modules that implement the \padsml{} type.  All
the generated modules are grouped into one module that implements the
complete description.  For example, a \padsml{} description named
\texttt{sirius.pml}, which contains three named types, will result in the
\ocaml{} file \texttt{sirius.ml} defining the module \cd{Sirius},
which will contain three submodules, each corresponding to one named type.

Namespace management alone is sufficient motivation to employ a
``types as modules'' approach, but the power of the \ml{} module
system provides substantially more.  We implement polymorphic
\padsml{} types as functors from (type) modules to (type) modules.
Ideally, we would like to map recursive \padsml{} types into recursive
modules.  Unfortunately, this approach currently is not possible, because
\ocaml{} prohibits the use of functors within recursive modules,
and the output of the \padsml{} compiler includes a functor for each
type.  Instead, we implement recursive types as modules containing
recursive datatypes and functions.  As there is no theoretical reason
to prevent recursive modules from containing functors~\cite{dreyer-thesis}, we
pose our system as a challenge to implementers of module systems.

The module generated for any monomorphic \padsml{} type 
matches the signature \cd{S}:
\begin{code}\scriptsize
\kw{module} \kw{type} S = \kw{sig}
  \kw{type} rep
  \kw{type} pd\_body
  \kw{type} pd = Pads.pd_header * pd_body
  \kw{val}  parse : Pads.handle -> rep * pd
  \kw{val}  print : rep -> pd -> Pads.handle -> unit
  (* Functor for tool generator ... *)
  \kw{module} Traverse ...
\kw{end}\end{code}% 
\noindent 
The \emph{representation} (rep) type describes the
in-memory representation of parsed data, while the
\emph{parse-descriptor} (PD) type describes meta-data collected
during parsing.
The parsing function converts the raw data into an in-memory
representation and parse descriptor for the representation.
The printing function performs the reverse operation.
The module also contains a generic tool generator implemented as a functor; we defer a description of this functor to \secref{sec:gen-tool}.
The module \cd{Pads} contains the
built-in types and functions that occur in base-type and generated
modules.  The type \cd{Pads.pd_header} is the type of all parse-descriptor
headers and \cd{Pads.handle} is an abstract type containing the
private data structures \padsml{} uses to manage data sources.

The structure of the representation and parse-descriptor types
resembles the structure of the corresponding \padsml{} type, making it
easy to see the correspondence between parsed data, its internal
representation, and the corresponding meta-data.  
For example, given the \padsml{} type \cd{Pair} describing a character
and integer separated by a vertical bar:
\begin{code}\scriptsize
  \kw{ptype} Pair = Pchar * '|' * Pint\end{code}%
the compiler generates a module with the signature:
\begin{code}\scriptsize
\kw{module} \kw{type} Pair_sig = \kw{sig}
  \kw{type} rep     = Pchar.rep * Pint.rep
  \kw{type} pd_body = Pchar.pd  * Pint.pd
  \kw{type} pd      = Pads.pd_header * pd_body
  \kw{val}  parse   : Pads.handle -> rep * pd
  \kw{val}  print   : rep -> pd -> Pads.handle -> unit
  ...
\kw{end}\end{code}%
\noindent 
The parse-descriptor header reports on the parsing
process that produced the corresponding representation.  It includes
the location of the data in the source, an error code
describing the first error encountered, and the number of
subcomponents with errors.  The body contains the parse
descriptors for subcomponents.
Parse descriptors for base types have a body of type \cd{unit}.

The signature for a polymorphic \padsml{} type uses the signature
\cd{S} for monomorphic types, defined above.  
Given the polymorphic \padsml{} type \cd{ABPair}:
\begin{code}\scriptsize
\kw{ptype} (Alpha,Beta) ABPair = Alpha * '|' * Beta\end{code}%
the compiler generates a module with the signature:
\begin{code}\scriptsize
\kw{module} \kw{type} ABPair_sig (Alpha : S) (Beta : S) = 
\kw{sig}
  \kw{type} rep      = Alpha.rep * Beta.rep
  \kw{type} pd\_body = (Pads.pd_header * Alpha.pd\_body) * 
                 (Pads.pd_header * Beta.pd\_body)
  \kw{type} pd       = Pads.pd_header * pd\_body
  \kw{val}  parse    : Pads.handle -> rep * pd
  \kw{val}  print    : rep -> pd -> Pads.handle -> unit
  ...
\kw{end}\end{code}%

\subsection{Using the Generated Libraries}
Common data management tasks like filtering and normalization are easy to express in \ocaml{}.  In the remainder of this section, we illustrate this point by giving \ocaml{} programs to compute properties of ad hoc data, to filter it, and to transform it.

\cut{In contrast, \padsc{} users fall off an
abstraction cliff when they shift from declaratively describing data
to manipulating the generated data structures in \C{}, where they have
to worry about details such as manipulating \C{} strings and worrying
about memory management.  }

\subsubsection{Example: Computing Properties}
\label{sec:ex-process}
Given the \padsml{} type:
\begin{code}\scriptsize
\kw{ptype} IntTriple = Pint * '|' * Pint * '|' * Pint\end{code}%
the following \ocaml{} expression computes the average of the three integers in the file \texttt{input.data}:
\begin{code}\scriptsize
\kw{let} ((i1,i2,i3), (pd_hdr, pd_body)) = 
 Pads.parse_source IntTriple.parse "input.data" \kw{in}
\kw{match} pd_hdr \kw{with}
  \{error_code = Pads.Good\} -> (i1 + i2 + i3)/3
{|} _ -> \kw{raise} Pads.Bad_file \end{code}%
\noindent
The \cd{parse_source} function takes a parsing function and a file
name, applies the parsing function to the data in the specified file,
and returns the resulting representation and parse descriptor.  To
ensure the data is valid, the program examines the error code in the parse-descriptor header.  The error code \cd{Good} indicates that the data
is syntactically and semantically valid. Other error codes include
\cd{Nest}, indicating an error in a subcomponent, \cd{Syn}, indicating
that a syntactic error occurred during parsing, and \cd{Sem},
indicating that the data violates a semantic constraint. The
expression above raises an exception if it encounters any of these
error codes.

Checking the top-level parse descriptor for errors is sufficient to
guarantee that there are no errors in any of the subcomponents.  This
property holds for all representations and corresponding parse
descriptors.  This design supports a ``pay-as-you-go'' approach to
error handling. The parse descriptor for valid data need only be
consulted once, no matter the size of the corresponding data, and user
code only needs to traverse nested parse descriptors if more
precise information about the error is required.

\subsubsection{Example: Filtering}
\label{sec:ex-filter}

Data analysts often need to ``clean'' their data, \ie{}, remove or
repair data containing errors, before loading the data into a database
or other application.  \ocaml{}'s pattern matching and higher-order
functions can simplify these tasks.  For example, the expression in
\figref{fig:ex-data-clean} partitions \dibbler{} data into valid
orders and invalid orders.  \cut{The valid orders may then be further
processed or loaded into a database without risk of failure during the
load nor of corrupting the valuable data therein.  The invalid orders
can be examined off-line to determine the cause of the errors or to
repair them.

An important set of tasks involving ad hoc data are those related to
errors, including error analysis, repair, and removal.}

\begin{figure}
\begin{code}\scriptsize
\kw{open} Pads

\kw{let} classify_order order (pd\_hdr, pd\_body) (good, bad)=
   \kw{match} pd\_hdr \kw{with}
    \{error_code = Good\} -> (order::good, bad)
   | _                  -> (good, order::bad)

\kw{let} split_orders orders (orders_pd_hdr,order_pds) = 
   List.fold_right2 classify_order orders order_pds []

\kw{let} ((header, orders),(header_pd, orders_pd)) = 
   parse_source Sirius.parse "input.txt"

\kw{let} (good,bad) = split_orders orders orders_pd\end{code} 
\caption{Error filtering of \dibbler{} data}
\label{fig:ex-data-clean}
\end{figure}

\cut{
The \cd{classify_order} function receives an order, its parse descriptor,
and the lists of good and bad orders. Based on the parse
descriptor, it adds the order to the appropriate list.  The function
\cd{split_orders} simply folds \cd{classify_order} over the lists of
orders and corresponding parse descriptors.
}
\subsubsection{Example: Transformation}
\label{sec:ex-trans}

\begin{figure}
  \centering
  \begin{code}\scriptsize
...
\kw{ptype} Header = \{
       alarm : [ a : Puint32 | a = 2 or a = 3];
 ':';  start :  Ptimestamp Popt;
 '|';  clear :  Ptimestamp Popt;
 '|';  code  :  Puint32;
 '|';  src\_dns  :  Nvp("dns1");
 ';';  dest\_dns :  Nvp("dns2");
 '|';  service  : Service
\}
\mbox{}
\kw{ptype} D\_alarm = \{
       header : Header;
 '|';  info   : Details
 \}
\mbox{}
\kw{ptype} G\_alarm = \{
       header : Header;
 '|';  info   : Nvp\_a Plist(';','|')
\}\end{code}
\caption{Listing of \texttt{\darkstar{}Normal.pml}, a normalized format for
  \darkstar{} data. All named types not explicitly included in this
  figure are unchanged from the original \darkstar{} description.}
\label{fig:normal-darkstar}
\end{figure}

\begin{figure}
\begin{code}\scriptsize
\kw{open} Regulus
\kw{open} RegulusNormal
\kw{module} A = Alarm
\kw{module} DA = D\_alarm
\kw{module} GA = G\_alarm
\kw{module} Header = H

\kw{type} ('a,'b) Sum = Left of 'a | Right of 'b

\kw{let} split_alarm ra =
  \kw{let} h = 
    \{H.alarm=ra.A.alarm; H.start=ra.A.start; 
     H.clear=ra.A.clear; H.code=ra.A.code;
     H.src\_dns=ra.A.src\_dns; H.dest\_dns=ra.A.dest\_dns;
     H.service=ra.A.service\}
  \kw{in} \kw{match} ra \kw{with}
      \{info=Details(d)\} -> 
      Left \{DA.header = h; DA.info = d\}
    | \{info=Generic(g)\} ->
      Right \{GA.header = h; GA.info = g\}

\kw{let} process_alarm pads [pads_D; pads_G] = 
  \kw{let} a,a_pd = Alarm.parse pads in
    \kw{match} (split_alarm a, split_alarm_pd a_pd) \kw{with}
     (Left  da, Left  da_p) -> DA.print da da_p pads_D
    |(Right ga, Right ga_p) -> GA.print ga ga_p pads_G
    | _ -> ... (* Bug! *)

\kw{let} _ = process_source process_alarm 
              "input.data" ["d_out.data";"g_out.data"]
  \end{code}
  \vskip -2ex
  \caption{Shredding \darkstar{} data based on the {\tt info} field.}
  \label{fig:ex-no-err-check}
\end{figure}

Once a data source has been parsed and cleaned, a common task is to
transform the data into formats required by other tools, like a
relational database or a statistical analysis package.
Transformations include removing extraneous literals, inserting
delimiters, dropping or reordering fields, and normalizing the values
of fields, \eg{}, converting all times into a specified time zone.
Because relational databases typically cannot store unions directly,
one common transformation is to convert data with variants (\ie{},
datatypes) into a form that such systems can handle.  One option is to
partition or ``shred'' the data into several relational tables, one
for each variant.  A second option is to create an universal table,
with one column for each field in any variant.  If a given field does
not occur in a particular variant, its value is marked as missing.

\figref{fig:normal-darkstar} shows a partial listing of
\texttt{\darkstar{}Normal.pml}, a normalized version of the
\darkstar{} description from \secref{sec:padsml-overview}. In this
shredded version, \cd{Alarm} has been split into two top-level types
\cd{D\_alarm} and \cd{G_alarm}.  The type \cd{D\_alarm} contains all
the information concerning alarms with the detailed payload, while
\cd{G\_alarm} contains the information for generic payloads.  In the
original description, the \cd{info} field identified the type of its
payload.  In the shredded version, the two different types of records
appear in two different data files. Since neither of these formats
contains a union, they can be easily loaded into a relational
database.

The code fragment in \figref{fig:ex-no-err-check} shreds \darkstar{}
data in the format described by \texttt{\darkstar{}.pml} into the
formats described in \texttt{\darkstar{}Normal.pml}.  It uses the
\cd{info} field of \cd{Alarm} records to partition the data. 
Notice the code invokes the \cd{print} functions generated for the \cd{G_alarm} and \cd{D_alarm} types to output the shredded data.

\cut{
\begin{figure}
  \centering
  \begin{code}\scriptsize
\kw{let} normalizeTimeToGMT t = 
    match t with
      \{time=t;timezone="GMT"\} => t
    | \{time=t;timezone="EST"\} => t + (5 * 60 * 60)
    | \{time=t;timezone="PST"\} => t + (8 * 60 * 60)
    | ... \end{code}
  \caption{Normalizing timestamps}
  \label{fig:ex-normalize}
\end{figure}

In \figref{fig:ex-normalize}, we show an additional example of data
transformation, where we normalize timestamp-timezone pairs into
simple timestamps in GMT time.
}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
