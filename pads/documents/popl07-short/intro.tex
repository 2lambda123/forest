\section{Introduction}
\label{sec:intro}
\cut{
{\em
To do:
\begin{itemize}
\item update text to include description of tools generated using the framework.
\item add size column to data source table.
\end{itemize}
}}
%% WHAT IS AD HOC DATA?

An {\em ad hoc} data format is any semi-structured data format for which
parsing, querying, analysis, or transformation tools are not readily
available.  Despite the existence of standard
formats like \xml{}, ad hoc data sources are ubiquitous,
arising in industries as diverse as finance, health care,
transportation, and telecommunications as well as in scientific
domains, such as computational biology and physics.
\figref{figure:data-sources} summarizes a variety of such formats,
including ASCII, binary, and Cobol encodings, with both fixed and
variable-width records arranged in linear sequences and in tree-shaped
hierarchies.  Snippets of some of these data formats appear in \figref{fig:sample-data}.
Note that even a single format can exhibit a great deal of
syntactic variability.  For example, \figref{fig:sample-data}(c)
contains two records from a network-monitoring application.  
Each record has a different number of fields (delimited by `$|$') and
individual fields contain structured values (\eg{},
attribute-value pairs separated by `=' and delimited by `;').

Common characteristics of ad hoc data make it difficult to perform
even basic data-processing tasks.  To start, data analysts typically
have little control over the format of the data;  it
arrives ``as is,'' and the analysts can only thank the supplier,
not request a more convenient format.  The documentation accompanying
ad hoc data is often incomplete, inaccurate, or missing entirely,
which makes understanding the data format more difficult.
Managing the errors that frequently occur poses another challenge. Common errors include undocumented fields, corrupted or missing data, and multiple representations for missing values.  Sources of errors include
malfunctioning equipment, race conditions on log entry, the
% deleted this cite for race conditions:  ~\cite{wpp}
presence of non-standard values to indicate ``no data available,'' and
human error when entering data.  How to respond to errors is highly 
application-specific: some need to halt processing and
alert a human operator, others can repair errors by consulting auxiliary sources, while still others simply filter out erroneous values. In some cases, erroneous data is more important than error-free data; for example, 
it may signal where two systems are failing to communicate.
Unfortunately, writing code that reliably handles
both error-free and erroneous data is difficult and tedious.

\begin{figure}
\begin{center}
\scriptsize
\begin{tabular}{@{}|l|l|l|l|l|}
\hline
Name: Use                               & Representation     \\ \hline\hline
Gene Ontology (GO)~\cite{geneontology}: & Variable-width     \\
Gene Product Information 	           & ASCII records      \\ \hline
SDSS/Reglens Data~\cite{mandelbaum+:reglens}:  & Floating point numbers,  \\
Weak gravitational lensing analysis     & among others       \\ \hline
Web server logs (CLF):                  & Fixed-column       \\ 
Measuring web workloads                 & ASCII records      \\ \hline
AT\&T Call detail data:                 & Fixed-width        \\
Phone call fraud detection              & binary records     \\ \hline 
AT\&T billing data:                     & Cobol              \\ 
Monitoring billing process              &                    \\ \hline
Newick:   Immune                        & Fixed-width ASCII records  \\ 
system response simulation              & in tree-shaped hierarchy   \\ \hline                                
OPRA:                                   & Mixed binary \& ASCII records  \\
Options-market transactions             & with data-dependent unions     \\ \hline
Palm PDA:                               & Mixed binary \& character  \\
Device synchronization                  & with data-dependent constraints \\ \hline
\end{tabular}
\caption{Selected ad hoc data sources.}
\label{figure:data-sources}
\end{center}
\end{figure}

\cut{
\begin{figure*}
\begin{center}
\scriptsize
\begin{tabular}{@{}|l|l|l|l|l|}
\hline
Name: Use                           & Representation    & Processing Problems \\ \hline\hline
Gene Ontology (GO)~\cite{geneontology}:                  & Variable-width    & White-space ambiguities \\
Gene Product Information 	      & ASCII records &  \\ \hline
SDSS/Reglens Data~\cite{mandelbaum+:reglens}:                & Floating point numbers, & Repeated multiplicative error \\
Weak gravitational lensing analysis   & among others & \\ \hline
Web server logs (CLF):                & Fixed-column      & Race conditions on log entry\\ 
Measuring web workloads               & ASCII records     & Unexpected values\\ \hline
AT\&T Call detail data:                          & Fixed-width       & Undocumented data\\
Phone call fraud detection            & binary records  & \\ \hline 
AT\&T billing data:                 & Cobol             &  Unexpected values\\ 
Monitoring billing process          &                   & Corrupted data feeds \\ \hline
Newick:   Immune                    & Fixed-width ASCII records & None \\ 
system response simulation          & in tree-shaped hierarchy &\\ \hline                                
OPRA:                               & Mixed binary \& ASCII records 
                                                       & 100-page informal \\
Options-market transactions         & with data-dependent unions & documentation \\ \hline
Palm PDA:                           & Mixed binary \& character & No high-level  \\
Device synchronization              & with data-dependent constraints & documentation available\\ \hline
\end{tabular}
\caption{Selected ad hoc data sources.}
\label{figure:data-sources}
\end{center}
\end{figure*}
}

% \begin{figure*}
% \begin{center}
% \begin{tabular}{@{}|l|l|l|}
% \hline
% \textbf{Name:} Use & Record Format (Size) 
% %& Size
%            & Common Errors \\ \hline\hline
% \textbf{Web server logs (CLF):}           & Fixed-column ASCII & Race conditions on log entry\\ 
% Measuring Web workloads  & ($\leq$12GB/week)  & Unexpected values\\ \hline
% \textbf{AT\&T provisioning data (\dibbler{}):} & Variable-width ASCII & Unexpected values \\ 
% Monitoring service activation  & (2.2GB/week) & Corrupted data feeds \\ \hline
% \textbf{Call detail:}                   & Fixed-width binary &  Undocumented data\\
% Fraud detection                         &   (\appr{}7GB/day) & \\ \hline 
% \textbf{AT\&T billing data (\ningaui{}):}      & Cobol      & Unexpected values\\ 
% Monitoring billing process  &  ($>$250GB/day) & Corrupted data feeds \\ \hline
% \textbf{IP backbone data (\darkstar{}):}  & ASCII & Multiple representations \\
% {Network Monitoring}       &  ($\ge$ 15 sources,\appr{}15 GB/day)  & of missing values \\
%           & & Undocumented data \\ \hline
% \textbf{Netflow:}               & Data-dependent number of & Missed packets\\ 
% {Network Monitoring}  & fixed-width binary records & \\ 
%                       & ($\ge$1Gigabit/second) & \\ \hline
% \textbf{Gene Ontology data:}    & Variable-width  & \\
% Gene product information & ASCII records & White-space ambiguities\\\hline
% \textbf{Newick data}              & Fixed-width ASCII & Manual entry errors \\
% Immune system response simulation & in tree-shaped hierarchy 
% & \\
% \hline
% \end{tabular}
% \normalsize
% \caption{Selected ad hoc data sources.}
% \label{figure:data-sources}
% \end{center}
% \end{figure*}

\begin{figure*}
  \centering
  \small

\begin{verbatim}
 2:3004092508||5001|dns1=abc.com;dns2=xyz.com|c=slow link;w=lost packets|INTERNATIONAL
 3:|3004097201|5074|dns1=bob.com;dns2=alice.com|src_addr=192.168.0.10; \
 dst_addr=192.168.23.10;start_time=1234567890;end_time=1234568000;cycle_time=17412|SPECIAL
\end{verbatim}  
%  \label{fig:darkstar-records1}
(a) Simplified Regulus network-monitoring data. 

\begin{verbatim}
0|1005022800
9153|9153|1|0|0|0|0||152268|LOC_6|0|FRDW1|DUO|LOC_CRTE|1001476800|LOC_OS_10|1001649601
9152|9151|1|9735551212|0||9085551212|07988|no_ii152272|EDTF_6|0|APRL1|DUO|10|1000295291
\end{verbatim}
%   \label{figure:dibbler-records}
(b) \dibbler{} data used to monitor billing in telecommunications industry.

\begin{verbatim}
(((erHomoC:0.28006,erCaelC:0.22089):0.40998, (erHomoA:0.32304,(erpCaelC:0.58815,((erHomoB: \
0.5807,erCaelB:0.23569):0.03586,erCaelA: 0.38272):0.06516):0.03492):0.14265):0.63594, \
(TRXHomo:0.65866,TRXSacch:0.38791):0.32147, TRXEcoli:0.57336)
\end{verbatim}
% \label{fig:newick}
(c) Newick data used to study immune system responses. 


  \caption{Snippets of a variety of ad hoc data formats. Each `$\backslash$' denotes a newline we inserted to improve readability. }
  \label{fig:sample-data}
\end{figure*}

\cut{
Surprisingly,
few meta-language tools, such as data-description languages or parser
generators, exist to assist in management of ad hoc data.  And
although ad hoc data sources are among the richest for database and
data mining researchers, they often ignore such sources as the work
necessary to clean and vet the data is prohibitively expensive.}

\subsection{\padsmlbig{}}

%% Slight change to emphasize generation of many tools.

\padsml{} is a domain-specific language designed to 
improve the productivity of data analysts, be they computational biologists, physicists, network administrators, healthcare providers, financial analysts, \etc\
To use the system, analysts describe their data in the \padsml{} language, capturing both the physical format of the data and any expected semantic constraints.  In return for this investment, analysts reap substantial rewards.
First of all, the description
serves as clear, compact, and formally-specified documentation of 
the data's structure and properties.  In addition, the \padsml{}
compiler can convert the description into a suite of robust, end-to-end
data processing tools and libraries specialized
to the format.  As the analysts' data sources evolve over time,
they can simply update the high-level descriptions
and recompile to produce updated tools.


The type structure of modern functional programming languages inspired the design of the \padsml{} language.  
Specifically, \padsml{} provides dependent, polymorphic recursive datatypes, layered on top of a rich collection of base types, to specify the syntactic structure and semantic properties of data
formats.  Together, these features enable analysts to write concise,
complete, and reusable descriptions of their data.  
We describe the \padsml{} language using examples from several domains
in \secref{sec:padsml-overview}.

We have implemented \padsml{} by compiling descriptions into
\ocaml{} code.  We use a
``types as modules'' implementation strategy in which each \padsml{} type
becomes a module and each \padsml{} type constructor becomes a functor. 
We chose \ml{} as the host language because we believe that 
functional languages lend themselves to data processing tasks more readily than imperative languages such as \C{} or \java{}.  In particular, constructs such as pattern matching and higher-order functions make expressing data transformations particularly convenient. \secref{sec:padsml-impl} describes our ``types as modules''
strategy and shows how \padsml{}-generated modules together
with functional \ocaml{} code can concisely express
common
data-processing tasks such as filtering errors and format transformation.

A key benefit of our approach is the high return-on-investment that
analysts can derive from describing their data in \padsml{}.  In particular, \padsml{} makes it possible to produce automatically a collection of data analysis and processing tools from each description.   
As a start, the \padsml{} compiler generates from each description a parser and a printer for the associated data source.  The parser maps raw 
data into two data
structures: a canonical \textit{representation} of the parsed data and
a \textit{parse descriptor}, a meta-data object detailing properties
of the corresponding data representation.  Parse descriptors provide
applications with programmatic access to errors detected during
parsing.  The printer inverts the process, mapping internal data structures
and their corresponding parse descriptors back into into raw data.

In addition to generating parsers and printers, our framework permits
developers to add {\em format-independent} tools without modifying the \padsml{} compiler by specifying \textit{tool generators}.  Such generators need only match a generic interface, specified as an \ml{} signature.  
Correspondingly, for each \padsml{} description, the \padsml{} compiler generates a meta-tool (a functor)
that takes a tool generator and specializes it for use with
the particular description.  \secref{sec:gen-tool} describes the
tool framework and gives examples of three format-independent 
tools that we have
implemented: a data printer useful for description debugging,
an accumulator that keeps track of error information for
each type in a data source, and a formatter that maps data into XML.

To define the semantics of \padsml{}, we extended our earlier work on
the Data Description Calculus (\ddcold{})~\cite{fisher+:next700ddl} to
account for \padsml{}'s polymorphic types.  In the process, we
simplified the original presentation of the parser semantics
substantially, particularly for recursive types.  In addition, we
extended the theory to give a printing semantics. We used this new
semantics to guide the \padsml{} implementation of printing.  We 
also proved that the generated code of the parsing and printing
semantics is type safe and well-behaved as defined by a canonical
forms theorem. A full treatment of the extended calculus appears in
Mandelbaum's Ph.D. thesis~\cite{mandelbaum-thesis}, while an overview of
the calculus and printing semantics, as well as the associated
metatheory, can be found in our companion technical
report~\cite{fisher+:popl-sub-long}.


\cut{\textbf{***THEN compare to \padsc{} in one paragraph only}}
\padsml{} has evolved from previous work on
\padsc{}~\footnote{We refer to the original
\pads{} language as \padsc{} to distinguish it from \padsml{}.}~\cite{fisher+:pads}, but
\padsml{} differs from \padsc{} in three significant ways.  First, it
is targeted at the \ml{} family of languages.  Using \ml{} as the host
language simplifies many data processing tasks, such as filtering and normalization, 
which benefit from \ml{}'s pattern matching constructs and
high level of abstraction.  Second, unlike \padsc{} types, \padsml{}
types may be parameterized by other types, resulting in more concise
and elegant descriptions through code reuse.  \ml{}-style datatypes and 
anonymous nested tuples also help improve readability by making descriptions more compact.  Third, \padsml{} provides
significantly better support for the development of new tool generators.
In particular, \padsml{} provides a generic interface against which
tool generators can be written.  In \padsc{}, the compiler itself
generates all tools, and, therefore, developing a new tool generator
requires understanding and modifying the compiler.

\cut{
\textbf{***Then give observations.}
\textbf{Actually, this observation should go in the conclusion.  It's
  distracting here.}
Our ``types as modules'' implementation strategy encountered the
  limits of the \ocaml{} module system in multiple ways. It therefore
  provides a natural, well-motivated challenge example for
  functional-programming researchers in type-directed programming and
  advanced module design.

Therefore, the combination of
  \padsml{} and \ocaml{} is a significant step towards a unified
  language for data description, transformation, and analysis.
}

\cut{\textbf{***Then, if still necessary give a pithy list of contributions}}

In summary, this work makes the following key contributions:
\begin{itemize}
\item We have designed and implemented \padsml{}, a novel
data-description language that includes 
dependent polymorphic recursive datatypes.  This design
allows data analysts to express the syntactic
structure and semantic properties of data formats from numerous
application domains in a concise, elegant, and easy-to-read notation.  
\item Our \padsml{} implementation employs an effective and
general ``types as modules'' compilation strategy
that produces robust parser and printer functions
as well as auxiliary support for user-specified tool generation.
\end{itemize}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
