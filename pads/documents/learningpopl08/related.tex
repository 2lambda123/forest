Researchers have been studying {\em grammar induction}, the process of
learning the structure of a data source, for decades.  Nevertheless,
the work we present in this paper represents an important and novel 
contribution to the field for three key reasons:

{\em NOTE: is the last one good?}

\begin{enumerate}
\item Our system solves {\em a new end-to-end problem} not treated in
past work --- the problem of generating an extensible suite of fully
functional data processing tools directly from ad hoc data.  We can
currently generate an xml translator, a normalizing reformatter, a
graphing tool, a full query engine allowing users to write arbitrary XQueries
against the ad hoc data, the accumulator tool, and
programming libraries for parsing, printing and data validation.
Generating such a wide variety of powerful tools would be impossible
without the combination of three elements: grammar induction,
automatic intermediate representation generation and type-directed
programming.  A key contribution of this work is the conception,
development and evaluation of this end-to-end system.  After surveying
experts at the CAGI 2007 workshop on grammar induction, where we
presented a two-page overview of our system~\cite{burke+:cagi07}, and
searching the literature, we could find no existing system that
provides this end-to-end functionality.

\item Past work on grammar induction has focused primarily on
either (1) abstract, theoretical problems, (2) natural language processing or
(3) XML typing.  Our work tackles a new domain, that of complex system
logs and other {\em ad hoc data sources}. 
Since ad hoc data has different characteristics from these 
other domains, na\:{i}ve adaptation of existing algorithms 
will not necessarily prove to be the most effective.  Our particular
system is tuned to perform well on ad hoc data, particularly system
logs and networking data.  Moreover, we have performed the necessary evaluation
on these sources to prove it.  One of the conclusions of the
chair of the CAGI 2007 workshop, presented in the final discussion session
of the workshop, was that ``ad hoc data'' was indeed a new domain for the 
study of grammar induction and that more research in this area was an
important future direction for the community.

\item  From a technical standpoint, we developed a new top-down 
structure-discovery algorithm and showed how to combine that 
productively with a classic bottom-up rewriting system based on 
the minimum description length principle. We demonstrate that our
new algorithm has good practical properties on ad hoc data sources:  
it usually infers correct descriptions on a small amount of training
data and its performance scales linearly relative to the amount of training
data used.
\end{enumerate}

\noindent
The following paragraphs analyze
the most closely related work in the areas of
traditional grammar induction, information extraction, and XML analysis
in more depth.

\paragraph*{Traditional Grammar Induction.}
Classic grammar induction algorithms (see De La Higuera~\cite{higuera01current}
or Vidal~\cite{vidal:gisurvey} for surveys) can be divided into two classes:
those that require both positive and negative examples to discover a grammar
and those that only require positive examples.\footnote{A positive training
example is an example guaranteed to be in the language in question;
a negative training example is an example guaranteed {\em not} to be in the 
language in question.}  The problem our system solves is the latter; 
negative examples of ad hoc data sources are not available in practice.  
Of course, a programmer might try to create
negative training examples themselves by hand, but creating a representative
sample would surely take far longer than simply writing
the appropriate PADS description itself.  Consequently, effective theoretical
algorithms for learning from both positive and negative examples~\cite{rpni,denis:learning-regular-languages,lemay+:tree-transducers,raeymaekers+:learning-tree-languages}, are 
simply not useful in our context.  

Unfortunately, an early result by Gold~\cite{gold:inference} 
showed that perfect solutions to the problem
are impossible any superfinite class of languages is 
impossible in the limit when the algorithm has no access to negative 
examples.  A {\em super-finite} class of languages is any set of languages
that includes all finite languages and at least one infinite language. Hence,
all the most familiar classes of languages, including regular expressions, 
context free grammars and PADS are superfinite.  There are two
main tactics one can use to avoid this negative result~\cite{vidal:gisurvey}:
(1) give up on perfect language identification and instead
settle for 
{\em approximate identification}~\cite{wharton:approximate-language-identification} through the use of probabilistic language
models or (2) use domain knowledge to explicitly limit the class of languages
to a non-superfinite class.  

Examples of non-trivial, non-superfinite
language classes with known inference algorithms include
k-reversible languages~\cite{angluin:revesible-language-inference},
k-testable regular languages~\cite{garcia+:k-testable-languages},
SOREs~\cite{bex+:dtd-inference} and CHAREs~\cite{bex+:dtd-inference}.
None of these languages and their associated algorithms seem to be 
a particularly good fit for inferring PADS descriptions (or at least the
regular subset of PADS without dependency and constraints).  
For example, ad hoc data
is not necessarily reversible and hence k-reversible languages
do not appear relevant.  K-testable regular languages might be somewhat
more relevant, but algorithms for inferring them
operate by finding a finite automaton and converting that 
automaton into a regular expression.  Unfortunately, the conversion process
often leads to overly verbose regular expressions, sometimes 
exponential in the size of the automaton~\cite{bex+:dtd-inference}. 
SOREs are a subset of the k-testable
regular languages with a linear-size translation from automata to
regular expressions, but they carry the restriction that each symbol
in the regular expression appear at most once.  A cursory glance at
our hand-written PADS descriptions reveals that many such descriptions
include repeated use of the same symbol.  Finally, it appears that
CHAREs restrict the nesting of regular expression operators too severely to 
be of much use to us.  For example, when $a$, $b$, and $c$ are atomic symbols,
even the simple expression $(ab + c)*$ is not a CHARE.

Given the difficulty of finding useful non-superfinite language classes,
it is reasonable to turn to algorithms for approximate
inference that use probabilistic models.    
Classic examples of such procedures include work by Stolcke and
Omohundro~\cite{stolcke94inducing}, {\em insert other references here -- see Hong thesis related work for other work...} and 
Hong~\cite{hong01using,hong:thesis}.  These and a number of other algorithms
operate by repeatedly rewriting a candidate grammar (or set of candidate
grammars) until an objective function is optimized.
If the training data is for the learning system is the strings
$s_1$, $s_2$, $\ldots$, $s_n$, these algorithms normally start their
process using the grammar $s_1 + s_2 + \cdots + s_n$, which may
be enormous if there is much training data.  
Consequently, hundreds or even thousands of different rewrites apply to the
initial candidate grammar.  Our structure refinement
phase avoids these problems and works relatively quickly 
because it is preceded by a novel and highly efficient
histogram-based structure-discovery algorithm 
that identifies a good candidate grammar to start the search from.  
Another interesting, non-standard element of our algorithm is the way 
it is tuned to include specialized rules for finding constraints and 
rewrite tokens.
These rules are very useful in the domain of ad hoc data; different
considerations are appropriate in other domains such as XML or HTML.

%% is also tuned in a variety of ways to make it effective

%% The effectiveness of structure-discovery allows us to 
%% simplify our search algorithm and cut down the search space we 
%% look at substantially.  In addition to worrying about
%% performance considerations, we tuned our structure refinement phase
%% specifically for ad hoc data by including domain-specific rules
%% for finding constraints and 
%% dependencies as well as those for introducing constants, enumerations and
%% good basic types/tokens that cannot be found effectively at earlier stages.
%% Some of these rules are needed in our system, but not other systems
%% that work in different domains, because
%% tokenization is highly ambiguous in ad hoc data.
%% Our initial tokenization and structure-discovery algorithms often 
%% over-generalize and this over-generalization must be undone during
%% the rewriting phase.  {\em NOTE: end of that paragraph was highly  run-on}

Another category of algorithms to consider 
are those that learn various kinds of
automata as opposed to regular expressions or grammars.
For instance, RPNI~\cite{rpni} and Denis's work on learning 
RFSAs~\cite{denis:learning-regular-languages} fall into this category,
as do Raeymaekers's algorithms to learn tree automata~\cite{raeymaekers+:learning-tree-languages,raeymaekers+:wrapper-induction}.
One difficulty with adapting these algorithms to our task is that 
any coverter from automata to regular expressions (or PADS descriptions)
may produce very large, unnatural descriptions.  This was found to occur 
when such algorithms were applied to XML data~\cite{bex+:dtd-inference}.
We would need such a converter to present inferred descriptions to users
or to funnel the results of inference to our tool-generation infrastructure.


%% developed another system for information extraction from web pages
%% based on learning ($k$,$l$)-Contextual Tree Languages.  They show that
%% these tree languages can be learned from positive examples 
%% (from which one may infer they are not superfinite) and apply
%% their techniques to the problem of information extraction.  One of the
%% difficulties they face involves estimating the parameters involved in

  
%% {\em NOTE: I'm leaving out reference to denis:learning-regular-languages (see
%% pads.bib file).
%% Vincent Danos mentioned it but it contains no references to any real data.
%% It's interesting theoretical result that infers a new kind of automaton.
%% This automaton will likely have the same potential difficulties 
%% (possibly exponential explosion -- I haven't prove that though) 
%% when conversion to regular expressions happens. Anyway, I just didn't
%% want to bother studying the paper because they're so much other stuff
%% that is more relevant.  basically, I just couldn't figure out how to cram
%% the reference in elegantly.  I actually couldn't even figure out when I skimmed
%% the paper whether or not it uses both positive and negative examples.
%% It gets compared to RPNI, so I think it must use negative examples.
%% }

%% One disadvantage of such
%% techniques is that the initial state is large (representing
%% the entire training data set explicitly) and the search space is 
%% enormous.  Nevertheless, bottom-up state-merging is often used because
%% it has been difficult to find an effective state-splitting algorithm.
%% Our histogram-based structure-discovery procedure is a new state-splitting
%% algorithm that appears to work well on ad hoc data when coupled with
%% bottom-up rewriting.


%% The classic grammar induction problem~\cite{vidal:gisurvey} requires we find an
%% algorithm that discovers a grammar $G$ given a set of
%% positive examples $R+$ (example strings in the language to be inferred)
%% and a set of negative examples $R-$ (example strings {\em not}
%% in the language to be inferred).  To be more specific, in the limit,
%% as the sets of positive and negative examples grow, the
%% algorithm is expected to converge on the language that defines them.  
%% Unfortunately, very early on,
%% Gold~\cite{gold:inference} proved a key negative result about this problem:  If
%% the algorithm is presented with no negative examples, grammar
%% induction for any super-finite class of languages is impossible.
%% A {\em super-finite} class of languages is any set of languages
%% that includes all finite languages and at least one infinite language.
%% All the most familiar classes of languages, including regular expressions, 
%% context free grammars and PADS, fall into this class.

%% Traditional
%% Some traditional grammar induction algorithms assume that
%% both positive and negative training data
%% One way to categorize research in traditional
%% grammar induction is to ask whether the research in question
%% assumes that both positive and negative training data is available
%% or whether only positive training data is available.

%% analyze the assumptions made
%% about the training data.  
%% Very early in the study of grammar induction, Gold proved a key
%% negative result:


%% Other researchers have defined grammar induction algorithms that use
%% bottom-up rewriting to search through description space for an optimal
%% description.  Many of these techniques, such as 
%% require the availability of both
%% positive and negative examples.  In our context, negative examples
%% never exist, making such techniques inapplicable.
%% % since Gold's early result proved the
%% %impossibility of {\em perfect} grammar induction for any useful family of
%% %languages when no negative examples are
%% %available~\cite{gold:inference}.  
%% However, others, such as Stolcke and
%% Omohundro~\cite{stolcke94inducing} and Hong~\cite{hong01using}, do not
%% assume the existence of negative examples.  These and a number of other systems
%% search through solution space using
%% state-merging rewriting rules.  One disadvantage of such
%% techniques is that the initial state is large (representing
%% the entire training data set explicitly) and the search space is 
%% enormous.  Nevertheless, bottom-up state-merging is often used because
%% it has been difficult to find an effective state-splitting algorithm.
%% Our histogram-based structure-discovery procedure is a new state-splitting
%% algorithm that appears to work well on ad hoc data when coupled with
%% bottom-up rewriting.

% State-merging rewriting rules seem to be
% more popular than 
% that use bottom-up rewriting to find good grammars may suffer from the
% problem of running into local maxima.  The rewriting component of our
% algorithm can also run into a local maximum, but because we start with
% a relatively good candidate generated from our recursive, top-down
% algorithm, this does not appear to be much of a problem for us.  We
% also believe that combining top-down structure-discovery with
% bottom-up rewriting has the potential to deal with larger data sources
% than a pure bottom-up approach.  Our empirical experiments demonstrate
% that the top-down structure-discovery phase is extremely efficient
% when compared with the cost of rewriting.  However, proposals for
% bottom-up-only inference techniques use the (possibly enormous) data
% source itself as the first description.  We are unaware of other
% systems that combine two techniques similar to ours.


%% ; De La Higuera
%% surveys some recent trends~\cite{higuera01current}.  However,
%% our system is unique in two important ways.  First, our inference
%% algorithm does not stand alone; it is part of the more general \pads{}
%% programming environment.  The fusion of the
%% \pads{} system, including its automatic data representation generation,
%% its error detection facilities, its generic programming environment, 
%% and its powerful tool suite, together with grammar induction
%% is one of our key contributions.  Second, many researchers have
%% focused either on grammar induction for natural language processing or
%% for information extraction from \xml{} or \html{} documents.  In
%% contrast, we focus on ad hoc data sources such as system logs and
%% scientific data sets. Ad hoc data is substantially less
%% structured syntactically than \xml{}, and yet, unlike natural language, it is
%% possible to assign our data sources accurate, compact descriptions. After
%% searching the literature and consulting
%% with experts in grammar induction at the CAGI 2007
%% workshop, where we presented a two page overview of our system~\cite{burke+:cagi07},
%% we could find no existing work comparable to ours.

% Third, from a
% technical standpoint, we developed a new top-down structure-discovery
% algorithm and showed how to combine that productively with a
% classic bottom-up rewriting systems based on the minimum description
% length principle.  In what follows, we compare our system more
% specifically to the most closely related work of other researchers.

\paragraph*{Information Extraction Systems.}
The basic goal of an information extraction system is 
to find and separate the few interesting and relevant bits of information 
(the needles) from a haystack of data.  These systems often learn partial
or total information about the structure of the data they are searching
through.  Most such systems have been developed either for
deployment over structured HTML data or free text; only a few have investigated
information extraction from ad hoc data such as system logs.  Those that have 
do not provide the same suite of tools as PADS does.

% Many information extraction
% systems learn rules about the structure of the data that they
% analyze but these rules often do not completely characterize
% the data in question.  In other words, information extraction systems
% often do not learn a description of the data, they only learn enough
% to retrieve key data items and often leave behind extraneous data they
% view as garbage.  Our system, on the other hand, learns complete descriptions,
% which are necessary for generating several of our tools,
% most notably the parsing and printing libraries, as well as the translation
% tools, which seek to {\em preserve} all the data in an ad hoc data file,
% but make it available in a different format.  
% It is also the case that
% most information extraction systems treat a different domain than we do ---
% they are usually applied to either collections of web pages or to 
% free text.  Both Web pages
% and free text present different sorts of problems from ad hoc data.

Examples of systems that operate over free text include
Gubanov's structural text search~\cite{gubanov+:structural-text-search},
Borkar's work~\cite{borkar+:text-segmentation} on extracting well-formed
records and 
Soderland's WHISK system~\cite{soderland:whisk}.  WHISK is particularly
interesting because it can also be deployed ad hoc data like our system....

Perhaps the most closely related work is from Arasu and 
Garcia-Molina~\cite{arasu+:sigmod03}, who developed an information
extraction system for sets of similar web pages.  
%The
%commonalities between web pages are assumed to be a ``template'' structure
%and the differences are assumed to be values drawn from a database
%sitting behind the web site.  
Arasu uses a top-down grammar induction
algorithm somewhat similar to our rough structure-inference phase
(though it does not use histograms),
but has no description-rewriting engine.  
%However, in certain ways, Arasu has a much easier task than we do as html
%documents have far more regular structure than ad hoc data sources do.
This algorithm exploits the hierarchical nesting
structure of \xml{} documents in essential ways
and so cannot be applied directly to ad hoc data.  
%For example,
%we use histograms to summarize the contents of data chunks whereas
%Arasu does not.  In addition, a substantial portion of our system
%is a description rewriting engine, which Arasu seems not to need.  

Earlier work by Kushmerick et al.~\cite{KushmerickWD97:Wrapper} 
proposed an
induction framework which learns a kind of wrappers from
HTML pages. A wrapper is a procedure that extracts tuples from
the web pages. The key contribution of their work is 
the use of a ``corroboration'' process that automatically labels
web page samples using imperfect reusable heuristics called 
``recognizers''. While this process may be related to the
tokenization in our algorithm, the general goal of the work
is extracting pieces of information from the documents and not
learning of the entire structure. Moreover, the technique presented
is only applicable to tabular content which is not
as general the ad hoc data. 

The TSIMMIS project~\cite{chawathe+:tsimmis} aims to
allow users to manage and query collections of heterogeneous, ad hoc
data sources.  TSIMMIS sits on top of the Rufus
system~\cite{shoens+:rufus}, which supports automatic classification
of data sources based on features such as the presence of certain
keywords, magic numbers appearing at the beginning of files and file
type.  
%The sources are classified using categories such as ``email''
%and ``C program.''  
This sort of classification is materially
different from the syntactic analysis we have developed.

Another approach to learning information extraction tools involves
having the user manually label documents and then using the labelled
documents in training.  Muslea {\em et al.}~\cite{muslea+:active-learning} 
use this idea effectively to extract information from web pages.  Work by 
Ireson {\em et al.}~\cite{ireson+:ml-evaluation} investigates how systems 
like this should be evaluated.  Systems that depend upon labeling
are unlikely to be helpful in our context; rather than spending 
time explicitly labeling documents, the user might as well write a 
PADS description by hand.


% For further reading on
% information extraction from web pages, Hong's
% thesis~\cite{hong:thesis} includes an informative survey.  Though,
% Arasu's work and TSIMMIS appear more closely related to our work than
% the others Hong mentions.

Potter's Wheel~\cite{raman+:potterwheel} is a system that attempts to
help users find and purge errors from
relational data sources.  It does so through the use of a spread-sheet
style interface, but in the background, a grammar inference algorithm
infers the structure of the input data, which may be ``ad hoc,'' 
somewhat like ours.  This inference algorithm operates by
enumerating all possible sequences of base types that appear
in the training data.  
%As in our work,
%users can specify custom base types, and search for a description
%is based on the minimum description length principle.  
Since Potter's Wheel is aimed at processing
relational data, they only infer \cd{struct} types
as opposed to enumerations, arrays, switches or unions.  

\paragraph*{XML Type Inference.}
Many researchers have studied the problem of learning
a schema such as a DTD or XSchema from a collection 
of XML documents~\cite{fernau:learning-xml,garofalakis+:xtract,bex+:inferring-xml-schema,bex+:dtd-inference}.  At a high level, this task is similar
to the format inference 
component of our system, though, of course, there is more
to our system than just format inference (we produce fully 
functional tools for parsing, printing and transforming ad hoc data).  
However, the details differ because
XML has different characteristics from the ad hoc data we
work with.  One difference, mentioned earlier in the comparison with
Arasu's work, is that XML documents come in a well-nested tree
shape.  On the one hand, the delimiters that define nesting
structure in ad hoc data is more difficult to uncover, bu on the other hand,
our informal observations suggest that ad hoc data sources are generally
far less nested than large XML documents.  A second important difference
is that the token structure of ad hoc data sources is often ambiguous and
the best token selection is not known in advance.  
One of our strategies for dealing with
these ambiguities is to define simple approximate tokens for use
in the tokenization phase, but then to employ a collection of 
rules to improve token ({\em i.e.}, base type) choices in the rewriting phase
when more contextual information is available.  In contrast,
tokens in XML documents are clearly demarcated using angle bracket syntax.
A third difference is that XML documents are often organized such that
the structure of a child node is dependent on its parent or grandparent.
In contrast, in the flatter ad hoc data we have considered, dependencies
generally arise between siblings -- some data item to the left influences
the structure of data to the right.  As a result of these differences,
XML inference algorithms cannot be used ``off-the-shelf'' for understanding
the structure of ad hoc data.  They must be modified, tuned and
empirically evaluated on this new task.

One line of research on schema inference for XML, which we would
particularly like to highlight, makes use of the 
observation that 99\% of the content models for an XML node are defined as
SOREs or CHAREs~\cite{martens+:expressiveness-xml-schema} (recall, these
are heavily restricted forms of regular expressions).  
This observation allows Bex {\em et al.}~\cite{bex+:dtd-inference} to define
an efficient algorithm for inferring concise DTDs.  Later 
Bex {\em et al.}~\cite{bex+:inferring-xml-schema} build on this work 
by showing how to infer $k$-local XML Schema definitions also based on
SORES.  A $k$-local definition allows node content to depend on the parent
tag, grandparent tag, etc. (up to $k$ levels for some fixed $k$).
As mentioned earlier, hand-written PADS descriptions do not generally obey
the SOREs or CHAREs restriction, nor are they generally arranged with a nesting
structure that suggests $k$-local inference will be particularly useful.
The successful application of these techniques to XML data reinforces 
the idea that the ad hoc data we analyze has quite different characteristics
from XML, and therefore the ad hoc data inference problem merits study
independent of the XML inference problem.

Another related problem of great interest in the XML and databases world
involves finding a mapping between two data sources with different schema.
Doan et al.~\cite{doan+:disparate-data-sources} is one example amongst
many who attempt to solve this problem using a machine learning approach.
While some of our PADS tools do involve translations between
different formats, our learning system does not attempt to discover
translation tools for which the output is guaranteed to match 
the characteristics of a second data set.
