
In this section, we discuss the principal limitations of the \pads{}\ 
infrastructure we have built to date and explain extensions
necessary to build data-centric system monitors. 

\paragraph*{Multi-source Monitoring}
The current \pads{} specification language can only describe
the contents of a single, fixed data source.  In order to 
generate monitoring infrastructure for
wide area distributed systems such as the Grid, which 
may contain hundreds or thousands of nodes, each 
potentially with several different sensors producing
new data at a rapid rate, we must augment \pads{}
so that it may specify a collection of data sources
both local to a single machine and distributed across a wide area network.
In addition, it will be necessary to describe the {\em temporal}
aspects of data collection -- will data be pulled to a central
processor next Tuesday (only), once per day, once every five minutes
or triggered by user, network or other conditions?
In order to support multi-source monitoring, we will augment PADS
with the following features and implementation support.

% For example, in order to monitor the health of PlanetLab, a
% distributed network of several hundred machines spread across the
% world, the CoMon monitoring system~\cite{comon} attempts to drag a
% small data file from each of the machines to a centralized repository
% once every five minutes.  In the centralized repository, the data is
% split into two new formats, each designed to accumulate information
% about a certain aspect of the system.  In all, CoMon produces
% approximately 22,000 files/day.    We
% propose to extend our specification language to enable automatic
% generation of tools that process multiple data sources, either on one
% local machine or distributed across a wide area network.  Doing so
% will require investigation of the following features.

\begin{enumerate}
\item {\bf Multi-source Specifications}  
We propose to extend the PADS specification language with a new
first-class type constructor, \texttt{Pget\{T;e\}}.  Here \texttt{e}
specifies a protocol for locating and accessing a data source, and
\texttt{T} is a PADS type specifying the structure of its contents.
The specification language for protocols should be completely flexible
so it can handle the largest possible collection of applications.  For
instance, CoMon accesses data via telnet and authentication; other
data is available over the web through FTP and HTTP.  
Though the construct \texttt{Pget \{T;e\}}, 
is simple (an explicit design choice) we believe that 
when it interacts with the rest of the PADS
specification language it will provide powerful access possibilities.
In particular, due to the dependency already present in PADS, it will
be possible to read a local file containing information
concerning when, where and how to acquire further data and
then use \texttt{Pget} recursively to implement distributed data collection. 
For instance, to implement a CoMon-like monitoring
service, a local machine might contain a list of all current
PlanetLab nodes.  A PADS specification might read that list and use
the information processed to acquire information from all machines on
the list.  Such a data-driven architecture allows dynamic changes
to network structure while leaving the monitoring infrastructure unchanged.

\item {\bf Temporal Specifications}
In order to support applications that monitor repeated, ongoing phenomena, we
will need to add temporal specifications to PADS.  These
temporal specifications might indicate periodic arrival of new data
(once every five minutes), arrival of data at some specific time in
the future (next Tuesday) or upon receiving an explicit signal from
some external source such as a user.  
As is the case with our spatial specification
\texttt{Pget}, we will strive for a design that combines simplicity
with generality.  We anticipate adding a second symmetric operator to PADS,
\texttt{Ptime} that specifies when to take action, and a 
domain-specific temporal language for specifying times.  However, 
it will take substantial research
to work out the details of a sufficiently flexible, yet concise
and easy-to-understand temporal specification language. 
We plan to investigate all corners of the design space.

\item {\bf Concurrent Execution}  
PADS is currently a single-threaded application.  However,
to support access to many sources, possibly distributed
across a wide area, it will be necessary to process multiple
repositories concurrently.  As data from each new source is requested
through the \texttt{Pget} command, we plan on launching a new thread
to read the source.  However, the dependency in PADS may
require synchronization between threads, making implementation
of parallel processing nontrivial.  More research is required to
understand the optimal implementation strategy.  However, the fact that
PADS is a pure, declarative language should simplify dependency
analysis greatly and improve opportunities to hide latency through
concurrency.


% BS alert!!

\item {\bf Modular Specifications}
As specifications begin to get larger and encompass multiple different
data repositories, possibly with different data formats, standard
software engineering practice suggests introduction of features to
enable modular development of specifications and to allow multiple
programmers to collaborate on specifications.  The first necessary
addition to PADS along these lines is a namespace mechanism to allow
programmers to control their type names in a disciplined fashion.  A
second extension we will explore is introduction of more general
interfaces that allow programmers to make type definitions abstract.
This feature should make it easier to evolve large specifications as
monitoring requirements change.

\end{enumerate}


\paragraph*{Data Transformation, Compression, Encryption and Error-correction}
The data used by monitoring systems may require simple transformations 
of various kinds
immediately before parsing or after parsing and before
passing data to downstream processors, query engines or 
visualization tools.  Before archiving data,
inverse transformations may have to be applied.  
Examples of pre-parsing routines include decryption for
security-sensitive data and decompression for high-volume data.  
The natural inverses for printing and archiving 
are encryption and compression.
After parsing, many data sources require, or at least benefit from,
a variety of simple data transformations.  For example,
sometimes poorly-designed
ad hoc data will have multiple different representations
of the same concept -- dates in different formats, several different strings
to represent ``no value'' etc.  Simple transforms can be used to convert
these representations into a canonical form that facilitates down-stream
processing.  As another example, many data sources have privacy-sensitive parts
that should be ``sanitized'' in some way or another, possibly by scrubbing or
filtering data fields before passing them to down-stream applications.
In October 2005, for instance, we asked the Princeton Computer Science
Department Technical Staff for access to web logs for some experiments
with \pads, but they refused until they had written scripts to
sanitize the data for us.  Medical data is another example of highly
privacy-sensitive data.
Lastly, almost all ad hoc data may contain errors, but sometimes there 
will be simple data-specific heuristics such as substitution of default values
or discarding of corrupted segments
that can be used to fix the most common problems.

It is currently impossible to code multi-stage processing and transformation
directly in PADS.  One solution
to this problem might be to let auxiliary passes through the data
remain outside the PADS system as prepasses or postpasses.  
Unfortunately, this solution is completely unsatisfactory for a
number of reasons.  First, doing so
will often leave us in a situation in which the \pads{} description 
is not a self-contained
definition of the data format in question.  Consequently some of the value
of \pads{} as documentation is lost.  
Second, programmers must do
more work themselves to produce PADS applications.  They cannot
simply run our automatic generators and receive a well-packaged 
query engine or statistical analyzer for the raw data.
Moreover, when coding transformation directly in C, the host language
for \pads{}, they must program at a much lower level of abstraction
than we might provide by supplying specialized domain-specific
transformers directly in \pads.
Since our goal is to maximize the productivity of scientists 
who use ad hoc data, ease-of-use is a key constraint.
Finally, some data formats and
tasks are not well-suited for implementation as a separate pre- or post-pass.
For example, some formats use non-uniform compression or encryption 
schemes~\cite{korn+:delta,korn+:data-format}.
Moreover, tasks such as data sanitization and error correction may be
data-dependent and directed by the structure of the data.  In other words,
they may involve just the sort of data analysis that PADS was built for
and should be integrated directly into the specification mechanism.

To address these difficulties,
we plan to research mechanisms that facilitate multi-stage data processing 
directly in PADS.  Since any PADS description must be able to generate 
both data
input tools {\em and} data output tools, we currently believe that each
data processing stage, or layer, should be specified as a pair of
transformations.  For instance, if data is decompressed on the way in,
it must be compressed on the way out.  If a field of the data is ``sanitized''
or filtered on the way in, perhaps a default value of the correct form must
be written back out to preserve the syntactic structure of the data format.

To achieve this functionality, we will begin by considering a
transformation specification with the general form 
\texttt{Ptransform \{ i,o :  Tcon <-> Tabs \}}.
Here, {\tt Tcon} is the PADS type of the external or {\tt con}crete
representation and {\tt Tabs} is the PADS type of the internal or 
{\tt abs}tract representation.  The internal representation of the current
phase may in turn serve as the external representation for the next
phase of the transformation.  The functions {\tt i} and {\tt o} are
user-defined functions that transform data from {\tt Tcon} to 
{\tt Tabs} and vice versa.  For example, {\tt i} may implement
decompression and {\tt o} may implement compression.

We intend to add these transformations as first-class
descriptions/types to the system.  In other words, these
transformation may be nested inside or otherwise composed with any
other form of PADS description.  When so nested, the transformation
will only apply to the appropriate specific subcomponent of the
format.  Therefore, transformations will be useful for simple
subcomponent error correction or representation casting as well as
full data source transformations such as decompression.  In addition,
transformations with compatible types will be composable.  For
example, if a data format is compressed and potentially contains
errors, a decompression transform may be composed with an
error-correction transform.

The meat of certain transformations such as compression and encryption
are probably best written as ordinary program code that is
subsequently included in the PADS description.  However, for smaller
scale, local transformations, we will investigate adding domain-specific
programming support.  This support would allow programmers to write
transforms quickly at an easy-to-understand and high level
abstraction.  It would also ensure that the output transformations are
proper inverses of the inputs.  In particular, inspired by recent work
by Foster et al.~\cite{foster+:lens}, we will explore how to develop a
library of {\em combinators}, simple composable functions, that can be
combined in a myriad of ways to produce the transforms {\em and their
inverses} at the same time.  Foster et al. used such bi-directional transforms to
solve a synchronization problem on error-free tree-shaped data. 
While we will exploit some of their
ideas, our application and
context are different: we are parsing, transforming, querying, archiving
and presenting system monitoring data.
As we do so, we are specifically interested in uncovering,
representing and handling error-filled data.  One of the critical
challenges for us will be to design the combinators so that they deal
with \pads{} parse descriptors correctly
and conveniently.

