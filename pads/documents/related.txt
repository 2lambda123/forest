Pads Related Work

------------------------------------------------------------------------------

Parsing Expression Grammars:
A Recognition-Based Syntactic Foundation 
Bryan Ford
POPL 04

-- PEGs combine CFG-like and regular-expression-like commands with
predicates.  However, CFG's use prioritized options like pads that
looks at the first alternative and if succeeds does not look at the
second one.  The RE's are similar -- they are "greedy" and always
except a longest match.  Once an RE match is found, there is no
backtracking even if some future command fails.

-- PEGs have syntactic predicates that allow arbitrary look-ahead
   without consuming any input.  This is sort of like look-ahead
   functions in our arrays??

-- I didn't read the formal analysis.  This appears all set-based as
   opposed to translation-based.

-- related work mentions extensions of CFGs we might want to
   investigate:

Many extensions and variations of context-free grammars have been
developed, such as indexed grammars [2], W-grammars [28], affix
grammars [13], tree-adjoining grammars [12], minimalist grammars [24],
and conjunctive grammars [18]. Most of these extensions are motivated
by the requirements of expressing natural languages, and all are at
least as difficult to parse as CFGs.

------------------------------------------------------------------------------

Antlr:  A Predicated-LL(k) Parser Generator
T.J. Parr and R.W. Quong
Software--Practice and experience, Vol 25(7),789-810 (July 1995)

-- Antlr is designed for parsing programming languages.

-- Pads is not designed for parsing programming languages. Pads, the
   system, provides a collection of value-added tools specific for ad
   hoc data as opposed to programming languages.

-- Antlr has parameterized rules and semantic constraints. This is
closely related to pads value parameters and their use in semantic
constraints.  However, error reporting due to violation of a semantic
constraint might be different. In addition, they did not show an
example (in this paper) of using a parameter as part of a parsing
directive (as opposed to just part of a constraint). For instance, we
can write as type that is parameterized over the separator in an
array:

type myintarray(x:char) = Puint32 array(x,'\n')

It is not obvious from the paper that the above specification can be
written in Antlr

It also does not appear that Antlr has any analog of type
parameters. The analogue of a type parameter would be a higher-order
non-terminal that took another non-terminal as a parameter, or
something like that (potential research topic: what is a higher-order
CFG and would one be useful?).

-- antlr has nondeterministic choice and pads does not.

-- antlr is LL(k) and pads is LL(1) (correct, Kathleen?) They show
   examples in which k > 1 is useful for parsing programming
   languages.

-- antlr semantic predicates can be used to implement pads switched
   unions

-- antlr has automatic error reporting mechanisms via an "error
   exception mechanism" that allows users to write code to respond to
   parsing errors in line with the parser description. I think this
   could definitely be useful in pads. However, it does not replace
   pads mechanism of pairing error descriptors with representation
   values.

-- if a user annotates the grammar with particular symbols (^ and !,
   which in my initial opinion are hard to read and easy to omit and
   easy screw up) then antler will generate an abstract syntax tree
   for them. Pads appears to have an enormous advantage here:

First, there are a broad collection of base types that do a tremendous
amount of conversions for you. These would all have to be hand coded
in antler. It is not clear to me how these conversions would actually
fit in with the the abstract syntax tree construction. I am sure it is
possible, it just was not clear from the paper.

Second, It appears you need to give a function to tell the system how
to create ast nodes. This is unnecessary in pads. Hence Pads is
simpler to use and more concise. However, specifying the function to
convert to ast nodes may provide some useful flexibility at some
point.

Third, Pads rich type descriptions give rise to internal data
structures with rich types. If you use Antler's mechanism, I am
guessing that all abstract syntax nodes basically have to have the
same type "node" or else you have to construct the abstract syntax by
hand.

Basically, it looked to me like I would not want to ever use Antlr's
automatic syntax tree construction -- I would always do it by hand. On
the other hand, Pads allows you to specify the types and shape of the
internal data structures effectively.

-------------------------------------------------------------------------------
Packrat Parsing: Simple, Powerful, Lazy, Linear Time
Functional Pearl
Bryan Ford

ICFP 02

-- Implementation of Packrat Parsing in Haskell, which is a memoized
recursive descent parsing strategy that dominates LL(k) and LR(k)

-- good related work section

-- Main theoretical ideas found in

[3] Alfred V. Aho and Jeffrey D. Ullman. The Theory of Parsing,
Translation and Compiling - Vol. I: Parsing. Prentice Hall,
Englewood Cliffs, N.J., 1972.
[4] Alexander Birman and Jeffrey D. Ullman. Parsing algorithms
with backtrack. Information and Control, 23(1):1–34, Aug
1973.

but not previously implemented or exploited

-------------------------------------------------------------------------------



