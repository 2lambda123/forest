\section{Performance}
\label{section:performance}

In order to understand the interaction between the layers of our
system as well as the peformance of the system as a whole, we ran
performance measurements at each layer of the corral. All tests were
run on a 1.67 GHz, G4 PowerPC processor, with 500 MB memory, running
Mac OS X 10.3. We performed the tests for two formats, three file
sizes -- 5,10 and 50 megabytes -- and multiple loading strategies
(where appropriate). We started at the bottom of the stack, with the
raw, type-specific parsing functions and measured the time to parse an
entire file. Next, we added a recursive, depth-first walk of the data
through the \padx node representation API (loading the data on demand,
sequentially). In this way, we timed the performance of the
type-specific portion of the \xml interface.  Finally, we used the
\padx concrete data model to traverse the data source.

For the bulk-loading strategy, we found that performance deteriated
for files as small as 20MB, as the system's physical memory was no
longer sufficient to hold all of the data structures. However, our
findings based on the on-demand strategies were more encouraging. At
each stage, we found a linear curve for time vs. file size. For the
first format, we measured $0.13$ {\mu}s per byte, $0.30$ {\mu}s per
byte, and ??? and for the second format, $0.90$ {\mu}s, $1.12$ {\mu}s,
and ???, for the three stages, respectively. For the system as a
whole, we found a constant ratio between stages across file sizes. The
measurements for the two formats differed only in the location of the
curve and the magnitude of the inter-stage ratio.

\begin{verbatim}
dibbler_new:

  |  pads  | node rep | padx concrete ...
--------------------------------------
 5|  .15   | .33      |  
10|  .13   | .31      |
50|  .11   | .29      |

ai:
  | pads  | node rep | padx concrete ...
-------------------------------------
 5|  .91  | 1.24     |  
10|  .90  | 1.13     |
50|  .87  | 1.10     |
\end{verbatim}


\subsection{Querying}

Something about query evaluation:
Although we have not explored custom evaluation plans 
Galax's algebra or optimizer are particularly interesting in the 
\padx{}, we expect to do so 

Give examples of queries that analyst cares about. 

Example of query that can be evaluated in single scan over data
source, but is currently not 

Database person would balk at this point!  Why aren't you just loading
this data into a real database, building indices and getting good
query performance?  B/c data is ephmeral, queries are ephmeral, but
analyst/programmer should profit from disciplined access/querying of
their data.  Don't abandon them to Perl. 
