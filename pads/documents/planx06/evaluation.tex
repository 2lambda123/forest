\section{Performance}
\label{section:performance}

Query performance in \padx{}, as in all query processors, depends on
the efficiency of the underlying \condm{}.  Its performance must be
well understood before it is possible to understand the performance of
particular query plans. We focus on the performance of the \condm{}
and measure the cost of accessing data via the \pads{} type-specific parsing
functions, the \padx{} type-specific node representations, and the
generic \padx{} \condm{}.  At the end of this section, we give preliminary
measurements on query performance.  We measured data model and query
performance for two \pads{} sources: \dibbler{} and the Web server
logs noted in Figure~\ref{figure:data-sources} on data sources of
5-50MB in size.  Our measurements were taken on the
two platforms in Table~\ref{tab:config}. 
\begin{table}
\begin{center}
\begin{tabular}{rl}
% \multicolumn{2}{l}{Platform Configuration} \\ \hline
I:  & G4 PowerPC, 1.67GHz, 500MB memory, Mac OS/X 10.3 \\ 
\\
II: & Intel Pentium M, 1.67GHz, 500MB memory, Linux RH 9.0 \\ 
\end{tabular}
\end{center}
\caption{System configurations}
\label{tab:config}
\end{table}

\subsection{Concrete Data Model} 

\cut{
In order to understand the interaction between the layers of our
system as well as the peformance of the system as a whole, we ran
performance measurements at each layer of the corral. All tests were
run on a 1.67 GHz, G4 PowerPC processor, with 500 MB memory, running
Mac OS X 10.3. We performed the tests for two formats, three file
sizes -- 5, 10, and 50 megabytes -- and multiple loading strategies
(where appropriate). We started at the bottom of the stack, with the
raw, type-specific parsing functions and measured the time to parse an
entire file. Next, we added a recursive, depth-first walk of the data
through the \padx node representation API (loading the data on demand,
sequentially). In this way, we timed the performance of the
type-specific portion of the \xml{} interface.  Finally, we used the
\padx{} concrete data model to traverse the data source.}


We first measured the time to bulk load data sources of 5, 10, and
20MB in size by calling the \pads{} parsing functions directly, \ie{}
the lowest level in the \padx{} data model.  Table~\ref{tab:bulk}
gives the load time per byte in microseconds ($\mu$s).  Note that the
load time is not linear.... why?
\begin{table}
\begin{center}
\begin{tabular}{c|r|r}
           & \multicolumn{1}{c|}{Data}  & \multicolumn{1}{c}{\pads{}} \\
Source     & \multicolumn{1}{c|}{size}  & \multicolumn{1}{c}{read} \\ \hline
           &  5MB  &      \\
\dibbler{} & 10MB  &      \\
           & 20MB  &      \\ \hline

           &  5MB  &      \\
Web server & 10MB  &      \\
           & 20MB  &      \\
\end{tabular}
\end{center}
\caption{Bulk strategy: load time per byte in $\mu$s}
\label{tab:bulk}
\end{table}

\cut{For the bulk-loading strategy, we found that performance deteriated
for files as small as 20MB, as the system's physical memory was no
longer sufficient to hold all of the data structures. However, our
findings based on the on-demand strategies were more encouraging. At
each stage, we found a linear curve for time vs. file size. For the
first format, we measured $0.13$ {$\mu$}s per byte, $0.30$ {$\mu$}s per
byte, and ??? and for the second format, $0.90$ {$\mu$}s, $1.12$ {$\mu$}s,
and ???, for the three stages, respectively. For the system as a
whole, we found a constant ratio between stages across file sizes. The
measurements for the two formats differed only in the location of the
curve and the magnitude of the inter-stage ratio.}

Next, we measured the time to load using the sequential stategy on sources of 5, 10, and
50MB in size.  We want to know the cost

 by calling the \pads{} parsing functions directly, \ie{}
the lowest level in the \padx{} data model.  Table~\ref{tab:bulk}
gives the load time per byte in microseconds ($\mu$s).  Note that the
load time is not linear.... why?
\begin{table}
\begin{center}
\begin{tabular}{c|r|r|r|r}
           &                            &                      &  \multicolumn{1}{c|}{\padx{}}   &  \multicolumn{1}{c}{\padx{}} \\
           & \multicolumn{1}{c|}{Data}  & \multicolumn{1}{c|}{\pads{}} & \multicolumn{1}{c|}{node}&  \multicolumn{1}{c}{concrete} \\
Source     & \multicolumn{1}{c|}{size}  &  \multicolumn{1}{c|}{read}   & \multicolumn{1}{c|}{rep} &  \multicolumn{1}{c}{DM}  \\ \hline
           &  5MB  &  0.15   & 0.33    & 3.87 \\
\dibbler{} & 10MB  &  0.13   & 0.31    & 3.82 \\
           & 50MB  &  0.11   & 0.29    & 3.90\\ \hline
           &  5MB  &  0.91   & 1.24    & 5.33 \\
Web server & 10MB  &  0.90   & 1.13    & 5.11 \\
           & 50MB  &  0.87   & 1.10    & 5.07 \\
\end{tabular}
\end{center}
\caption{Sequential strategy: load time per byte in $\mu$s}
\label{tab:linear}
\end{table}

\subsection{Materialization and Querying}

Something about query evaluation:
Although we have not explored custom evaluation plans 
Galax's algebra or optimizer are particularly interesting in the 
\padx{}, we expect to do so 

Give examples of queries that analyst cares about. 

Example of query that can be evaluated in single scan over data
source, but is currently not 

Database person would balk at this point!  Why aren't you just loading
this data into a real database, building indices and getting good
query performance?  B/c data is ephmeral, queries are ephmeral, but
analyst/programmer should profit from disciplined access/querying of
their data.  Don't abandon them to Perl. 


\cut{
% File sizes:
% -rw-r--r--  1 yitzhakm  yitzhakm   4999890 29 Sep 13:41 ai.5MB
% -rw-r--r--  1 yitzhakm  yitzhakm   9999780 28 Sep 20:57 ai.10MB
% -rw-r--r--  1 yitzhakm  yitzhakm  49999915 28 Sep 20:58 ai.50MB

% -rw-r--r--  1 yitzhakm  yitzhakm   4090277 29 Sep 13:34 dibbler_new.5MB
% -rw-r--r--  1 yitzhakm  yitzhakm   8180541 29 Sep 13:34 dibbler_new.10MB
% -rw-r--r--  1 yitzhakm  yitzhakm  49083181 15 Sep 10:07 dibbler_new.50MB

% Total times:
% dibbler: pads:
% timing$ cat CaS_dibbler_new_5MB_linear.time  CaS_dibbler_new_10MB_linear.time  CaS_dibbler_new_50MB_linear.time 
% 0.617 
% 0.618 
% 0.617 
% 1.031 
% 1.047 
% 1.056 
% 5.330 
% 5.542 
% 5.302 

% dibbler: noderep:
% timing$ cat dibbler_new_5MB_linear.time  dibbler_new_10MB_linear.time dibbler_new_50MB_linear.time 
% 1.341 
% 1.364 
% 1.342 
% 2.505 
% 2.498 
% 2.503 
% 14.106
% 14.144
% 14.361

% dibbler: ocaml walk doc:
% timing$ cat glxwalk_dibbler_new_5MB_linear.time  glxwalk_dibbler_new_10MB_linear.time  glxwalk_dibbler_new_50MB_linear.time 
% 16.014 15.060 0.140
% 15.780 14.820 0.180
% 15.755 14.590 0.240
% 31.463 29.400 0.270
% 31.058 28.940 0.340
% 31.220 28.970 0.380
% 191.903 169.750 1.630
% 191.396 176.160 1.380
% 190.717 174.180 1.510

% ai: pads:
% timing$ cat CaS_ai_5MB_linear.time  CaS_ai_10MB_linear.time  CaS_ai_50MB_linear.time 
% 4.527 
% 4.535 
% 4.542 
% 9.134 
% 8.834 
% 8.883 
% 43.451
% 43.350
% 43.355

% ai: noderep:
% timing$ cat ai_5MB_linear.time  ai_10MB_linear.time ai_50MB_linear.time 
% 6.033 
% 5.686 
% 6.904 
% 11.233
% 11.363
% 11.200
% 55.172
% 55.256
% 55.175

% ai: ocaml walk doc:
% timing$ cat glxwalk_ai_5MB_linear.time  glxwalk_ai_10MB_linear.time  glxwalk_ai_50MB_linear.time 
% 27.580 24.430 0.310
% 26.241 24.060 0.270
% 26.187 23.910 0.410
% 50.917 47.440 0.580
% 50.973 47.890 0.520
% 51.511 48.140 0.430
% 252.543 237.150 1.860
% 254.043 238.870 1.590
% 253.771 234.570 2.210

}