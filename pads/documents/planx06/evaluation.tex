\section{Performance}
\label{section:performance}

\subsection{Materialization and Loading}

% Connect scalability to the "multiple entry point parsing routines" in
% Sec 2:
% \begin{itemize}
% \item galax has a "virtual random-access view" of the XML
%   source. Interface to PADX does not reveal details of how and when
%   data is loaded. The interface puts no restrictions on access.
% \item Indeed, \padx{} can supply a real random-access view of the data but at a
%   high cost. Can prefetch entire data source into memory, but then
%   depend on VM system to manage any overflows. Call this prefetch {\em
%     bulk load}.
% \item Problems crop up early due to quantity of data generated (on
%   average) per byte.
% \item Therefore, bulk reading will only work for the smallest of
%   data sets.
% \item This drawback is not a flaw in the system, but an intentionally
%   chosen point in the design space. The parsing libraries were never
%   intended to be used that way. Instead, \pads model is for programmer
%   to use multiple entry points to control the parsing to produce
%   manageable quantities of data. \pads generates a lot of meta data
%   and lets programmer filter as desired.
% \item Unfortunately, requires much programmer involvement. We want to
%   capitilize on this behaviour, but automatically, without requiring
%   any more involvement by Galax than what is already provided in
%   interface. so we use the libraries as intended by reading
%   sequentially and maintaining just enough state to satisfy
%   Galax. That is, we take advantage of multiple entry points provided,
%   but in an automatic way.
% \item In fact, the automatic nature of the \padx memory management,
%   offers a value-added tool to even the ``pure'' \pads
%   programmer. However, the memory management layer is not free, as we
%   now examine in more detail.
% \end{itemize}

The \padx \absdm provides \galax with a random-acces view
of the underlying data source. The essential, \cd{kth\_child} calls
can be made in any order on a particular node, and any node can be
accessed individually at any time, regardless of its place in the
document. In addition, there are no parameters in the interface
specfiying when or how data is loaded.

This level of abstraction allows the \padx implementation (the
concrete data model) to decide when and how to load data.  \padx can
support the random-acccess view with true random access to the data by
prefetching the entire data source into memory, before any calls to
the \padx \absdm are made. We call this approach {\em bulk loading}.
Indeed, bulk loading is the simplest approach to data materialization.
Unfortunately, it can also be quite costly.  As long as the entire
data source along with its \pads meta-data fit comfortably in memory,
prefetching is cost-effective. However, once the memory requirements
push on the virtual memory system, performance plummets.

The question, then, is how often do we have to worry about data
sources hogging memory. The answer, unforunately, is quite often.
Problems crop up early due to quantity of data that \pads generates
(on average) per byte. Therefore, bulk loading is only practical for
the smallest of data sets.

This restriction, however, should not be seen as a flaw in \pads, but
an intentionally chosen point in the design space. The generated
parsing libraries were never intended to be used for bulk loading
large data sources. Instead, the \pads model is for the programmer to
use the multiple entry points of the generated parsing library to
parse manageable quantities of data at at time. \pads generates a lot
of meta data and lets the programmer filter it as desired.

Unfortunately, this model requires a great deal of programmer
involvement. We need a way to load data according to the \pads model,
but automatically, without requiring any more involvement by Galax
than what is already provided in interface. To accomplish this, we
build a layer of data loading ``intelligence'' between \galax and the
\padx parsing library.  This layer uses the library as intended by
keeping a fixed amount of data in memory at any point, and loading
new data upon request from \galax.

However, for performance reasons, we provide two implementations of
the loading-management layer. The first is semantically true to the
bulk loading mechanism, supporting random access to the data. {\em
  details}.System preserves meta-data about previously read records,
but re-uses memory for reading next item.  This rep permits multiple
scans of input (semantic problem is that DM must preserve node
identity), but slowly. Does not work for read once data that can't be
``rewound'' such as live streams.

The second approach is an optimization of the first. It too maintains
a fixed amount of storage space (one record) and loads on demand. However, it
supports strictly sequential access -- neither skipping ahead, nor
rewinding is allowed. {\em should note here that this last option is
  not fully implemented. macros exist, but compiler doesn't spit out
  function definitions.}   Many common queries permit sequential,
  streamed access to underlying XML source.  Give an example.

In sum, the following three data loading schemes are supported by \padx:

\begin{enumerate}
\item Bulk loading: Materialize entire PADS representation, populate all
  of the \pads reps. Build \padx \condm upon memory-resident data.

\item On-demand sequential loading: Keep storage for one record. Read
  records on demand into single memory slot. Strictly sequential.

\item On-demand, random access loading: Store fixed number of records in
  memory at any one time. Allow access to arbitrary records in
  arbitrary order.
\end{enumerate}

Lasagna performance issues (i.e. big picture, not just the one layer):

\begin{itemize}
\item Each level in the data model adds a small constant cost to
  touching the data.
\item The linear reading is indeed linear.
\end{itemize}

\subsection{Querying}

Something about query evaluation:
Although we have not explored custom evaluation plans 
Galax's algebra or optimizer are particularly interesting in the 
\padx{}, we expect to do so 

Give examples of queries that analyst cares about. 

Example of query that can be evaluated in single scan over data
source, but is currently not 

Database person would balk at this point!  Why aren't you just loading
this data into a real database, building indices and getting good
query performance?  B/c data is ephmeral, queries are ephmeral, but
analyst/programmer should profit from disciplined access/querying of
their data.  Don't abandon them to Perl. 

