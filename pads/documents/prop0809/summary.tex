%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \centerline{
% \begin{tabular}{cc}
%           \\[-1ex]
% \multicolumn{2}{c}{Automatic Tool Generation for Ad Hoc Scientific Data} \\
%           & \\[-1ex]
% David Walker (PI)\\
% Princeton University\\[2ex]
% \end{tabular}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph*{Intellectual Merits:} 

Complex networked systems and applications must be {\em monitored} to
proactively find problems, record/archive system health, oversee
system operation, detect malicious processes or security violations
and perform a myriad of other tasks.  
The monitoring infrastructure necessary to perform such tasks should
be able to include embedded sensors that monitor physical processes,
machine-level monitors to manage server infrastructure, intrusion
detection systems that monitor network traffic, and application-level
monitors that can observe applications within a system. Monitoring
should be able to span multiple such systems, spread across a facility
or multiple locations.

Unfortunately, developing and maintaining monitoring
infrastructure is a tremendously difficult, costly and error-prone
enterprise. A substantial part of the problem arises because
the data produced by networked systems and applications is
varied and voluminous, poorly documented and filled
with errors.  Consequently, application developers normally lack the time,
skill or discipline to create robust monitoring tools, and, even if they do,
keeping their tools up-to-date as the underlying applications change
is tedious and time-consuming.  As a
result, complex systems are usually {\em under-monitored}. They can
fail in ways the associated monitoring system cannot observe or help
diagnose, leaving high-value systems vulnerable to a myriad of threats.

The goal of our research is to provide comprehensive, whole-system
monitoring for complex systems
%, which may include legacy software systems and devices, 
without placing impractical demands on system
administrators or application developers.  To achieve this
goal, we will fuse {\em cutting-edge programming language and system
techniques to semi- and/or fully automatically generate monitoring and
anomaly detection tools for complex software}.
To be specific, our core technology will consist of
the following components: (1) a non-intrusive application traffic
sniffer that performs automated data characterization and analysis,
(2) a high-level, domain-specific programming language, called
\pads{}, that allows users to specify the data that monitoring systems
accumulate and present to users, (3) a compiler for \pads{} that will
automatically generate data processing libraries, interfaces and tools
from such specifications, (4) a data format inference engine capable
of automatically generating \pads{} descriptions from
collected data and (5) a scalable monitoring system, CoMon, that can
adaptively present new data sources and allow operators to analyze and
visualize data across multiple domains.

This approach addresses a number of shortcomings of modern monitoring
systems.  First, the \pads{} specification language provides a 
way to create high-level, uniform, easy-to-understand {\em documentation}
of all data processed or transmitted by any system component, 
including legacy components, without having to modify or alter existing
systems or
application in any way.  Second, this documentation is 
{\em executable} --- the
\pads{} compiler will automatically generate a collection of
reliable, secure, and high-performance libraries and interfaces
to perform all low-level data processing tasks such as ingesting
data from multi-source archives, detecting and reporting
errors, gathering statistics, 
transforming data into standard formats and providing
general-purpose programmatic interfaces.  Third, generated
tools are {\em trustworthy} and {\em reliable} -- unlike manually 
implemented tools, there will be no security vulnerabilities due
buffer overruns or other such low-level, manual coding errors.
Fourth, generated tools are {\em evolvable} -- a simple change to
a specification and recompilation will generate new tools for
the modified format.  Fifth, new data with unknown formats can be analyzed
using novel format inference algorithms that automatically generate
candidate specifications.  Users can inspect and if necessary modify
such specifications. Once satisfied, they can invoke the \pads{}
compiler to generate new tools {\em with just the press of a button}.
Sixth, such automatically generated data-processing tools and libraries 
can be linked to the CoMon monitoring
system.  This linkage allows users to query
data, view it graphically, and analyze trends, all in real
time and without having to load a database or configure the system manually.

% as well as all of the
% monitoring components, such as concurrently {\em ingesting/processing}
% data from any number of distributed sources, {\em archiving}
% (self-describing) data for later analysis, {\em querying} data to
% troubleshoot problems, and {\em displaying} statistical data summaries
% so users can monitor system health in real time.

% and automatically generate
% data processing tools, libraries and interfaces that may be linked into
% a comprehensive monitoring framework.  Third, a format inference engine
% will be able to read 
% Automated format inference and parsing of ad-hoc data allows
% application data to be sniffed on the wire, without having to modify
% applications. PADS provides a comprehensive system for describing data
% in its native formats, and automatically generating tools to access
% the data, both for live and archival data. CoMon works with PADS to
% interactively present the data to operators, allowing them to query
% it, view it graphically, and analyze trends on the data, without having
% to provide manual configuration of the database.

% Moving away from manual parsing simplifies the system and provides the
% flexibility and security that hand-written parsers do not.  Given a
% high-level specification, either provided by the operator or inferred
% from the data, PADS will automatically generate a collection of
% reliable, secure, and high-performance libraries as well as all of the
% monitoring components, such as concurrently {\em ingesting/processing}
% data from any number of distributed sources, {\em archiving}
% (self-describing) data for later analysis, {\em querying} data to
% troubleshoot problems, and {\em displaying} statistical data summaries
% so users can monitor system health in real time.  As the system
% changes and evolves, implementers can change the high-level
% specifications and recompile to automatically obtain an improved
% monitoring system.  In addition, since code is automatically
% generated, as opposed to hand-written, it will not contain
% vulnerabilities that make other systems susceptible to buffer
% overflows and related attacks.  Finally, since PADS can describe the
% format of any data source, users will be able to automatically
% generate monitoring tools that interoperate with legacy software,
% data, and devices.  

In summary, this research will combine principled and innovative
language design with high-performance systems engineering, with the
goal of solving pervasive systems monitoring and measurement problems.
It will have an immediate impact on the
productivity of systems implementers by helping produce the next
generation of monitoring systems.


% \paragraph*{Broader Impacts:}  Kathleen Fisher, senior personnel, 
% will work with other researchers at AT\&T to transfer our monitoring
% technology to industry.  In addition, we will develop tools for
% monitoring the health of PlanetLab, a global network research testbed
% with 400-450 nodes and 200-250 network experiments running at any
% given time.  Not only will our troubleshooting and diagnostic tools
% will provide feedback to PlanetLab users and administrators, thereby
% improving PlanetLab as a research facility for the entire networking
% community, but these same tools will easily usable by individual
% researchers to monitor their own experiments on PlanetLab. In effect,
% we can provide a complete system to archive history, analyze data, and
% present demonstrations, all from a simple data description.
% 
% PADS will also make a broad impact outside the networking community.
% The kind of {\em ad hoc data} found in monitoring systems also appears
% across the natural and social sciences, including biology, chemistry,
% physics and economics.  The PADS specification language will be used to
% specify the formats of these other data sources and to generate the
% querying and visualization tools that help improve
% the productivity of computational scientists.  To jumpstart this
% research, we have already been meeting with Olga Troyanskaya,
% professor in Princeton's Lewis-Sigler Institute for Integrative
% Genomics, who does computational analysis of protein-protein
% interactions, and with Rachel Mandelbaum, Ph.D. candidate in physics
% who analyzes cosmology data.  It is clear that if funded, the PADS system
% will make a broad impact on their research --- PADS will free them to use
% their world-class skills on their {\em science} 
% as opposed to labouring over development of data processing tools.
% The collaboration between computer science, genomics and physics will
% also be an excellent platform for developing interdisciplinary
% undergraduate research projects.  The PI has a proven track-record for
% following through with undergraduate and graduate educational plans.
% In 2004 and 2005, he organized NSF-sponsored summer schools on secure
% and reliable computing.  Last year, his undergraduate student advisee,
% Rob Simmons, won the Princeton Computer Science Senior Thesis Award.
% 

\paragraph*{Major Tasks and Subtasks.}
We have four main tasks: (1) PADS compiler development, 
(2) Classification of Live Data, (3) Application Log File Format Inference,
and (4) Monitoring system integration.  Each task has subtasks
(labelled 1.a, 1.b, {\em etc.}) to be completed as follows.

% \begin{itemize}
% \item Task 1 -- PADS compiler development
% \item Task 2 -- Classification of Live Data
% \item Task 3 -- Archival Data Format Inference
% \item Task 4 -- Monitoring system development
% \end{itemize}


\noindent
{\bf Year 1}
\begin{itemize}
\item 1.a PADS implementation: new algorithms for context-free and non-context
free ({\em i.e.,} data dependent) parser and tool generation 
\item 2.a Collection of (live) wire data from networked applications
\item 3.a Collection of (archival) log files from networked applications
\item 2.b/3.b Build library of PADS specifications for common data formats
\item 3.c Developoment of algorithms for format inference for individual
(archival) log files
(builds on experience from inference prototype)
\item 4.a Development of algorithms for automatic configuration of CoMon monitoring system 
from format specifications (builds on experience from CoMon prototype)
\end{itemize}

\noindent
{\bf Year 2}
\begin{itemize}
\item 1.b Design and implementation of specification language for multi-level archives
\item 2.c Development of algorithms for classifying data by application, ports, wire formats
\item 3.d Development of algorithms to scale format inference engine to handle high-volume 
data
\item 4.b Development of algorithms for classification, trending, and 
anomaly detection using live data
\end{itemize}

\noindent
{\bf Year 3}
\begin{itemize}
\item 1.c Development of tool generation infrastructure for multi-level archives
\item 2.d Development of algorithms for entropy-based matching of unknown data to existing formats
\item 3.e Development of algorithms for format inference for multi-level archives
\end{itemize}


