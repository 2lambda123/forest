\section{Complexity Metric}
\label{sec:ComplexityMetric}

The PADS structure has two levels, namely \textit{Base types} and
\textit{structured types}. The base types are already somewhat complex.
Many of the base types are defined using \textit{regular expressions}.
Structured types provide further structure on top of the base types.
Structured types include \textbf{Pstruct}, \textbf{Punion},
\textbf{Parray}, and \textbf{Penum}.

The complexity metric must take into account both the structure
described by the PADS structured types, and the structure inherent in
the base types and their underlying regular expressions. Regular
expressions can be arbitrarily complex, however PADS base types do use
only relatively simple regular expressions. Some of the PADS base
types use a rich variety of these simple regular expressions. For
example, the time base type is based on the C-library \textit{tm}
function, which supports at least 40 kinds of time and data
specification.

To get started, we will make some simplifying assumptions about the
PADS structures, and the underlying regular expressions. We need to
verify that these assumptions match the initial test cases for PADS.

\subsection{Requirements}

\begin{description}

\item [Compositionality over structured types]
The metric must be compositional in terms of the PADS structure.
For example, based on the complexity assigned to each of PADS
types $P_1$, $P_2$, and $P_3$, it should be possible to compute
the complexity for the PADS structure having $P_1$, $P_2$, and $P_3$
as fields.

\item [Compositionality over base types]
The same compositionality that applies to PADS structured types should
apply to PADS base types, and their underlying regular
expressions. Thus the method for composing complexities for a
\textbf{Pstruct} type should be the same as the method for composing
complexities for a sequence of two (or more) regular expressions.

\item [MDL Principle]
The metric must permit trade-offs between the complexity of the
description as a PADS type, and the complexity of the data under
the description. In practice, this means that the complexity metric
should have terms corresponding to different PADS constructs such
as \textbf{Pstruct}, \textbf{Punion}.

\end{description}

\subsection{Simplifying assumptions}

\begin{description}

\item [Pre]
The PADS type \textbf{Pre} permits the specification of any Perl
regular expression. Perl regular expressions are quite complex, and
they are more powerful than regular expressions. This type is not
currently used in the PADS examples, and we do not consider it in the
complexity metric yet.

\item [Limited base types]
As previously noted, some of the base types such as dates and times
make use of a rich variety of formats. We will restrict these formats
to the very limited subset defined in the file \textsf{tokens.lex}.

\item [Limited regular expressions]
It is possible to do a lot of the PADS structuring using regular
expressions. For example the PADS type \textbf{Pstruct} corresponds to
\textit{sequencing} in regular expressions, and the PADS type
\textbf{Punion} corresponds to \textit{selection} in regular
expressions. The PADS base types make some use of selection and
sequencing. For example, in the file \textsf{tokens.lex} a
\textsf{triple} is defined as $[0-9]\{1,3\}$, a sequence of three
numerals. Our assumption is that beyond the base types, sequencing
and selection will be described using the PADS types \textbf{Pstruct}
and \textit{sequencing}.

\item [Match expressions]
Many of the PADS base types can be defined using a regular expression
as a \textit{match expression}. For example, strings can be defined
with a specified regular expression using \textsf{Pstring\_ME}, or with
a compiled regular expression using \textsf{Pstring\_CME}. Similarly,
a date field can be defined using \textsf{Pdate\_ME}. For now, the
computation of the complexity metric will not be defined for fields
with match expressions. As a next step, we can enumerate a limited
style of regular expressions for which we can compute the complexity
metric.

\item [Stop expressions]
The situation for stop expressions is the same as that for match
expressions. A \textit{stop expression} is used to define the extent
of many PADS base types. For example, \textsf{Pstring\_SE} uses a stop
expression to define the conditions under which the string
terminates. For our first complexity metric, we will handle only the
case where a stop expression is a regular expression consisting of a
single character. In this case, the stop expression is a
\textit{stop character}.

\item [PADS constraints]
A \textit{constraint} can occur in many places in the declaration of a
PADS type. The constraint is a Boolean valued function on one or more
PADS types. The boolean function constrains the values of the input
types. Constraints can be used to decrease an entropy metric. At this
time, we do not know an automated method to take advantage of these
constraints in our calculation of the complexity metric. Furthermore,
such constraints are not yet appearing in the PADS types inferred from
sample data. For these reasons, the complexity metric does not yet
support constraints.

\item [PADS predicates]
Predicates can occur in other situations besides constraints. For
example, a \textbf{Parray} can specify a \textbf{Plast} predicate to
determine when an array terminates. If such a \textbf{Plast} is
specified by the user, then the system will use the information to
parse the data. The length frequency statistics (see below) will
reflect the decisions based on the \textbf{Plast} specification. For
now, this is the only influence of the \textbf{Plast} specification on
the complexity metric. We will consider more complete analysis of
\textbf{Plast} and other situations in which predicates can occur in
future versions of the complexity metric.

\end{description}

\subsection{Calculating the metric}

\subsubsection{Basic idea}

The basic idea is to add a probability distribution to each PADS type.
Since many base types are defined from regular expressions, or may take
regular expressions as parameters, this means we need to add a probability
distribution to regular expressions and their components as well as to
PADS structured types.

During the earlier passes of PADS, the type \textsf{Ty} with its
auxiliary information (type \textsf{AuxInfo}) will accumulate
frequencies with each of its component types. During later phases
other auxiliary information will be added to the \textsf{Refined}
type, to define a probility distribution to each type.

We would like to associate a worst case with type, but as we will see
this is not possible for all PADS types.

\subsubsection{Composition rules}

\begin{description}

\item [Fixed Sequence]
A fixed sequence could result from a \textbf{Pstruct} type, a
\textbf{Parray} type, or from sequencing within a regular expression.
In any case, as a first approximation, the complexity of the sequence
$P_0 \cdot P_1 \cdot \ldots \cdot P_n$ is defined as $\prod^n_{j=0} P_j$.
This is a bad approximation in many cases. For example, if a
year is represented as the regular expression \textsf{[0-9]\{1,4\}},
then it is extremely likely that the first two digits of the year will
be either $19$ or $20$.  If the first two digits are $20$, it is
unlikely that the last digit will be $8$ (until next year), and so
on. For this reason, we will want the user to be able to specify that
the elements of a sequence will be considered jointly. Similarly, in
learning mode, the system should be able to note that there are
dependencies between the different elements of the sequence. When
working with the system, the user should be able to guide the system
to group elements of a sequence together, and store frequencies for
the entire sequence, and not for elements of the sequence.

\item [Unbounded iteration]
An unbounded iteration can result from a regular expression, for
example \textsf{[A-Za-z][A-Za-z0-9\_\-]*} is a regular expression for
an alphanumeric string of any finite length. The the PADS base types
for strings can be unbounded. An unbounded iteration can also result
from many of the base types, using either a match expression, or a
stop expression. A \textbf{Parray} can also be given a predicate
defining when the array ends. Note that by \textit{unbounded} we mean
\textit{a priori unbounded}, thus there is no way to predict in
advance how long the data correspondiing to the type will be. One has
to actually look at the data to determine this. For an unbounded
iteration, we will need to determine two kinds of distrbution data.

\begin{description}
\item [length distribution]
In preliminary passes, compute how often each length appears. When few
lengths appear, this is a strong suggestion to use an alternative to
unbounded lenghts. In the refinement phase we would compute one of
at least two possibilities.
\begin{description}
\item [maximum length]
When a maximum length is suggested, we can compute a finite distribution
as for the case of bounded iteration.
\item [median (or mode or mean?) length]
When a mean length is computed, we can compute a distribution that puts
half the weight less than the mean, and half the weight more than the
mean, with a tail that tapers off to infinity.
\end{description}

\item [frequency distribution]
Given a length distribution, it may (or may not) be important to have
a frequency distribution at each length. For example, if a field is a
string, then the data may have many different lengths of string for
that field. It may be that whenever the string is of a certain length,
say 4, that the value is constant, say ``Iraq''. Strings of other
lengths may be more varied. As a default, we should assume that the
strings at each length are uniformly distributed over the possible
values for that length. If the data indicates the values are
concentrated at certain values or in certain ranges, then the
distributtion should indicate that.

\end{description}

\item [Selection]
Selections can occur either as part of a regular expression, or as
part of a PADS type. In PADS, both \textbf{Punion} and \textbf{Penum}
support forms of selection. In regular expressions, the selection
operator is the vertical bar \textsf{|}. As a default, we should
assume that each branch of the selection is equally likely. For more
fine tuning, the user should be able to specify a weight for each
branch, and during data analysis, the system should be able to assign
a frequency to each branch of the selection.

\end{description}

\subsubsection{Base rules}

How to assign distributions to the PADS base types is discussed here ******.

\subsection{Sensitivity to data}

How some types require data to assign a distribution is discussed here *****.

\begin{figure}
\label{fig:Parray1}
\begin{verbatim}
Parray nIP {
  Punit8 [4] : Psep('.') && Pterm(' ');
};
\end{verbatim}
\caption{Bounded iteration using \textbf{Parray}}
\end{figure}

\subsection{Eventual treatment of regular expressions}

Regular expressions turn out to be equivalent to \textit{sofic shifts}
\footnote{See \textit{An introduction to Symbolic Dynamics} by
Douglas Lind and Brian Marcus}. Sofic shifts have a graph representation,
and in turn this graph representation corresponds to an
\textit{adjacency matrix}. Using the Perron-Frobenius theorem,
we can calculate the \textit{entropy} of an adjacency matrix by
computing its largest positive eigenvalue. This entropy is the same as
that defined as Shannon entropy, source entropy, metric entropy,
topological entropy, Shift of Finte Type (SFT) entropy, Kolmogorov
complexity, and Galois entropy (formally similar to thermodynamic
entropy, measures size of an orbit of an element of a group). This is
likely to be the best complexity metric for regular expressions.  To
compute it, we will need an algorithm that turns a regular expression
into a graph (see for example
\url{http://www.unix6.com/prom/SHELL/200610/2672.html}).
From the graph we can compute the adjacency matrix and then the
entropy.
