\section{Token Ambiguity Problem} \label{sec:examples}
\cut{
\begin{verbatim}
- example text
- describe where the examples come from, what the data is 
  (could be) used for
- show description written by hand (ideal case)
- show description from old learning system, which is verbose 
  and bad
  - explain why it's verbose and bad
\end{verbatim}
}
\begin{figure}[t]
\begin{center}
{\small
\begin{verbatim}
May 02 06:19:57 Updated: openssl.i686 0.9.7a-43.8
Jul 16 12:37:13 Erased: dhcp-devel
Jul 16 12:37:13 Erased: dhcpv6_client
Dec 10 04:07:51 Updated: openldap.x86_64 2.2.13-4
Dec 10 04:07:52 Updated: util-linux.x86_64 2.12a-16.EL4.12
Dec 10 04:07:58 Updated: nss_ldap.x86_64 226-10
Dec 10 04:07:58 Updated: shadow-utils.x86_64 2:4.0.3-58.RHEL4
Dec 10 04:11:17 Installed: postgresql-libs.x86_64 7.4.8-1.RHEL4.1
Dec 10 04:11:27 Installed: fonts-xorg-75dpi.noarch 6.8.1.1-1.EL.1
\end{verbatim}
}
\end{center}
\caption{Fragment of {\tt yum.txt} log file} \label{fig:yum}
\end{figure}

\begin{figure}[t]
\begin{minipage}[t]{0.5\columnwidth}
\begin{code}
Penum action \{
  install Pfrom("Installed");
  update Pfrom("Updated");
  erase Pfrom("Erased");
\};
Pstruct version_hdr \{
  Pint major; ':';
\}
Pstruct sp_version \{
  ' ';  
  Popt version_hdr h_opt;
  \kw{Pid} version;
\}
\end{code}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\columnwidth}
\begin{code}
Precord Pstruct entry_t \{
        \kw{Pdate} date;	
  ' ';  \kw{Ptime} time;	
  ' ';  action m; 	
  ": "; \kw{Pid} package;	
        Popt sp_version sv;
\};
Psource Parray yum \{
        entry_t[];
\};
\end{code}
\end{minipage}
\caption{Ideal \pads{} description of {\tt yum.txt}}\label{fig:yum-gold}
\end{figure}


In this section, we introduce the token ambiguity problem through
a real-life ad hoc data source, and motivate a new probablistic approach
to solve this problem. Many other ad hoc data sources with similar
problem exist and more examples can be found on the \pads{} web site \cite{padsweb}.

Fig. \ref{fig:yum} shows a fragment from a log file, {\tt yum.txt},
which is written by a software package manager called {\tt yum}. {\tt yum} 
is a tool for installing, updating and removing packages and dependencies
on RPM-based systems. 
Each line in yum.txt is a unit of
repetition in the data source and we call it a {\em chunk} or
a {\em record}. A data chunk could be a line of data, a block of data or
even a file, depending on the data source.
The data chunk in {\tt yum.txt} consists of several distinct fields: 
date, time, action taken,
package name and version. The fields are separated by single spaces.
This file is used by system administrators to keep track of the
software updates on the system. 
Fig.\ref{fig:yum-gold} shows an {\em ideal} \pads{} description of
{\tt yum.txt} written by a human expert.
The {\tt entry\_t} type describes one chunk in the data source, and is
denoted with the keyword {\tt Precord}. 
{\tt Pdate} stands for a date type, {\tt Ptime} stands for a time type,
action type is defined to an enumeration of three different actions,
and {\tt Pid} matches a system identifier such as a file
name, a MAC address, etc. Types such as {\tt Pdate} and {\tt Pid}
are called {\em base types} that represent a single token 
in \pads{}; types such as {\tt Pstruct}, {\tt Penum} and {\tt Popt} are 
intermediate types that represent
structures. We highlight all the base types in the \pads{} description. 

\begin{figure}[t]
{\tiny
\begin{minipage}[t]{0.33\columnwidth}
\begin{verbatim}
#include "vanilla.p"
Penum Enum_10 {
	Installed10 Pfrom("Installed"),
	Updated10 Pfrom("Updated"),
	Erased10 Pfrom("Erased")
};
Popt Pstring_ME(:"/\\+\\+/":) Opt_22;
Penum Enum_31 {
	x86_6431 Pfrom("x86_64"),
	noarch31 Pfrom("noarch"),
	i68631 Pfrom("i686"),
	i38631 Pfrom("i386")
};
Pstruct Struct_53 {
	PPstring  v_string_49;
	'.';
};
Popt Struct_53 Opt_55;
Pstruct Struct_56 {
	PPip  v_ip_42;
	'.';
	Opt_55  v_opt_55;
};
Popt Struct_56 Opt_40;
Pstruct Struct_59 {
	Opt_40  v_opt_40;
	Pint64  v_int_57;
};
Popt Struct_59 Opt_60;
Punion Union_66 {
	v_stringconst_63 Pfrom(".");
	v_stringconst_68 Pfrom(":");
	v_stringconst_73 Pfrom("_");
};
Pstruct Struct_78 {
	Union_66  v_union_66;
	Pint64  v_int_76;
};
Parray Array_35 {
	Struct_78[] : Plongest;
};
Popt PPip Opt_83;
Penum Enum_106 {
	centos4106 Pfrom("centos4"),
	rhel4106 Pfrom("rhel4"),
	RHEL4106 Pfrom("RHEL4"),
	pre5106 Pfrom("pre5"),
	rc1106 Pfrom("rc1"),
	p23106 Pfrom("p23"),
	el4106 Pfrom("el4"),
	EL4106 Pfrom("EL4"),
	c4106 Pfrom("c4"),
	EL106 Pfrom("EL")
};
Pstruct Struct_110 {
	Enum_106  v_enum_106;
	'.';
};
Popt Struct_110 Opt_112;
Pstruct Struct_100 {
	'.';
	Opt_112  v_opt_112;
};
\end{verbatim}
\end{minipage}
\begin{minipage}[t]{0.33\columnwidth}
\begin{verbatim}
Punion Union_113 {
	v_stringconst_95 Pfrom("E.");
	Struct_100  v_struct_100;
};
Pstruct Struct_116 {
	Union_113  v_union_113;
	Pint64  v_int_114;
};
Parray Array_89 {
	Struct_116[] : Plongest;
};
Penum Enum_133 {
	centos4133 Pfrom("centos4"),
	rhel4133 Pfrom("rhel4"),
	RHEL4133 Pfrom("RHEL4"),
	ent133 Pfrom("ent"),
	el4133 Pfrom("el4"),
	EL4133 Pfrom("EL4"),
	c4133 Pfrom("c4"),
	EL133 Pfrom("EL")
};
Penum Enum_144 {
	centos4144 Pfrom("centos4"),
	kb144 Pfrom("kb")
};
Pstruct Struct_146 {
	'.';
	Enum_144  v_enum_144;
};
Popt Struct_146 Opt_140;
Pstruct Struct_126 {
	'.';
	Enum_133  v_enum_133;
	Opt_140  v_opt_140;
};
Penum Enum_150 {
	nonptl150 Pfrom("nonptl"),
	EL4150 Pfrom("EL4")
};
Pstruct Struct_152 {
	'_';
	Enum_150  v_enum_150;
};
Punion Union_121 {
	Struct_126  v_struct_126;
	Struct_152  v_struct_152;
	PPstring  v_string_123;
	Pempty;
};
Pstruct Struct_154 {
	Opt_60  v_opt_60;
	Array_35  v_array_35;
	Opt_83  v_opt_83;
	'-';
	Pint64  v_int_91;
	Array_89  v_array_89;
	Union_121  v_union_121;
};
Popt PPstring Opt_163;
\end{verbatim}
\end{minipage}
\begin{minipage}[t]{0.33\columnwidth}
\begin{verbatim}
Penum Enum_174 {
	string174_0 Pfrom("CENTOS-0"),
	string174_1 Pfrom("p1-8"),
	string174_2 Pfrom("a-43"),
	string174_3 Pfrom("a-33"),
	string174_4 Pfrom("a-16"),
	string174_5 Pfrom("a-3")
};
Popt Enum_174 Opt_178;
Pstruct Struct_179 {
	Pint64  v_int_172;
	Opt_178  v_opt_178;
};
Penum Enum_182 {
	centos4182 Pfrom("centos4"),
	RHEL4182 Pfrom("RHEL4"),
	string182_2 Pfrom("EL-1"),
	EL4182 Pfrom("EL4")
};
Punion Union_180 {
	Struct_179  v_struct_179;
	Enum_182  v_enum_182;
};
Parray Array_156 {
	Union_180[] : Psep('.') && Plongest;
};
Pstruct Struct_223 {
	Pint64  v_int_158;
	Opt_163  v_opt_163;
	'.';
	Array_156  v_array_156;
};
Punion Union_155 {
	Struct_154  v_struct_154;
	Struct_223  v_struct_223;
};
Pstruct Struct_205 {
	Opt_22  v_opt_22;
	'.';
	Enum_31  v_enum_31;
	' ';
	Union_155  v_union_155;
};
Popt Struct_205 Opt_206;
Precord Pstruct Struct_219 {
	PPdate  v_date_1;
	' ';
	PPtime  v_time_6;
	' ';
	Enum_10  v_enum_10;
	": ";
	PPstring  v_string_17;
	Opt_206  v_opt_206;
};
Psource Parray entries_t {
	Struct_219[];
};
\end{verbatim}
\end{minipage}
}
\cut{ %%%%%%%%%%%%%%%%%%%%%%% 
\begin{centercode}
Penum Enum_10 \{
  Installed10 Pfrom("Installed"),
  Updated10 Pfrom("Updated"),
  Erased10 Pfrom("Erased")
\};
Popt \kw{Pstring_ME}(:"/\\+\\+/":) Opt_22;
Penum Enum_31 \{
  x86_6431 Pfrom("x86_64"),
  noarch31 Pfrom("noarch"),
  i68631 Pfrom("i686"),
  i38631 Pfrom("i386")
\};

... /* Complex definition of types 
       Struct_154 and Struct_233 
       (\kw{141 lines of code}) ommitted */

Punion Union_155 \{
  Struct_154  v_struct_154;
  Struct_223  v_struct_223;
\};
Pstruct Struct_205 \{
       Opt_22  v_opt_22;
  '.'; Enum_31  v_enum_31;
  ' '; Union_155  v_union_155;
\};
Popt Struct_205 Opt_206;
Precord Pstruct entry_t \{
        \kw{Pdate}  v_date_1;
  ' ';  \kw{Ptime}  v_time_6;
  ' ';  Enum_10  v_enum_10;
  ": "; \kw{Pword} v_string_17;
        Opt_206  v_opt_206;
\};
Psource Parray entries_t \{
        entry_t[];
\};

\end{centercode}
}%%%%%%%%%%%%%%%%%%%%%%%
\caption{\pads{} description of {\tt yum.txt} inferred by the original \learnpads}\label{fig:yum-bad}
\end{figure}

In comparison, we show the description of {\tt yum.txt} infered by
the original \learnpads{} system \cite{fisher+:dirttoshovels,fisher+:sigmod08}
in Fig. \ref{fig:yum-bad}. 
This description, despite being able to correctly parse the original data,
is very verbose and un-intuitive. It is whopping 179 line long compared 
to the neat 23-liner written by the human expert.

The main problem with the inferred description is that it 
did not take advantage of the {\tt id} token, but instead 
use simpler tokens such as {\tt word}, {\tt int}, etc,
to represent the package names and version numbers. 
This introduced the complex structure within the package names 
and versions into the description. 

The question is, why didn't the old inference algorithm use
the {\tt id} token? It turns out that the definition of a complex token
like {\tt id} includes that of other simple tokens in the system such as 
{\tt word} and {\tt int}. This gives rise to the 
{\em token ambiguity problem} (TAP), which is, given an input
string, there are multiple ways of parsing it.
TAP occurs in numerous places in {\tt yum.txt}. 
For instance, the string ``{\tt 2.2.13-4}'' can be parsed into one of 
these possible sequences:
{\small
\begin{verbatim}
Option 1: [int] [.] [int] [.] [int] [-] [int]
Option 2: [float] [.] [int] [-] [int]
Option 3: [int] [.] [float] [-] [int]
Option 4: [id]
\end{verbatim}
}

Similarly, the string ``{\tt Dec 10 04:07:51}'' can be interpreted as, 
among other choices, any of these token sequences:

{\small
\begin{verbatim}
Option 1: [word] [' '] [int] [' '] [int] [:] [int] [:] [int]
Option 2: [month] [' '] [int] [' '] [time]
Option 3: [date] [' '] [time]
\end{verbatim}
}

The original inference algorithm disambiguates the overlapping
tokens by attempting each defined tokens in some order 
and picking the {\em first} matched token to parse the string. 
While effective for some data sources, this simple policy 
is not ideal because
\begin{itemize}
\item it makes a black-and-white decision for the tokenization up front;
\item it does not take into account of contextual information when picking
      a token to parse a substring; and
\item it restricts the use of some complex tokens because they ``overshadows''
	some of the simpler tokens.
\end{itemize}

To tackle the above limitations, in the next section, we will propose
a revised inference algorithm that 
\begin{itemize}
\item assigns probability to each possible token sequence;
\item defers the decision of tokenization, and makes the decision 
      incrementally as the structure is constructed; and
\item takes the context into account when deciding which tokens to use.
\end{itemize}

