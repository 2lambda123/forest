\section{Related Work}
\label{sec:related}

There are many useful tools designed to help programmers generate
parsers.  Examples include compiler technology such as the many
variants of Lex and Yacc as well as interpreter technology such the
parser combinator libraries found in functional programming languages
(Haskell~\cite{hutton+:parser-combinators}, for example).  Likewise,
there are tools to help programmers generate printers.  Each of these
technologies are very useful in their own domain, but none of them
could possibly be substituted for \padsml{}.  A key difference is that
a single \padsml{} description is sufficient to generate a large
collection of useful data processing tools including a parser, a
printer, a statistical error analysis, a format debugger, an \xml{}
translator, and in the future, a query engine~\cite{fernandez+:padx},
a content-based search engine~\cite{lv+:cbs,oh:siw}, more statistical
analysis, etc.  Though we chose a compiled solution, a parser or
printer combinator library might have served as an alternative
implementation strategy for certain individual components of our tool
suite.  However, by themselves, parser or printer combinator
libraries, \lex{} or \yacc, are not properly architected to give the
same, simple and powerful user experience as \padsml{}, which can be
summed up through the motto ``one declarative description; many
reliable tools.''

% A second way to characterize some of the differences between parser
% technologies is to recognize that \padsml{} is higher level (leaving
% out semantic actions, thereby making descriptions relatively simpler
% and enabling post facto tool implementation) and more domain specific
% (generating tools useful for processing ad hoc data, such as the
% \xml{} translator and statistical analysis, but not particularly
% useful for programming language implementation, for instance).  There
% are also many technical differences between the parsing technologies
% but we believe these are less important than the high-level vision.

Generic
programming~\cite{jeuring+:polytypic-programming,hinze+:generic-programming,lammel+:syb}
and design patterns such as the visitor are technologies that can
facilitate the implementation of type-directed data structure
traversals.  Lammel and Peyton Jones' original ``scrap your
boilerplate'' article~\cite{lammel+:syb} provides a detailed summary
of the trade-offs between different techniques.  We investigated using
one of these techniques before implementing the generator for
\padsml{} traversal functors from scratch.  However, we found most
advanced techniques for functional programming languages required
features such as type classes that are only present in variants of
Haskell.  The generated \padsml{} traversal functors are less flexible
than some of these traversal techniques, but they suffice for helping
us program the tools we have implemented, and for many more tools for
ad hoc data we are considering implementing.  On the other hand, we
have not seen type directed programming techniques developed for
systems of dependent types similar to the \padsml{} dependent type
structure.  
% However, to summarize the central differences between
% generic programming and \padsml{}, generic programming is a powerful
% {\em implementation technique} which can be used to implement many
% programs, including some of the programs generated from a \padsml{}
% description.  \padsml{}, however, is a higher-level system that
% directly provides a simple and powerful user experience for analysts
% who need to parse, print, process or transform ad hoc data.


%Again, the phrase ``one declarative description; many 
%reliable tools'' is a concise summary of \padsml{} goals.

% As with parser and printer
% combinator libraries, eview generic programming techniques as an
% implementation technique


% are two other closely-related 
% technologies that, like parser or printer generators, might have
% been used as implementation components for parts of the \padsml{} system.
% Indeed, before beginning our implementation we investigated these technologies
% to see whether or not they would apply in our context.  Unfortunately,
% all the work we are aware of is quite specific to Haskell.  For instance,
% Hinze's "Generics for the Masses"~\cite{hinze+: improves upon a number of
% previous efforts because he "only" requires Haskell 98, not Haskell 98
% with extensions.
  
% There are also a number of technical differences in the parsing
% technology that \padsml{} uses (particularly 
% the dependent types, critical for many
% ad hoc data formats but unavailable in Yacc)
% By generating
% parsers and printers together \padsml{} also provides a very convenient
% framework for programmers to implement their own format translators




% It is possible to generate any number of tools from
% a single \padsml{} type because the type is 
% limited to describing properties of the data.
% The descriptions themselves do not contain an 
% algorithmic component similar to the semantic actions found in Yacc
% or the associated functional parameters 
% a The \padsml{} architecture is designed

% A parser or printer combinator library might have been helped
% us implement the specific components of the

% Some of the oldest tools for describing data formats are parser
% generators for compiler construction such as
% Lex and Yacc.  While excellent for parsing programming languages, Lex and Yacc
% are too heavyweight for parsing many of the simpler ad hoc data formats that
% arise in networking, the computational sciences, finance, \etc{}   
% In addition, Lex and Yacc do not support data-dependent parsing, 
% do not generate internal representations automatically, 
% and do not supply a collection of value-added tools such as
% \padsml's \xml{} translator.

% More modern compiler construction tools alleviate
% several of the problems of Lex and Yacc by providing more
% built-in programming support.  For instance,
% the ANTLR parser generator~\cite{antlr} allows the user to add
% annotations to a grammar to direct construction of a parse tree.
% Demeter's class dictionaries~\cite{lieberherr+:class-dictionaries}
% can generate parsers that construct internal parse trees
% as well as traversal functions, much like the traversal functions
% generated by \padsml.  However, these tools do not have dependent
% and polymorphic data descriptions or a formal semantics.  Moreover,
% they were designed for imperative and object-oriented languages 
% as opposed to strongly typed functional languages like \ml{}.

The networking community has developed a number of domain-specific
languages, including PacketTypes~\cite{sigcomm00},
DataScript~\cite{gpce02} and Bro's~\cite{paxson:bro} packet processing
language for parsing and printing binary data.  Like \padsml{}, these
languages use a type-directed approach to describing ad hoc data and
permit the user to define semantic constraints.  In contrast to our
work, these systems handle only binary data and assume the data is
error-free or halt parsing if an error is detected. DFDL is a data
format specification language with an XML-based syntax and type
structure~\cite{dfdl-proposal,dfdl-primer}. At this stage in its
development, it appears DFDL remains a language specification; a tool
generation architecture has not yet been developed. We believe that
DFDL is similar in its expressiveness to \padsc{}.  However, because
the specification is still under development, we cannot give a more
detailed comparison at this point.

A somewhat different class of languages includes
\textsc{ASN.1}~\cite{asn} and \textsc{ASDL}~\cite{asdl}.  Both of
these systems specify the {\em logical\/} in-memory representation of
data and then automatically generate a {\em physical\/} on-disk
representation.  This technology does not help process data that
arrives in predetermined, ad hoc formats.

There are a number of tools designed to deal with converting ad hoc
data formats into \xml{} and various related tasks, including
XSugar~\cite{brabrand+:xsugar2005} and the Binary Format Description
language (BFD)~\cite{bfd}. The scope of both of these projects is
limited to conversion to-and-from \xml{}, and neither seek to provide
programmers with access to the raw data, nor produce a broad suite of
data processing tools.

% There are probably hundreds of tools that one might use if their data were
% in \xml.  However, the point of PADS is to allow scientists whose data is {\em not}
% already in \xml to get work done, particularly when that data contains errors,
% as ad hoc data often does.  Since many processes, machines, programs and other devices
% currently output data and a whole most of

Commercial database products provide support for
parsing data in external formats so the data can be imported into
their database systems, but they typically support a limited number of
formats.  Also, no declarative description of the
original format is exposed to the user for their own use, and they
have fixed methods for coping with erroneous data.  For these reasons,
\padsml{} is complementary to database systems.  

On the theoretical front, the scientific community's understanding of
type-based languages for data description is much less mature.  To the
best of our knowledge, our previous work on the
DDC~\cite{fisher+:next700ddl} was the first to provide a formal
interpretation of dependent types as parsers and to study the
properties of these parsers including error correctness and type
safety.  The current paper extends and improves our earlier work by
simplifying the basic theory in a number of subtle but important ways
and by adding polymorphic types for the purpose of code reuse.
Regular expressions and context-free grammars, the basis for Lex and
Yacc have been well-studied, but they do not have dependency, a key
feature necessary for expressing constraints and parsing ad hoc
scientific data.  {\em Parsing Expression Grammars} (PEGs), studied in
the early seventies~\cite{birman+:parsing}, revitalized more recently
by Ford~\cite{ford:pegs} and implemented using ``packrat parsing''
techniques~\cite{ford:packrat,grimm:packrat}, are somewhat more
similar to \padsml{}'s recursive descent parsers. However, our
multiple interpretations of types in the DDC makes our theory
substantially different from the theory of PEGs.

% {\em PEG difference: not just dependency, but error handling?}


% To our knowledge, we are the first to attempt to specify a semantics for
% data description languages based on types such as \packettypes{},
% \datascript{} or \pads.  
% %Prior to our work, this family of languages 
% %was described informally and by example.  There was no precise
% %connection to formal dependent type theory.

% Of course, there are other formalisms for
% defining parsers, most famously, regular expressions and
% contex-free grammars.  In terms of recognition power,
% these formalisms differ from our type theory
% in that they have nondeterministic choice, but do not have
% dependency or constraints.  We have found that 
% dependency and constraints are absolutely essential for
% describing most of the ad hoc data sources we have studied.
% Perhaps more importantly though, unlike standard theories of
% context-free grammars,
% we do not treat our type theory merely as a recognizer for
% a collection of strings.  Our type-based descriptions 
% define {\em both} external data formats {\em and} 
% rich invariants on %(\ie{} types for)
% the internal parsed data structures.  This dual interpretation
% of types lies at the heart of tools such as \pads, \datascript{} and
% \packettypes{}.  
% %\pads{} programmers, for instance, demand that
% %representations produced by their \pads{} parsers have the expected type and 
% %count on the fact that the associated PD is accurately correlated
% %with the representation.  
% %Existing formalisms simply do not address
% %this elements of data description languages.

% {\em Parsing Expression Grammars} (PEGs),
% studied in the early 70s~\cite{birman+:parsing} and revitalized more 
% recently by Ford~\cite{ford:pegs}, 
% evolved from context-free grammars but
% have deterministic, prioritized choice like \ddc{} as opposed to
% nondeterministic choice.  Though PEGs have syntactic lookahead operators,
% they may be parsed in linear time through the use of
% ``packrat parsing'' techniques~\cite{ford:packrat,grimm:packrat}.
% Once again, the dual interpretation of types in \ddc{} both as
% data descriptions and as classifiers for internal representations
% make our theory substantially different from the theory of PEGs.
% %In practice, PEGs has not been used to parse ad hoc data.

% {\sc antlr}~\cite{antlr}, a popular programming language parsing tool, 
% uses top-down recursive descent
% parsing and appears roughly similar in recognition power to PEGs and \ddc.
% {\sc antlr} also allows programmers to place annotations
% in the grammar definitions to guide construction of an abstract syntax
% tree. However, all nodes in the abstract syntax tree have a 
% single type, hence the guidance is rather crude when compared with
% the richly-typed structures that can be constructed using
% \ddc.


% Practical experience indicates that
% tools based on these formalisms, such as the many variations of
% Lex and Yacc, are highly effective for processing
% programming language syntax.  However, there is also ample evidence
% that these tools are a poor fit for processing
% ad hoc data --- simply put, {\em no one ever uses Lex or Yacc for 
% these tasks}.
% Unfortunately, the nondeterminism and lack of
% dependency in these formalisms limit their suitability to formalizing
% data description languages. While the parsing expression grammars
% (PEG) formalism~\cite{ford:parsing-expression-grammars} is
% significantly closer to the \ddc{}, it too lacks the necessary
% dependency.

% Less related, but still relevant, are Haskell's parsing
% combinators. While these are not a formalism, they do provide an
% elegant manner in which to express parsers. Hence, while we chose to
% define our parsing semantics in the polymorphic lambda calculus,they
% potentialy provide a more elegant alternative.

% % {\em Mention dependent type theory work?}
