\section{The Generic Tool Framework}
\label{sec:gen-tool}

% \begin{itemize}
% \item x show signature of traversal functor.
% \item x show interface - explain that one module/constructor and base types.
% \item x constrast records and one other module.
% \item x Make it 3 tools: accum, XML, debuger.
% \item x Focus on accumulator. describe in more detail.
% \item x show implementations,  including base types to show how they differ.
% \item x then, describe XML, debugger as pretty printers.
% \item xuse ``generic tool'' in consistent way. I like it better than
%   tool generator.
% \end{itemize}

An essential benefit of \padsml{} is that it can provide the users
with a high return-on-investment for describing their data. While the
generated parser alone is enough to justify the user's effort, we aim
to increase the return by enabling users to easily construct data
analysis tools. However, there is a limit, both in resources and
expertise, to the range of tool generators that we can develop.
Indeed, new and interesting data analysis tools are constantly being
developed, and we have no hope of integrating even a fraction of them
into the \padsml{} system ourselves.

Fortunately, we don't have to. Many of the tools that we have
encountered in practice perform their computations in a single pass
over the representation and corresponding parse descriptor, visiting
each value in the data with a pre-,post-,or in-order traversal.

% A large class of data analysis tools
% share a common data processing method while differing in the details
% of how they transform data. These tools traverse the data
% representation and parse descriptor in a depth-first, left-to-right
% manner, often carrying some auxiliary state.  For each element
% visited, they perform some action involving the auxiliary state,
% either before, after or between visiting the element's subcomponents.
% Often, the most interesting computations occur at the leaves, where
% the computation is based on the leaf's type.  

We can, therefore, split such tools into a format-dependent traversal
mechanism, which implements a generalized fold over the representation
and parse descriptor; and a format-independent, \emph{generic tool}
that specifies how to process individual data elements. The \padsml{}
compiler generates such a format-dependent traversal for all
descriptions, while generic tools are developed independently by
users. The traversal mechanism interacts with generic tools through a
signature that every generic tool must match.

The new, generic tool architecture of \padsml{} delivers a number of
benefits over the fixed architecture of \padsc{}. In \padsc{}, all
tools are generated from within the compiler. Therefore, developing a
new tool generator requires understanding and modifying the compiler.
Furthermore, the set of tools to be generated is chosen by the user
when compiling the description.  In \padsml{}, tool generators can be
developed independent of the compiler and they can be developed more
rapidly, as the ``boilerplate'' code to traverse data need not be
replicated for each tool generator. In addition, the user controls
which tools to ``generate'' for a given data format, and the choice
can differ on a program-by-program basis.

\subsection{The Generic-Tool Interface}
\label{sec:gentool-interface}

\begin{figure}
\begin{code}\scriptsize
\kw{module} \kw{type} S = \kw{sig}
  \kw{type} state
  ...
  \kw{module} Record : \kw{sig}
    \kw{type} partial_state
    \kw{val}  init          : (string * state) list -> state
    \kw{val}  start         : state -> Pads.pd_header 
                         -> partial_state
    \kw{val}  project       : state -> string -> state
    \kw{val}  process_field : partial_state -> string
                         -> state -> partial_state
    \kw{val}  finish        : partial_state -> state
  \kw{end}

  \kw{module} Datatype : \kw{sig}
    \kw{type} partial_state
    \kw{val}  init            : unit -> state
    \kw{val}  start           : state -> Pads.pd_header 
                           -> partial_state
    \kw{val}  project         : state -> string -> state option
    \kw{val}  process_variant : partial_state -> string 
                           -> state -> partial_state
    \kw{val}  finish          : partial_state -> state
  \kw{end}
   ...
\kw{end}
\end{code}
\caption{An excerpt of the generic-tool interface \texttt{Generic\_tool.S}.}
\label{fig:gentool-interface}
\end{figure}

% As the elements of data representations and PD's do not have a uniform
% type, the generic tool must provide different functionality for
% different types, which the traversal functor can then apply
% appropriately to each element of the data.  Therefore, the
% generic-tool signature specifies a particular collection of types and
% functions for every construct in \padsml{}.

The generic tool interface specifies an (abstract) type for auxiliary
state that is threaded through the traversal, and, for every type
constructor in \padsml{}, a set of types and functions -- grouped
together in a module -- that a generic tool must implement. Every
module has an \cd{init} function to create an initial state object for
data processed by that module. In addition, a \cd{project} function
retrieves the state of a subcomponent from the state of an element. As
processing an element can occur before, after, or between processing
an element's children, the signature includes functions corresponding
to each of these events. The function \cd{start} begins processing the
element, \cd{process_...} to process a subcomponent, and \cd{finish}
to complete processing the element. For type constructs with only one
subcomponent, the \cd{process} and \cd{finish} functions are combined.

An excerpt of the generic tool interface is shown in
\figref{fig:gentool-interface}. It includes the signatures of the
\cd{Record} and \cd{Datatype} modules. The \cd{Record} module includes
a type \cd{partial_state} that allows tools to represent intermediate
state in a different form than the general state, while processing
subcomponents. The \cd{init} function forms the state of the record
from the state of its fields. The \cd{start} function receives the PD
header for the data element being traversed. Function \cd{project}
takes a record's state and the name of a field and returns that
field's state. Function \cd{process_field} updates the intermediate
state of the record based on the name and state of a field, and
\cd{finish} converts the finished intermediate state into general tool
state.  Note that any of these functions could have side effects.

The \cd{Datatype} module is quite similar to \cd{Record}, however,
there are some important difference. Its \cd{init} function does not
start with the state of all the variants. Instead, variant's state is
added during processing. In this way, only variants that have been
visited will have corresponding state. For this reason, \cd{project}
returns a \cd{state option}, rather than just \cd{state}. This design
is essential for supporting recursive datatypes.

\begin{figure}
\begin{code}\scriptsize
  \kw{module} Traverse (Tool : Generic_tool.S) :
  \kw{sig}
    \kw{val} init : unit -> Tool.state
    \kw{val} traverse : rep -> pd -> Tool.state -> Tool.state
  \kw{end}
\end{code}
\caption{The signature of the Traversal functor within the signature \texttt{Type.S}.}
\label{fig:traversal-interface}
\end{figure}

In~\figref{fig:traversal-interface}, we show the signature for the
traversal functor as it appears in the signature \cd{Type.S} from
\secref{sec:padsml-impl}. The functor takes a generic tool and produce
a specific tool with two functions: \cd{init}, to create the initial
state for the tool, and \cd{traverse}, which traverses the
representation and parse descriptor for the type and updates the given
tool state.

\subsection{Example Tools}
\label{sec:gentool-motivation-ex}

% \begin{figure}
%   \centering
%   \small
% \begin{verbatim}
% 122Joe|Wright|450|95|790
% n/aEd|Wood|10|47|31
% 124Chris|Nolan|80|93|85
% 125Tim|Burton|30|82|71
% 126George|Lucas|32|62|40
% \end{verbatim}  
%   \caption{A fictitious data fragment in the Movie-director Bowling
%     Score (MBS) format. Note that the first record contains semantic
%     errors (in that the minimum is larger than the maximum and the
%     average is larger than both the minimum and the maximum).}
%   \label{fig:gentool-mbs-sample}
% \end{figure}

\begin{figure}
  \centering
  \scriptsize
\begin{verbatim}
<Order>
   <summary>
      <errors>1</errors> <total>2</total>        
   </summary>
   <Order_header>
      <summary>
         <errors>1</errors> <total>2</total>        
      </summary>
      <order_num>
         <errors>0</errors> <total>2</total>        
      </order_num>
      <att_order_num>
         <summary>
            <errors>1</errors> <total>2</total>        
         </summary>
         <val>
            <errors>0</errors> <total>2</total>                
         </val>
      </att_order_num>
      <ord_version>
         <errors>0</errors> <total>2</total>                
      </ord_version>
      ...
   </Order_header>
</Order>
\end{verbatim}  
  \caption{A fragment of the accumulator output for \dibbler{}. The
    output is encoded in XML.}
  \label{fig:gentool-acc-output}
\end{figure}

We have implemented three generic tools that illustrate important
features of the framework: a tool for generating statistical
overviews of the data, a data printer for debugging, and an XML
formatter.

A common desire of a data analyst upon receiving a new data source is
to get a sense of the quality of the data. In particular, they might
be interested in knowing what percentage of the source has errors, or
which fields are the most problematic. For this purpose, an
\emph{accumulator} tool provides a statistical summary of data
sources. For example, it tracks the distribution of the top $n$
distinct legal values. The accumulator is designed for data sources
whose basic structure is a series of records of the same type and
provides the summary for the record type based on viewing many records
of that type in the data source.

We have implemented a generic tool that provides some of the basic
features of accumulators. Our accummulator counts the number of errors
and the total number of values for every element of a description. In
addition, based on past experience, we know of other statistical
algorithms that could be implemented in a similar manner.

In \figref{fig:gentool-acc-output}, we show a sample portion of
accumulator output for the \dibbler{} data
from~\figref{figure:dibbler-records}. The data shows that one out of the
two \cd{Order}s has an error. Investigating further, we notice that the
problem lies in the \cd{Order_header}, in particular within the
\cd{att_order_num} field.  This field has a constraint on it, and one
of the values violates the constraint. A quick glance at the data
fragment reveals that the second order is contains the offending
field. In general, specific information like this could be found in
the parse descriptor.

\begin{figure}
\begin{code}\scriptsize
\kw{type} baseAcc = int * int
\kw{type} acc = ...
| RecordData of baseAcc * acc Table.t

\kw{type} compoundAcc = baseAcc * acc Table.t

\kw{type} state = acc

\kw{module} Record = \kw{struct}
  \kw{type} partial_state = compoundAcc

  \kw{let} init accs = RecordData ((0,0), Table.from_list accs)

  \kw{let} start state header =
    \kw{match} state \kw{with}
      RecordData ((errs, total), accs) ->
	\kw{let} errs' = if header.nerr > 0
                    then errs + 1 else errs
	\kw{in} (((errs', total + 1), accs) : partial_state)
    | _ -> \kw{raise} ...
	  
  \kw{let} project state label = 
     \kw{match} state \kw{with}
      RecordData (_, accs) -> (\kw{try} Table.find accs label
                                 \kw{with} _ -> \kw{raise} ...)
    | _ -> \kw{raise} ...

  \kw{let} process_field (ba, accs) label acc =
    (ba, Table.update accs label acc)
      
  \kw{let} finish (ba, accs) = RecordData (ba, accs)
\kw{end}
...
\end{code}
\caption{Excerpts from the implementation of the accumulator.}
\label{fig:gentool-accum-code}
\end{figure}

In~\figref{fig:gentool-accum-code}, we show a portion of the of the
accumulator implementation, including the \cd{Record} module. We first
define a basic accumulator, which is simply a pair of integers
counting the number of errors seen and the total number of elements
seen. The type \cd{acc} is essentially a universal datatype with
accumulator summaries for every element of the representation type. We
show the \cd{RecordData} variant for illustration.  The \cd{init}
function starts both counts at zero and converts the provided list of
subcomponent accumulators into a \cd{Table.t}.  The \cd{start}
function updates the summary based on the error count \cd{nerr} in the
PD header provided, and increments that total count by one. It returns
a \cd{partial_state}, as indicated by the type annotation. Projection
and processing of fields are simply lookups and insertions in a table
of subcomponent accumulators.

In addition to the accumulator, we have implemented two different
kinds of pretty printers for parsed data.  One formats the data in
XML. The other prints the data in a simple text format that is helpful
for debugging descriptions. Importantly, both tool's output corresponds to the in-memory
representation of the data rather than its original format (which may,
for example, have delimiters that are not present in the
representation).

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
