\section{The Generic Tool Framework}
\label{sec:gen-tool}

eAn essential benefit of \padsml{} is that it can provide users
with a high return-on-investment for describing their data. While the
generated parser alone is enough to justify the user's effort, we aim
to increase the return by enabling users to easily construct data
analysis tools. However, there is a limit, both in resources and
expertise, to the range of tool generators that we can develop.
Indeed, new and interesting data analysis tools are constantly being
developed, and we have no hope of integrating even a fraction of them
into the \padsml{} system ourselves.

Fortunately, we don't have to. Many of the tools that we have
encountered in practice perform their computations in a single pass
over the representation and corresponding parse descriptor, visiting
each value in the data with a pre-, post-, or in-order traversal.
We can, therefore, split such tools into a format-dependent traversal
mechanism, which implements a generalized fold over the representation
and parse descriptor; and a format-independent, \emph{generic tool}
that specifies how to process individual data elements. The \padsml{}
compiler generates such a format-dependent traversal for all
descriptions, while generic tools are developed independently by
users. The traversal mechanism interacts with generic tools through a
signature that every generic tool must match.

The generic tool architecture of \padsml{} delivers a number of
benefits over the fixed architecture of \padsc{}. In \padsc{}, all
tools are generated from within the compiler. Therefore, developing a
new tool generator requires understanding and modifying the compiler.
Furthermore, the set of tools to be generated is chosen by the user
when compiling the description.  In \padsml{}, tool generators can be
developed independent of the compiler and they can be developed more
rapidly, as the ``boilerplate'' code to traverse data need not be
replicated for each tool generator. In addition, the user controls
which tools to ``generate'' for a given data format, and the choice
can differ on a program-by-program basis.

\subsection{The Generic-Tool Interface}
\label{sec:gentool-interface}

\begin{figure}
\begin{code}\scriptsize
\kw{module} \kw{type} S = \kw{sig}
  \kw{type} state
  ...
  \kw{module} Record : \kw{sig}
    \kw{type} partial_state
    \kw{val}  init          : (string * state) list -> state
    \kw{val}  start         : state -> Pads.pd_header 
                         -> partial_state
    \kw{val}  project       : state -> string -> state
    \kw{val}  process_field : partial_state -> string
                         -> state -> partial_state
    \kw{val}  finish        : partial_state -> state
  \kw{end}

  \kw{module} Datatype : \kw{sig}
    \kw{type} partial_state
    \kw{val}  init            : unit -> state
    \kw{val}  start           : state -> Pads.pd_header 
                           -> partial_state
    \kw{val}  project         : state -> string -> state option
    \kw{val}  process_variant : partial_state -> string 
                           -> state -> partial_state
    \kw{val}  finish          : partial_state -> state
  \kw{end}
   ...
\kw{end}
\end{code}
\caption{An excerpt of the generic-tool interface \texttt{Generic\_tool.S}.}
\label{fig:gentool-interface}
\end{figure}

% As the elements of data representations and PD's do not have a uniform
% type, the generic tool must provide different functionality for
% different types, which the traversal functor can then apply
% appropriately to each element of the data.  Therefore, the
% generic-tool signature specifies a particular collection of types and
% functions for every construct in \padsml{}.

The generic tool interface specifies an (abstract) type for auxiliary
state that is threaded through the traversal, and, for every type
constructor in \padsml{}, a set of types and functions -- grouped
together in a module -- that a generic tool must implement. 
An excerpt of the generic tool interface is shown in
\figref{fig:gentool-interface}. It includes the signatures of the
\cd{Record} and \cd{Datatype} modules. The signatures of other modules
are quite similar.

The \cd{Record} module includes a type \cd{partial_state} that allows
tools to represent intermediate state in a different form than the
general state. The \cd{init} function forms the state of the record
from the state of its fields. The \cd{start} function receives the PD
header for the data element being traversed and begins processing the
element. Function \cd{project} takes a record's state and the name of
a field and returns that field's state. Function \cd{process_field}
updates the intermediate state of the record based on the name and
state of a field, and \cd{finish} converts the finished intermediate
state into general tool state.  Note that any of these functions could
have side effects.

The \cd{Datatype} module is quite similar to \cd{Record}, however,
there are some important differences. Its \cd{init} function does not
start with the state of all the variants. Instead, variants' state is
added during processing. In this way, only variants that have been
encountered will have corresponding state. For this reason,
\cd{project} returns a \cd{state option}, rather than just \cd{state}.
This design is essential for supporting recursive datatypes.

\begin{figure}
\begin{code}\scriptsize
  \kw{module} Traverse (Tool : Generic_tool.S) :
  \kw{sig}
    \kw{val} init : unit -> Tool.state
    \kw{val} traverse : rep -> pd -> Tool.state -> Tool.state
  \kw{end}
\end{code}
\caption{The signature of the Traversal functor within the signature \texttt{Type.S}.}
\label{fig:traversal-interface}
\end{figure}

In~\figref{fig:traversal-interface}, we show the signature for the
traversal functor as it would appear in the signature \cd{S} from
\secref{sec:padsml-impl}. The functor takes a generic tool and produce
a specific tool with two functions: \cd{init}, to create the initial
state for the tool, and \cd{traverse}, which traverses the
representation and parse descriptor for the type and updates the given
tool state.

\subsection{Example Tools}
\label{sec:gentool-motivation-ex}

% \begin{figure}
%   \centering
%   \small
% \begin{verbatim}
% 122Joe|Wright|450|95|790
% n/aEd|Wood|10|47|31
% 124Chris|Nolan|80|93|85
% 125Tim|Burton|30|82|71
% 126George|Lucas|32|62|40
% \end{verbatim}  
%   \caption{A fictitious data fragment in the Movie-director Bowling
%     Score (MBS) format. Note that the first record contains semantic
%     errors (in that the minimum is larger than the maximum and the
%     average is larger than both the minimum and the maximum).}
%   \label{fig:gentool-mbs-sample}
% \end{figure}

\begin{figure}
  \centering
  \scriptsize
\begin{verbatim}
<Order>
   <summary>
      <errors>1</errors> <total>2</total>        
   </summary>
   <Order_header>
      <summary>
         <errors>1</errors> <total>2</total>        
      </summary>
      <order_num>
         <errors>0</errors> <total>2</total>        
      </order_num>
      <att_order_num>
         <summary>
            <errors>1</errors> <total>2</total>        
         </summary>
         <val>
            <errors>0</errors> <total>2</total>                
         </val>
      </att_order_num>
      <ord_version>
         <errors>0</errors> <total>2</total>                
      </ord_version>
      ...
   </Order_header>
</Order>
\end{verbatim}  
  \caption{A fragment of the accumulator output for \dibbler{}. The
    output is encoded in XML.}
  \label{fig:gentool-acc-output}
\end{figure}

We have implemented three generic tools that illustrate important
features of the framework: a tool for generating statistical
overviews of the data, a data printer for debugging, and an XML
formatter.

A common desire of a data analyst upon receiving a new data source is
to get a sense of the quality of the data. In particular, they might
be interested in knowing what percentage of the source has errors, or
which fields are the most problematic. For this purpose, an
\emph{accumulator} tool provides a statistical summary of data
sources. For example, it tracks the distribution of the top $n$
distinct legal values. The accumulator is designed for data sources
whose basic structure is a series of records of the same type, and
provides the summary for the record type based on viewing many records
of that type in the data source.

We have implemented a generic tool that provides some of the basic
features of accumulators. Our accumulator counts the number of errors
and the total number of values for every element of a description.
Based on past experience, we know of other statistical algorithms that
could be implemented in a similar manner.

In \figref{fig:gentool-acc-output}, we show a sample portion of
accumulator output for the \dibbler{} data
from~\figref{figure:dibbler-records}. The data shows that one out of
the two \cd{Order}s has an error. Investigating further, we notice
that the problem lies in the \cd{Order_header}, in particular within
the \cd{att_order_num} field.  This field has a constraint on it, and
one of the values violates the constraint. A quick glance at the data
fragment reveals that the second order contains the offending field.
In general, particular invalid data can be located using the parse
descriptor.

\begin{figure}
\begin{code}\scriptsize
\kw{type} baseAcc = int * int
\kw{type} acc = ...
| RecordData of baseAcc * acc Table.t

\kw{type} compoundAcc = baseAcc * acc Table.t

\kw{type} state = acc

\kw{module} Record = \kw{struct}
  \kw{type} partial_state = compoundAcc

  \kw{let} init accs = RecordData ((0,0), Table.from_list accs)

  \kw{let} start state header =
    \kw{match} state \kw{with}
      RecordData ((errs, total), accs) ->
	\kw{let} errs' = if header.nerr > 0
                    then errs + 1 else errs
	\kw{in} (((errs', total + 1), accs) : partial_state)
    | _ -> \kw{raise} ...
	  
  \kw{let} project state label = 
     \kw{match} state \kw{with}
      RecordData (_, accs) -> (\kw{try} Table.find accs label
                                 \kw{with} _ -> \kw{raise} ...)
    | _ -> \kw{raise} ...

  \kw{let} process_field (ba, accs) label acc =
    (ba, Table.update accs label acc)
      
  \kw{let} finish (ba, accs) = RecordData (ba, accs)
\kw{end}
...
\end{code}
\caption{Excerpts from the implementation of the accumulator.}
\label{fig:gentool-accum-code}
\end{figure}

In~\figref{fig:gentool-accum-code}, we show a portion of the
accumulator implementation, including the \cd{Record} module. We first
define a basic accumulator, which is simply a pair of integers
counting the number of errors seen and the total number of elements
seen. The type \cd{acc} is essentially a universal datatype with
accumulator summaries for every element of the representation type. We
show the \cd{RecordData} variant for illustration.  The \cd{init}
function starts both counts at zero and converts the provided list of
subcomponent accumulators into a \cd{Table.t}.  The \cd{start}
function updates the summary based on the error count \cd{nerr} in the
PD header provided, and increments that total count by one. It returns
a \cd{partial_state}, as indicated by the type annotation. Projection
and processing of fields are simply lookups and insertions in a table
of subcomponent accumulators.

In addition to the accumulator, we have implemented two different
kinds of pretty printers for parsed data.  One formats the data in
XML. The other prints the data in a simple text format that is helpful
for debugging descriptions. Importantly, both tool's output corresponds to the in-memory
representation of the data rather than its original format (which may,
for example, have delimiters that are not present in the
representation).

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
