
\section{From \padsmlbig{} to \ocamlbig{}}
\label{sec:padsml-impl}

{\em
ToDo: Move detail about Traverse functor to Generic tools section.
}

We have implemented \padsml{} for use with \ocaml{}. The \padsml{}
compiler generates libraries in \ocaml{} source code that can then be
used by any \ocaml{} program. In this section, we describe the
contents of the generated libraries followed by some examples
demonstrating their use.


\subsection{Generated Libraries}
\label{sec:gen-code}

From each \padsml{} description, we generate a collection of types and
functions in \ocaml{}, including:
\begin{itemize}
\item The types of two data structures: one to contain parsed data in
  memory and the other to hold meta-data about the parsing process.
  These are respectively called the \emph{representation} and
  the \emph{parse descriptor}.
\item The parsing function, which take an abstract handle for the data
  source and produces a representation and parse descriptor for the
  data.
\item A generic tool generator, based on the new tool development
  framework for \padsml{}. This framework is discussed in the next
  section.
\end{itemize} 

In general, the representation and parse-descriptor type definitions
are designed to be as close as possible to the original description.
The aim is to minimize the amount of effort a user must invest in
order to understand and use the data structures returned by the
parser.

Furthermore, the type of parse descriptor mimics the type of the
representation so that the parse descriptor can provide a precise
report on the parsing process for every element of a corresponding
representation. Parse descriptors have two components: a header and a
body. The header reports on the parsing process that produced the
representation. It includes an error count that indicates the number
of subcomponents with errors; an error code that provides a brief
indicator of the type of error, if any; and the location of the data
within the original data source. The body of the parse descriptor
contains the parse descriptors (if any) for subcomponents of
corresponding representations. The body for a base-type parse
descriptor is always type \cd{unit}.

As an example, below is a simple a \padsml{} description of a character
and integer separated by a vertical bar.
\begin{code}\scriptsize
\kw{ptype} Pair = Pchar * '|' * Pint\end{code}
Here is a portion of a signature for the elements generated from that
type. 
\begin{code}
\kw{type} rep = Pchar.rep * Pint.rep
\kw{type} pd_body = Pchar.pd  * Pint.pd
\kw{type} pd = Pads.pd_header * pd_body

\kw{val} parse : Pads.handle -> rep * pd\end{code} 

First, note the close correspondence between the structure of the
description and that of the \cd{rep} and \cd{pd} types. Next, the
\cd{Pads} module contains types and functions that commonly occur in
generated and base-type modules. In this example we use
\cd{Pads.pd_header}, which is the type of all parse-descriptor
headers, and \cd{Pads.handle}, which is the type of the (abstract)
handles used for data sources.

Given the close relationship between the elements generated from a
description, it is natural to collect them together in a module. For
each named type, therefore, we generate a module with definitions like
those shown in the above example.
% For all generated modules, \cd{rep}, \cd{pd_body},\cd{pd} define the
% types of the data's representation, parse-descriptor body, and parse
% descriptor, respectively. The parsing function is named \cd{parse}.
In general, all types with base kind (i.e. those that are not
parameterized by values or other types) match the following signature
\cd{Type.S}:
\begin{code}\scriptsize
\kw{type} rep
\kw{type} pd\_body
\kw{type} pd = Pads.pd_header * pd_body

val parse : Pads.handle -> rep * pd\end{code}

Modules, then, become the building blocks of the \padsml{} system.
Base types, too, are implementated with modules. Polymorphic types,
which map types to types, are implemented as functors from (type)
modules to (type) modules. It would even be appropriate to map
recursive types into recursive modules. Unfortunately, this approach
fails due to the limitations of the \ocaml{} implementation of
recursive modules. We would need support for inclusion of functors in
recursive modules in order to take this approach.

Given the signature \cd{Type.S} for types of base kind, we can now
show an example signature for a polymorphic \kw{type}.
\begin{code}\scriptsize
\kw{ptype} (Alpha,Beta) ABPair = Alpha * '|' * Beta
\(\Longrightarrow\)
\kw{module} ABPair (Alpha : Type.S) (Beta : Type.S) :
\kw{sig}
  \kw{type} rep = Alpha.rep * Beta.rep
  \kw{type} pd\_body = Alpha.pd\_body Pads.pd * 
                     Beta.pd\_body Pads.pd
  \kw{type} pd = pd\_body Pads.pd

  \kw{val} parse : Pads.handle -> rep * pd
\kw{end}\end{code}

Once a description has been compiled into an \ocaml{} module, that
module can be used like any other. In the remainder of this section,
we will demonstrate a number of usecases, highlighting data transformation,
filtering, and processing.

\emph{fit this in somewhere}.  Therefore, each named type in a
description file is mapped into an \ocaml module of the same name. The
collection of modules is then grouped together into a single file
(compilation unit) with a name corresponding to the name of the
original description file. So, if the description file is ``foo.pml,''
with three types inside, then the result is a file ``foo.ml'' with
three submodules, each corresponding to one named type.

\subsection{Example: Data Processing}
\label{sec:ex-process}

We begin with a simple example in which we process a list of
integers. Below, we show a description of a data source that contains
a list of ASCII-encoded integers, separated by a semicolon and
terminated by the end of the file.
\begin{code}\scriptsize
ptype Source = (Pint32,Semicolon, Peof) Plist\end{code}
Next, we show a complete \ocaml{} program that finds the average of
the integers in the list. (Note that we assume that the
name of the description file is ``intList.pml,'' resulting in an
\ocaml{} module \cd{IntList}.)
\begin{code}\scriptsize
\kw{open} Pads
\kw{module} S = IntList.Source

\kw{let} get_sum sum len = function
  S.Nil() -> sum,len
| S.Cons(_,i,is) -> sum (sum + i) (len + 1) is
  
\kw{let} (rep,pd) = Tester.parse_with_from_file S.parse ``input.txt''

\kw{let} sum = match get_pd_hdr pd with
            \{error_code = Good\} -> get_sum 0 0 rep
          | _ -> 0\end{code}

\emph{Explain code here.}


\subsection{Example: Transformation}
\label{sec:ex-trans}

\begin{figure}
  \centering
  \begin{code}\scriptsize
\kw{ptype} Header = \{
       alarm : [ a : Puint32 | a = 2 or a = 3];
 ':';  start :  Timestamp Popt;
 '|';  clear :  Timestamp Popt;
 '|';  code: Puint32;
 '|';  src\_dns  :  Nvp("dns1");
 ';';  dest\_dns :  Nvp("dns2");
 '|';  service  : service
\}
\mbox{}
\kw{ptype} D\_alarm = \{
       header   : header;
 '|';  details  : details
 \}
\mbox{}
\kw{ptype} G\_alarm = \{
       header   : header;
 '|';  generic  : (Nvp\_a,Semicolon,Vbar) Plist
\}\end{code}
\caption{Normalized format for \darkstar{} data}
\label{fig:normal-darkstar}
\end{figure}

\begin{figure}
\begin{code}\scriptsize
\kw{open} Darkstar
\kw{open} DarkstarNormal
\kw{module} RA = Raw\_alarm
\kw{module} DA = D\_alarm
\kw{module} GA = G\_alarm
\kw{module} Header = H

(* splitAlarm: RA.rep -> DA.rep option * GA.rep option *)
\kw{let} splitAlarm ra =
    \kw{let} h = \{H.alarm=ra.RA.alarm; H.start=ra.RA.start; 
              H.clear=ra.RA.clear; H.code=ra.RA.code;
              H.src\_dns=ra.RA.src\_dns; H.dest\_dns=ra.RA.dest\_dns;
              H.service=ra.RA.service\};
    in match ra with
        \{info=Details(d)\} -> 
        (Some \{DA.header = h; DA.details = d\}, None)
      | \{info=Generic(g)\} ->
        (None, Some \{GA.header = h; GA.generic = g\})    
  \end{code}
  \caption{Shredding \darkstar{} data based on the {\tt info} field.}
  \label{fig:ex-no-err-check}
\end{figure}

Once a data source has been parsed, a natural desire is to transform
such data to make it more amenable to further analysis.  For example,
analysts often need to convert ad hoc data into a form suitable for
loading into an existing system, such as a relational database or
statistical analysis package. Desired transformations include
removing extraneous literals, inserting delimiters, dropping or
reordering fields, and normalizing the values of fields (\eg{}
converting all times into a specified time zone).  

Because relational databases typically cannot store unions directly,
another important transformation is to convert data with variation
(\ie{}, datatypes) into a form that such systems can handle.
Typically, there are two choices for such a transformation.  The first
is to chop the data into a number of relational tables: one table for
each variation.  This approach is called \textit{shredding}. The
second is to create an ``uber'' table, with one ``column'' for each
field in any variation.  If a given field is not in a particular
variation, it is marked as missing. 

The code fragment in \figref{fig:ex-no-err-check} demonstrates
shredding with \padsml{} and \ocaml{}. We shred the data into two
different tables based on the \cd{info} field. In the process, we also
reorder the fields, putting the shared \texttt{service} field into
the common \texttt{header}.

\begin{figure}
  \centering
  \begin{code}\scriptsize
\kw{ptype} Time = \{time: Timestamp;
               ':'; timezone: Pstring_FW(3)\}
\mbox{}
(* normalizeTimeToGMT: time -> Ptimestamp_FW(8) *)
\kw{let} normalizeTimeToGMT t = 
    match t with
      \{time=t;timezone="GMT"\} => t
    | \{time=t;timezone="EST"\} => t + (5 * 60 * 60)
    | \{time=t;timezone="PST"\} => t + (8 * 60 * 60)
    | ... \end{code}
  \caption{Normalizing timestamps}
  \label{fig:ex-normalize}
\end{figure}

In \figref{fig:ex-normalize}, we show an additional example of data
transformation, where we normalize timestamp-timezone pairs into
simple timestamps in GMT time.

\subsection{Example: Filtering}
\label{sec:ex-filter}

Another important set of tasks relating to ad hoc data are those
related to errors, including error analysis, repair, and removal.
Instead of simply ignoring errors as in the previous section,
programmers might want to clean their data, \ie{}, filter out data
containing errors. In this case, they can access parse descriptors to
facilitate this task.

\begin{figure}
\begin{code}\scriptsize
\kw{open} Pads
   ...
\kw{let} splitEntry (good,bad) (entry,pd) =
   match get\_pd\_hdr pd with
     \{error_code = Good\} -> (entry::good, bad)
   | _ => (good, (entry::bad))\end{code}
\caption{Error filter for \dibbler{} data}
\label{fig:ex-data-clean}
\end{figure}

\figref{fig:ex-data-clean} gives such an example.  It examines all
entries in a \dibbler{} data source, placing good entries into one
output list and bad entries into another.  The good entries may then
be further processed or loaded into a database without corrupting the
valuable data therein.  A human might examine the bad entries off-line
to determine the cause of errors or to figure out how to fix the
corrupted entries.

The \cd{splitEntry} function checks its argument \cd{entry} to
determine whether it is \cd{Good} (syntactically and semantically
valid).  Because the function needs to access \cd{e}'s descriptor for
filtering, it first projects the parse descriptor header from the
entry.  The \cd{splitEntry} could then be used in some other function
to split a standard \dibbler{} source into two separate sources, one
with clean records and the other (potentially) invalid records.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
