
\section{From \padsmlbig{} to \ocaml{}}
\label{sec:padsml-impl}

We have implemented \padsml{} for use with \ocaml{}. The \padsml{}
compiler generates \ocaml{} source code that can then be used by any
\ocaml{} program. We will next describe exactly what is generated from
a description followed by some example uses of the generated code.

\subsection{Generated Code}
\label{sec:gen-code}

Every type in \padsml{} corresponds to a collection of types and
functions in \ocaml{}, including: the type of parsed data as it is represented in
memory, called the \textit{representation} type; the type of the data's
parse descriptor; and the parser function. Given the close relationship
between these types and functions, it is natural to collect them
together in an \ocaml{} module. Therefore, each named type in a
description file is mapped into an \ocaml module of the same
name. The collection of modules is then grouped together into a single
file (compilation unit) with a name corresponding to the name of the
original description file. So, if the description file is ``foo.pml,''
with three types inside, then the result is a module ``Foo'' with
three submodules, each corresponding to one description.

Once types are mapped into modules, it is again quite
natural to map polymorphic types into functors from types to
types. Continuing the analogy, it would be appropriate to map
recursive types into recursive modules. Unfortunately, this approach
fails do to the limitations of the \ocaml{} implementation of
recursive modules. We would need support for inclusion of functors in
recursive modules in order to take this approach.

To give the reader a better understanding of the contents of the
generated modules, we show here a simple \padsml{} type along with the
signature of the module generated based on that type.
To give the reader a better understanding of the contents of the
generated modules, we show here a simple \padsml{} type along with the
signature of the module generated based on that type.
To give the reader a better understanding of the contents of the
generated modules, we show here a simple \padsml{} type along with the
signature of the module generated based on that type.
\begin{code}\scriptsize
\kw{ptype} Pair = Pchar * '|' * Pint

-------------------------------

type rep = Pchar.rep * Pint.rep
type pd_body = Pchar.pd_body Pads.pd * 
                  Pint.pd_body Pads.pd
type pd = pd_body Pads.pd

val parse : Pads.handle -> rep * pd

module Traverse (Tool : Generic_tool.S) :
sig
  val init : unit -> Tool.state
  val traverse : rep -> pd -> Tool.state -> Tool.state
end\end{code}
There is one new element to the signature that has not previously been
discussed - the functor \cd{Traversal}. This functor is essential to
the new generic tool framework and will be discussed in greater detail
in \secref{sec:gen-tool}.

In general, all types with base kind match the following signature
(later referenced as \cd{Type.S}):
\begin{code}\scriptsize
type rep
type pd\_body
type pd = Pads.pd_header * pd_body

val parse : (rep,pd\_body) Pads.parser

module Traverse (Tool : Generic\_tool.S) :
sig
  val init : unit -> Tool.state
  val traverse : rep -> pd -> Tool.state -> Tool.state
end\end{code}
With this signature for types at base kind, we can now show an example
signature for a polymorphic type.
\begin{code}\scriptsize
\kw{ptype} (Alpha,Beta) ABPair = Alpha * '|' * Beta
\mbox{}
-------------------------------------------------
\mbox{}
module ABPair (Alpha : Type.S) (Beta : Type.S) :
sig
  type rep = Alpha.rep * Beta.rep
  type pd\_body = Alpha.pd\_body Pads.pd * 
                     Beta.pd\_body Pads.pd
  type pd = pd\_body Pads.pd

  val parse : Pads.handle -> rep * pd

  module Traverse (Tool : Generic\_tool.S) :
  sig
    val init : unit -> Tool.state
    val traverse : rep -> pd -> Tool.state -> Tool.state
  end
end\end{code}

Once a description has been compiled into an \ocaml{} module, that
module can be used like any other. There are many possible ways to use
the generated moduel. Next, we will show to example usecases,
highlighting data transformation, filtering, and processing.

\subsection{Example: Data Processing}
\label{sec:ex-process}

We begin with a simple example in which we process a list of
integers. Below, we show the description of that data source:
\begin{code}\scriptsize
ptype Source = (Pint32,Semicolon, Peof) Plist\end{code}
Next, we show a complete \ocaml program that finds the average of a
data source matching the given description. (Note that we assume the
name of the description file is ``intList.pml.'')
\begin{code}\scriptsize
open Pads
module S = IntList.Source

let get_sum sum len = function
  S.Term _ -> sum,len
| S.DtDefault (_,i,is) -> sum (sum + i) (len + 1) is
  
let (rep,pd) = Tester.parse_with_from_file S.parse ``input.txt''

let sum = match get_pd_hdr pd with
            {error_code = Good} -> get_sum 0 0 rep
          | _ -> 0\end{code}

\subsection{Example: Transformation}
\label{sec:ex-trans}

\begin{figure}
  \centering
  \begin{code}\scriptsize
ptype Header = \{
       alarm : [ alarm : Puint32 | alarm = 2 
                                    orelse alarm = 3];
 ':';  start :  Timestamp Popt;
 '|';  clear :  Timestamp Popt;
 '|';  code: Puint32;
 '|';  src\_dns  :  Nvp("dns1");
 ';';  dest\_dns :  Nvp("dns2");
 '|';  service  : service
\}
\mbox{}
ptype D\_alarm = \{
       header   : header;
 '|';  details  : details
 \}
\mbox{}
ptype G\_alarm = \{
       header   : header;
 '|';  generic  : (Nvp\_a,Semicolon,Vbar) Plist
\}\end{code}
\caption{Normalized format for \darkstar{} data}
\label{fig:normal-darkstar}
\end{figure}

\begin{figure}
\begin{code}\scriptsize
open Darkstar
open DarkstarNormal
module RA = Raw\_alarm
module DA = D\_alarm
module GA = G\_alarm
module Header = H

(* splitAlarm: RA.rep -> DA.rep option * GA.rep option *)
let splitAlarm ra =
    let h = \{H.alarm=ra.RA.alarm; H.start=ra.RA.start; 
              H.clear=ra.RA.clear; H.code=ra.RA.code;
              H.src\_dns=ra.RA.src\_dns; H.dest\_dns=ra.RA.dest\_dns;
              H.service=ra.RA.service\};
    in match ra with
        \{info=Details(d)\} -> 
        (Some \{DA.header = h; DA.details = d\}, None)
      | \{info=Generic(g)\} ->
        (None, Some \{GA.header = h; GA.generic = g\})    
  \end{code}
  \caption{Shredding \darkstar{} data based on the {\tt info} field.}
  \label{fig:ex-no-err-check}
\end{figure}

Once a data source has been parsed, a natural desire is to transform
such data to make it more amenable to further analysis.  For example,
analysts often need to convert ad hoc data into a form suitable for
loading into an existing system, such as a relational database or
statistical analysis pacakge.  Desired transformations include
removing extraneous literals, inserting delimiters, dropping or
reordering fields, and normalizing the values of fields (\eg{}
converting all times into a specified time zone).  

Because relational databases typically cannot store unions directly,
another important transformation is to convert data with variation
(\ie{}, datatypes) into a form that such systems can handle.
Typically, there are two choices for such a transformation.  The first
is to chop the data into a number of relational tables: one table for
each variation.  This approach is called \textit{shredding}. The
second is to create an ``uber'' table, with one ``column'' for each
field in any variation.  If a given field is not in a particular
variation, it is marked as missing. Next, we discuss an example of
shredding with \padsml{} and \ocaml{}.

In particular, we shred the data into two different tables based on
the \cd{info} field.  The code fragment in
\figref{fig:ex-no-err-check} demonstrates such a transformation (it
also reorders the fields, putting the shared \texttt{service} field
into the common \texttt{header}).

\begin{figure}
  \centering
  \begin{code}\scriptsize
ptype Time = 
  \{time: Timestamp;
   ':'; timezone: Pstring_FW(3)\}
\mbox{}
(* normalizeTimeToGMT: time -> Ptimestamp_FW(8) *)
let normalizeTimeToGMT t = 
    match t with
      \{time=t;timezone="GMT"\} => t
    | \{time=t;timezone="EST"\} => t + (5 * 60 * 60)
    | \{time=t;timezone="PST"\} => t + (8 * 60 * 60)
    | ... \end{code}
  \caption{Normalizing timestamps}
  \label{fig:ex-normalize}
\end{figure}

In \figref{fig:ex-normalize}, we show an additional example of data
transformation, where we normalize timestamp-timezone pairs into
simple timestamps in GMT time.

\subsection{Example: Filtering}
\label{sec:ex-filter}

Another important set of tasks relating to ad hoc data are those
related to errors, including error analysis, repair, and removal.
Instead of simply ignoring errors as in the previous section,
programmers might want to clean their data, \ie{}, filter out data
containing errors. In this case, they can access parse descriptors to
facilitate this task.

\begin{figure}
\begin{code}\scriptsize
open Pads
   ...
let splitEntry (good,bad) entry =
  let(\_,pd) = entry in
    match get\_pd\_hdr pd with
      {error_code = Good} -> (entry::good * bad)
    | _ => (good * (entry::bad))\end{code}
\caption{Error filter for \dibbler{} data}
\label{fig:ex-data-clean}
\end{figure}

\figref{fig:ex-data-clean} gives such an example.  It examines all
entries in a \dibbler{} data source, placing good entries into one
output list and bad entries into another.  The good entries may then
be further processed or loaded into a database without corrupting the
valuable data therein.  A human might examine the bad entries off-line
to determine the cause of errors or to figure out how to fix the
corrupted entries.

The \cd{splitEntry} function checks its argument \cd{entry} to
determine whether it is \cd{G}ood (syntactically and semantically
valid).  Because the function needs to access \cd{e}'s descriptor for
filtering, it first projects the parse descriptor header from the
entry.  The \cd{splitEntry} could then be used in some other function
to split a standard \dibbler{} source into two separate sources, one
with clean records and the other (potentially) invalid records.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
