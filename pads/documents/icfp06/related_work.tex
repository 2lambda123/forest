\section{Related Work}
\label{sec:related}


Some of the oldest tools for describing data formats are parser
generators for compiler construction such as
Lex and Yacc.  While excellent for parsing programming languages, Lex and Yacc
are too heavyweight for parsing many of the simpler ad hoc data formats that
arise in networking, the computational sciences, finance, \etc{}   
In addition, Lex and Yacc do not support data-dependent parsing, 
do not generate internal representations automatically, 
and do not supply a collection of value-added tools such as
\padsml's XML translator.

Some more modern compiler construction tools alleviate
a few of the problems of Lex and Yacc by providing more
built-in programming support.  For instance,
the ANTLR parser generator~\cite{antlr} allows the user to add
annotations to a grammar to direct construction of a parse tree.
As another example,
Demeter's class dictionaries~\cite{lieberherr+:class-dictionaries}
can generate parsers that construct internal parse trees
as well as traversal functions, much like the traversal functions
generated by \padsml.  However, these tools do not have dependent
and polymorphic data descriptions or a formal semantics.  Moreover,
they were designed for imperative and object-oriented languages 
as opposed to strongly typed functional languages like ML.

The networking community has developed a number of domain-specific
languages, including PacketTypes~\cite{sigcomm00}, DataScript~\cite{gpce02}
and Bro's~\cite{paxson:bro} packet processing language
for parsing and printing binary data.  
Like \pads{} and \padsml{}, these languages have a type-directed
approach to describing ad hoc data and permit the user to define
semantic constraints.  In contrast to our work, these systems handle
only binary data and assume the data is error-free or halt parsing if
an error is detected.  Not only are ASCII formats a common part of
many software monitoring systems, parsing non-binary data poses additional
challenges because of the need to handle delimiter values and to
express richer termination conditions on sequences of data. 
PacketTypes and DataScript also focus exclusively on the 
parsing/printing problem,
whereas our research will exploit the declarative nature of our data
descriptions to automatically generate additional useful tools and
programming libraries.  

There are a number of tools designed to deal with converting ad hoc
data formats into XML and various related tasks.  For instance,
XSugar~\cite{brabrand+:xsugar2005} allows users to specify an
alternative non-XML syntax for XML languages using a context-free
grammar.  This tool automatically generates conversion between XML and
non-XML syntax.  The Binary Format Description language 
(BFD)~\cite{bfd} is a fragment of
XML that allows programmers to specify binary and ASCII formats.  BFD
is able to convert the raw data into XML-tagged data where it can then be
processed using XML-processing tools.    While both these tools are 
useful for many
tasks, conversion to XML is not always the answer.  Such conversion
often results in an 8-10 times blowup in data size over the native form.
\padsml{}, on the other hand, avoids this blowup by processing data in its 
native form.  The conversion process also does not directly help programmers
get their hands on the data.

The Global Grid Forum is working on a standard
data-format description language for describing ad hoc data formats,
called DFDL~\cite{dfdl-proposal,dfdl-primer}.  Like \pads{},
DFDL{} has a rich collection of base types and supports a variety of
ambient codings.  Unlike \pads{}, DFDL{} does not support semantic
constraints on types nor dependent types, \eg{}, it is not possible to
specify that the length of an array is determined by some previously parsed field in the
data.  Our practical experience indicates that many ad hoc formats,
particularly binary formats, absolutely require dependent types in their
specifications.  DFDL{} is an annotated subset of XML{} Schema, which means
that the XML{} view of the ad hoc data is implicit in a DFDL{}
description.  DFDL{} is still being specified, so no DFDL-aware
parsers or data analyzers exist yet.  

% There are parallels between PADS types and some of the elements of parser
% combinator libraries found in languages like
% Haskell~\cite{burge:parser-combinators,hutton+:parser-combinators}. 
% However, as with most other general-purpose parsing tools, one cannot
% simply put together a collection of Haskell's parser combinators and
% automatically generate domain-specific programs such as 
% an XML converter or a histogram generator, for instance.  

A somewhat different class of languages includes
\textsc{ASN.1}~\cite{asn} and \textsc{ASDL}~\cite{asdl}.  Both of
these systems specify the {\em logical\/} in-memory representation of
data and then automatically generate a {\em physical\/} on-disk
representation.  Although useful for many purposes, this technology
does not help process data that arrives in predetermined, ad hoc
formats.  Another language in this category is the Hierarchical Data
Format 5 (HDF5)~\cite{hdf5}.  This file format allows users to store
scientific data, but it does not help users deal with legacy ad hoc
formats like PADS does.

% There are probably hundreds of tools that one might use if their data were
% in \xml.  However, the point of PADS is to allow scientists whose data is {\em not}
% already in \xml to get work done, particularly when that data contains errors,
% as ad hoc data often does.  Since many processes, machines, programs and other devices
% currently output data and a whole most of

XDTM~\cite{zhao+:sigmod05,xdtm} uses XML Schema to describe the
locations of a collection of sources spread across a local file system
or distributed across a network of computers.  However, XDTM has no
means of specifying the contents of files, so XDTM and PADS solve
complementary problems.  The METS schema~\cite{mets} is similar to XDTM as
it describes metadata for objects in a digital library, including a
hierarchy such objects.

Commercial database products provide support for
parsing data in external formats so the data can be imported into
their database systems, but they typically support a limited number of
formats.  Also, no declarative description of the
original format is exposed to the user for their own use, and they
have fixed methods for coping with erroneous data.  For these reasons,
PADS is complementary to database systems.  We strongly believe that
in the future, commercial database systems could and should support a 
PADS-like description language that allows users to import information from
almost any format.

On the theoretical front, the scientific community's understanding of
type-based languages for data description is much less mature.  To the
best of our knowledge, our previous work on the DDC~\cite{fisher+:next700ddl} 
was the first to provide a
formal interpretation of dependent types as parsers and to study the
properties of these parsers including error correctness and type
safety.  The current paper extends and improves our earlier work 
by simplifying the basic theory in a number of subtle but important ways
and by adding polymorphic types for the purpose of code reuse.
Regular expressions and context-free grammars, the basis for
Lex and Yacc have been well-studied, but they do not have dependency,
a key feature necessary for expressing constraints and parsing ad hoc
scientific data.  {\em Parsing Expression Grammars} (PEGs), studied in
the early seventies~\cite{birman+:parsing}, revitalized more recently
by Ford~\cite{ford:pegs} and implemented using ``packrat parsing''
techniques~\cite{ford:packrat,grimm:packrat}, are somewhat more
similar to PADS recursive descent parsers. However, PADS does not use
packrat parsing techniques as the space overhead is too high for large
data sets.  Moreover, our multiple interpretations of types
in the DDC makes our theory substantially different from the theory of
PEGs.

% {\em PEG difference: not just dependency, but error handling?}


% To our knowledge, we are the first to attempt to specify a semantics for
% data description languages based on types such as \packettypes{},
% \datascript{} or \pads.  
% %Prior to our work, this family of languages 
% %was described informally and by example.  There was no precise
% %connection to formal dependent type theory.

% Of course, there are other formalisms for
% defining parsers, most famously, regular expressions and
% contex-free grammars.  In terms of recognition power,
% these formalisms differ from our type theory
% in that they have nondeterministic choice, but do not have
% dependency or constraints.  We have found that 
% dependency and constraints are absolutely essential for
% describing most of the ad hoc data sources we have studied.
% Perhaps more importantly though, unlike standard theories of
% context-free grammars,
% we do not treat our type theory merely as a recognizer for
% a collection of strings.  Our type-based descriptions 
% define {\em both} external data formats {\em and} 
% rich invariants on %(\ie{} types for)
% the internal parsed data structures.  This dual interpretation
% of types lies at the heart of tools such as \pads, \datascript{} and
% \packettypes{}.  
% %\pads{} programmers, for instance, demand that
% %representations produced by their \pads{} parsers have the expected type and 
% %count on the fact that the associated PD is accurately correlated
% %with the representation.  
% %Existing formalisms simply do not address
% %this elements of data description languages.

% {\em Parsing Expression Grammars} (PEGs),
% studied in the early 70s~\cite{birman+:parsing} and revitalized more 
% recently by Ford~\cite{ford:pegs}, 
% evolved from context-free grammars but
% have deterministic, prioritized choice like \ddc{} as opposed to
% nondeterministic choice.  Though PEGs have syntactic lookahead operators,
% they may be parsed in linear time through the use of
% ``packrat parsing'' techniques~\cite{ford:packrat,grimm:packrat}.
% Once again, the dual interpretation of types in \ddc{} both as
% data descriptions and as classifiers for internal representations
% make our theory substantially different from the theory of PEGs.
% %In practice, PEGs has not been used to parse ad hoc data.

% {\sc antlr}~\cite{antlr}, a popular programming language parsing tool, 
% uses top-down recursive descent
% parsing and appears roughly similar in recognition power to PEGs and \ddc.
% {\sc antlr} also allows programmers to place annotations
% in the grammar definitions to guide construction of an abstract syntax
% tree. However, all nodes in the abstract syntax tree have a 
% single type, hence the guidance is rather crude when compared with
% the richly-typed structures that can be constructed using
% \ddc.


% Practical experience indicates that
% tools based on these formalisms, such as the many variations of
% Lex and Yacc, are highly effective for processing
% programming language syntax.  However, there is also ample evidence
% that these tools are a poor fit for processing
% ad hoc data --- simply put, {\em no one ever uses Lex or Yacc for 
% these tasks}.
% Unfortunately, the nondeterminism and lack of
% dependency in these formalisms limit their suitability to formalizing
% data description languages. While the parsing expression grammars
% (PEG) formalism~\cite{ford:parsing-expression-grammars} is
% significantly closer to the \ddc{}, it too lacks the necessary
% dependency.

% Less related, but still relevant, are Haskell's parsing
% combinators. While these are not a formalism, they do provide an
% elegant manner in which to express parsers. Hence, while we chose to
% define our parsing semantics in the polymorphic lambda calculus,they
% potentialy provide a more elegant alternative.

% % {\em Mention dependent type theory work?}
