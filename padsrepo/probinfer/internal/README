*******************************************************************
NEW: Environment variable LEARN_HOME must be set to point to root of
     inference system.

Description of directory structure

infer	      -- root of the inference system
 GNUmakefile  -- compiles learn by delegating to src/GNUmakefile
 README       -- user level README file
 cpl-1.0-licence.{html,txt}  -- common public licenses under which 
 			        code is released
 examples    -- directory with example files
   data         -- example data files
   gold         -- files related to gold standard
     data          -- data corresponding to gold descriptions
     ir            -- src files for parsing gold data
     p             -- hand-written pads descriptions
   results      -- directory for results of running inference system
    GNUmakefile    -- for running inference on data files
 include     -- input files of various types
   GNUmakefile.output   
                -- template makefile for directories with generated code
   basetoken.p  -- ??
   tokens.config  
                -- description file for tokenizer
   vanilla.config
                -- description fiel for tokenzier
 internal    -- files used strictly internally
   scripts      -- internal scripts
     export-learn.sh  -- file for generating release tar ball
     release          -- directory containing materials related to release
 lib         -- compiler outputs
 scripts     -- scripts used in distribution
   config.pl    -- script that generates .p and .lex files from .config
   learn        -- script that invokes inference system
   grapher.template  
                -- used in generating graphing tool
 

*******************************************************************


This directory contains a prototype system for inferring a description
of newline-separated ASCII data.  

1. Requirements:
   You must have sml/nj 110.64 or later, available from www.smlnj.org.
   You must have PADS 2.00 or later, available from www.padsproj.org.

2. You must set the LEARN_HOME environment variable to the root of the
   PADS Inference System distribution.

3. To compile the learning program, just type "make".
   Note: This will not modify the script "learn". Instead, it
   produces an updated file in the subdirectory "lib". 
   The system assumes all data files are located in data/.

4. The "learn" program takes a data file input and produces an 
   intermediate representation (IR) and also prints out the PADS
   description. For details of the usage of "learn", type:
   
   >learn --help 

   PADS Learning System 1.0
   learn  [-d <string>] [-n <string>] [-maxdepth <int>] [-lineNos] 
   [-ids] [-h <float>] [-s <float>] [-noise <float>] [-a <int>] 
   [-ma <int>] [-j <float>] [-e] [-lex <string>] [-au <string> ...] 
   [--help] files...

   -d      output directory (default gen/)
   -n      name of output file (default generatedDescription)
   -maxdepth       maximum depth for exploration (default 50)
   -lineNos        print line numbers in output contexts (default false)
   -ids    print ids in type and tokens matching base types (default false)
   -h      histogram comparison tolerance (percentage, default 0.01)
   -s      struct determination tolerance (percentage, default 0.1)
   -noise  noise level (percentage, default 0.0)
   -a      array width requirement (default 4)
   -ma     minimum array width (default 0)
   -j      junk threshold (percentage, default 0.1)
   -e      Print entropy tokens (default false)
   -lex    prefix of the lex config to be used (default "vanilla")
   -au     run only the golden file

   For example, 

   >learn data/crashreporter.log

   will generate in the /gen directory a Ty which contains the IR, 
   and crashreporter.log.p which is the PADS description. In addition,
   a number of tools avilable to this data source in the form of .c
   files are generated in the same directory. For data source XYZ,
   XYZ-accum.c is the accumulator tool, XYZ-xml.c is the XML tool, 
   XYZ-fmt.c is the formatting tool, XYZ-graph is the grapher too etc. 
   For example, to build the accumulator tool for crashreporter.log, do:
   
   >cd gen/
   >make crashreporter.log-accum

   To build the xml tool, do:
   >make crashreporter.log-xml

   Executable programs crashreporter.log-accum and crashreporter.log-xml
   will be created in directory gen/ARCH, where ARCH is a string that
   represents the OS and the CPU architecture, such as darwin.ppc and 
   linux.i386.

   To run the accumulator program,
   >cd darwin.ppc
   >crashreporter.log-accum ../../data/crashreporter.log

   The grapher tool is a generated Perl script. To run the
   grapher tool, one has to first make the formatting tool by doing:
   >make crashreporter.log-fmt 

   and then execute
   >crashreporter.log-graph 

   to see detailed usage of the grapher. And example of use is:

   ai.3000-graph -d ../data/ai.3000 -x 3 -y 8 -s impulses -t "%H:%M:%S"

5. The GNUMakefile included in the learning directory has a few
   targets for running end-to-end scenarios and experimenting with 
   training on random data. The GNUMakefile assumes that the following
   "golden" data sources exists in the data/ directory, and the 
   hand-written IRs are in the gold/ directory. Currently the golden
   data sources are:

   1967Transactions.short
   ai.3000
   boot.log
   crashreporter.log
   crashreporter.log.modified
   dibbler.1000
   ls-l.txt
   quarterlypersonalincome
   railroad.txt
   yum.txt
   asl.log
   page_log
   windowserver_last.log
   MER_T01_01.csv
   netstat-an
   scrollkeeper.log

   To make a summary report on any of the golden formats run the target 
   with a ".rep" suffix, eg. 
   >make crashreporter.log.rep

   The report will be saved in ouput/crashreporter.log/Report along with
   some other files in that directory.
 
   To run the learning system on three smaller training sets and report
   the accuracy and timing information:
   >make xxx.train P=p 

   where p is the size of the training set in terms of the percentage 
   of the original data file. This will create 3 random trainining data 
   sets, and learn on these three sets, produce the pads
   descriptions and parses the three descriptions on the original
   data file. Finally it prints the execution time and success rate 
   each of the 3 descriptions and the average values.
*******************************************************************
