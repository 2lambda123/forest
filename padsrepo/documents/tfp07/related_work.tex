\section{Related Work}
\label{sec:related}

There are other formalisms for
defining parsers, most famously, regular expressions and contex-free
grammars.  In terms of recognition power, our type theory contains
dependency and hence easily expresses languages that are not
context-free.  Perhaps more importantly though, unlike
standard theories of context-free grammars, we do not treat our type
theory merely as a recognizer for a collection of strings.  Our
type-based descriptions define external data formats, rich invariants 
on the internal parsed data structures and parser and printer
functions to relate them.  This
multi-part interpretation of types lies at the heart of 
tools such as \pads{}.

As mentioned in the introduction, there are many domain-specific
specification languages that allow users to write down descriptions
of data and generate tools from them~\cite{gpce02,lieberherr+:class-dictionaries,sigcomm00,fisher+:pads,mandelbaum+:padsml,xsugar2005}.  Many of these projects contain great ideas, 
but we would like to highlight just two of them:
\demeter~\cite{lieberherr+:class-dictionaries} and 
\xsugar~\cite{xsugar2005}.  \demeter{} generates a number of different kinds of visitor patterns, including visitors for printing, from high-level 
type-based descriptions called {\em class dictionaries}.  \xsugar{}
is a specialized tool for converting back and forth from ad hoc data
to \xml.  A static analysis guarantees that \xsugar{}'s generated
transforms are inverses of one another, something we have not yet proven
for \ddc{}.  On the other hand, neither \demeter{} nor \xsugar{} supports
dependent types or polymorphism.

% {\em Parsing Expression Grammars} (PEGs), studied in the early
% 70s~\cite{birman+:parsing} and revitalized more recently by
% Ford~\cite{ford:pegs}, evolved from context-free grammars but have
% deterministic, prioritized choice like \ddc{} as opposed to
% nondeterministic choice.  Though PEGs have syntactic lookahead
% operators, they may be parsed in linear time through the use of
% ``packrat parsing'' techniques~\cite{ford:packrat,grimm:packrat}.
% Once again, our multiple interpretations of types in \ddc{} makes our
% theory substantially different from the theory of PEGs.

There is also a clear relation between our work and the parser/printer
combinator libraries developed for many functional programming languages.
One difference between the \ddc{} and, for instance, Haskell
combinator libraries~\cite{hutton+:parser-combinators,wadler99prettier}, is that a single \ddc{} description specifies
multiple programs ({\em i.e.,} a parser and a printer) whereas
a program built from Haskell combinators will generally only specify 
one thing -- either a parser or a printer.  

% There are many parallels between \ddc{} and {\it parser
%   combinators}~\cite{burge:parser-combinators,hutton+:parser-combinators}.
% In particular, \ddc{}'s dependent sum construct is reminiscent of the
% bind operator in the monadic formulation of parser combinators.
% Parser combinators, however, are a general approach to specifying
% recursive descent parsing, whereas we have targeted \ddc{} to the
% more-specific domain of parsing ad hoc data. This focus leads to many
% features not found in parser combinators, including the implicit
% type/value correspondence, the error response mechanism, and arrays.
% Each of these features is as fundamental to \ddc{} as dependent sums.
% These two approaches demonstrate the idea of a spectrum of
% domain-specificity in languages. The relationship between parser
% combinators and \ddc{} is like the relationship between a general
% purpose language and parser combinators themselves. That is, while
% parser combinators form an (embedded) domain-specific language, \ddc{}
% constructs form a language that is even more domain-specific.

The \ddc{} and its semantics are also closely tied to 
{\em type-directed} programming techniques~\cite{harper+:intensional,jansson+:97,weirich+:flexible-type-analysis,jansson:phdthesis,hinze:generic}.  Of particular
interest is the elegant work by Jansson and Jeuring
on polytypic data conversions~\cite{jansson+:99,jansson+:02}.
These authors demonstrate how to program a variety of different
data transformation functions together with their inverses
in PolyP, a type-directed extension of Haskell.  For instance,
they describe a generic compressing printing/parsing algorithm, 
a generic noncompressing (``pretty'') printing/parsing algorithm, and
a ``data extraction'' (merge) algorithm that separates (merges)
primitive data from (into) its containing structure.
The authors prove that each function pair is invertible --
print followed by parse is the identity (though not necessarily
the other way around), which is a substantially stronger 
correctness property than any we have proven in this paper.

What makes our work here and the overall \pads{} project
independently interesting from Jansson and Jeuring's
is our domain-specific focus.  For instance,
whereas Jansson and Jeuring show how to parse and print any 
{\em internal} data structure, \pads{} focuses on parsing and printing any {\em
external} format -- there is a shift in goal.  In addition, \pads{}
provides the capability to generate a number of format-specific
programs specially designed
for ad hoc data processing including an XML translator, query engine,
formatter and statistical analysis.  This domain-specific collection of tools
allows one to use \pads{} to rapidly investigate, query and transform new, 
unanticipated data formats that show up at one's doorstep without
advanced warning. 
It is also important to note that \pads{} is compiled for performance reasons
and this is reflected in our
denotational semantics, which is quite different from
the semantics used by Jansson and Jeuring.

% in 
% a specific external format, \pads{} is
% a domain specific language aimed at describing any one of many
% non-standard, external file formats

% (See, for example, Hinze's work~\cite{hinze:generic}).
% Indeed, the \ddc{} parsers and printers really are just
% specially crafted (dependently) type-directed programs.


% Perhaps one of the most closely related works on generic programming
% is that of van Weelden \textit{et al}~\cite{weelden+:polytypic-ast},
% as it relates to the generated parser and printers, rather than only
% to the generic tool support. The authors investigate the use of
% polytypic programming to produce a parser for a language based only on
% the specification of its AST type(s). In this way, the AST types
% themselves serve as the grammar for the language. They also
% investigate applying this approach to other compiler-related analyses,
% like scope checking and type inference.  However, while their
% ``types-as-grammar'' approach is clearly related to \padsml{}, they
% are using standard functional-programming types, and they
% are targeting the domain of programming languages. Dependent types
% like those of \padsml{} and support for ad hoc data processing are
% beyond the scope of their work.

% Many only specify one. Most closely related is work by J & J, which
% investigates how to specify both from one specification using
% (provably) invertible combinators.

