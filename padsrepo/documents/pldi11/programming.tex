\section{Programming with \forest{}}
\label{sec:exp}

\begin{figure}
Load Functions:
\begin{code}
log_load   :: FilePath -> IO (Log, Log_md),
site_load  :: FilePath -> IO (Site, Site_md)
coral_load :: FilePath -> IO (Top, Top_md),
\end{code}
%\caption{Load functions for Coral}
%\label{fig:coral-load}
%\end{figure}
%
%\begin{figure}
Representation Types:
\begin{code}
\kw{data}    Log   = Log   \{log :: CoralLog\}
\kw{newtype} Site  = Site  [(String, Log)]
\kw{newtype} Coral = Coral [(String, Site)]
\end{code}
%\caption{Representation types for Coral}
%\label{fig:coral-rep}
%\end{figure}
%
%\begin{figure}
Metadata Types:
\begin{code}
\kw{data} Log_inner_md = 
  Log_inner_md \{log_md :: (Forest_md, CoralLog_md)\}
\kw{type} Log_md   = (Forest_md, Log_inner_md)
\kw{type} Site_md  = (Forest_md, [(String, Log_md)])
\kw{type} Coral_md = (Forest_md, [(String, Site_md)])
\end{code}
\caption{Coral load functions, representation and metadata types}
\label{fig:coral-aux}
\end{figure}

Most \forest{} programs work in two phases. In the first phase they
use \forest{} to load relevant portions of the file system into memory,
and in the second phase they use an ordinary Haskell function to
traverse the in-memory representation of the data (or its associated
metadata) and compute the desired result.
\jnf{TODOs
\begin{itemize}
\item Format of coralwebsrv.log.gz is not currently explained anywhere.
\item Must explain the structure of entries for the top-k example.
\end{itemize}}


To facilitate this style of programming, the \forest{} compiler
generates several Haskell functions and types from every \forest{}
description.  It generates a \emph{load function}, which traverses the
file system and reads the files, directories, and symbolic links
mentioned in the description into a structured object in memory; it
generates a Haskell type for the in-memory \emph{representation} of
the data produced by the load function; and it generates a Haskell
type for the \emph{metadata} associated with the representation. For
example, from the descriptions for \coral{} logs in
Figure~\ref{fig:coral-description}, the compiler generates the load
functions, the representation types, and the metadata types presented in
Figure~\ref{fig:coral-aux}. Note that the structure of each of these
artifacts mirrors the structure of the \forest{}
description that generated them. This close correspondence makes it
easy for programmers to write programs using these \forest{}-generated artifacts.

As a simple example, consider the \cd{Coral} description in
Figure~\ref{fig:coral-description}. The \cd{coral\_load} function takes
a path as an argument and produces the representation and metadata
obtained by loading each of the site directories contained in the
directory at that path:
%
\begin{code}
(rep,md) <- coral_load "/var/log/coral1"
\end{code}
Because \cd{Coral} is a comprehension, both \cd{rep} and \cd{md} are
lists. More specifically, \cd{rep} has the form
\begin{code}
Coral [("planetab2.eecs.wsu.edu", Site [...]),
       ("planetlab3.williams.edu",Site [...]),...]
\end{code}
where the list contains pairs of names of subdirectories and
representations for the data loaded from those directories. The
metadata is a pair consisting of a generic header of type
\cd{Forest\_md} and a list of pairs of names of subdirectories and
their associated metadata. The header records aggregate information
about any errors encountered during loading as well as the file system
attributes of each file, directory, or symbolic link loaded from the
file system:
%
\begin{code}
Forest_md 
  \{ numErrors = 0, 
    errorMsg = Nothing, 
    fileInfo = FileInfo
      \{ fullpath = /var/log/coral, 
        owner = alice, group = staff, size = 102, 
        access_time = Fri Nov 19 01:47:09 2010, 
        mod_time = Thu Nov 18 20:42:37 2010, 
        read_time = Fri Nov 19 01:47:28 2010, 
        mode = drwxr-xr-x, isSymLink = False, 
        kind = Directory \} \},
[("planetlab2.eecs.wsu.edu", Forest_md \{...\}),
 ("planetlab3.williams.edu", Forest_md \{...\}), ...]
\end{code}
%
Using these functions and types, it is easy to formulate many useful
queries as simple Haskell programs. For instance, to count the number
of sites we can simply compute the length of the nested list in
\cd{rep}:
%
\begin{code}
num_sites = \kw{case} rep \kw{of} Coral l -> List.length l 
\end{code}
%
More interestingly, since the internals of the web log are specified
using \padshaskell{} (see \ifanon\auxmaterials{}\else the appendix\fi{}
for details), it is straightforward to dig in to the file data and
combine it with file metadata or attributes in queries.  For example,
to calculate the time when statistics were last reported for each
site, we can zip the lists in \cd{rep} and \cd{md} together and
project out the site name and the \cd{mod_time} field from each
element in the resulting list of pairs:
%
\begin{code}
get_site = fst
get_mod (_,(f,_)) = mod_time . fileInfo $ f  
sites_mod () = 
  \kw{case} (rep,md) \kw{of} (Coral rs, (_,ms)) -> 
    map (get_site *** get_mod) (zip rs ms)
\end{code}
% $

These simple examples show how \forest{} blurs the distinction
between data represented on disk and in memory. After writing a
suitable \forest{} description, programmers can write programs that
work on file system data as if it were in memory. Moreover, because
Forest uses lazy I/O operations, many simple programs do not require
constructing an explicit representation of the entire directory being
loaded in memory---a good thing as the directory of \coral{} logs
contains approximately 1GB of data!  Instead, the load functions only
read the portions of the file system that are needed to compute the
result---in this case, only the site directories and not the gzipped
log files contained within them.

As a final example, consider a program that computes the top-$k$
requested URLs from all \coral{} nodes by size. The \coral{}
administrators compute this statistic periodically to help monitor and
tune the performance of the system~\cite{freedman:coral-experience}. 
We define the analogous function in Haskell using helper
functions such as \cd{get_sites} to project out components of
\cd{rep}:
%
\begin{code}
topk k = 
  take k $ sortBy descBytes $ toList $
  fromListWith (+)
    [ (get\_url e, get\_total e)
    | (site,sdir) <- get\_sites rep,
      (datetime,ldir) <- get\_dates sdir,
      e <- get\_entries ldir,
      is\_in e ]
\end{code}
% $
Reading this program inside-out, we see that it first uses a list
comprehension to iterate through \cd{rep}, collecting the
individual log entries in the \cd{coralwebsrv.log.gz} file for
incoming requests and projecting out the URL requested and the total
size of the request. It then sums the sizes of all requests for the
same URL using the \cd{fromListWith} function from the \cd{Data.Map}
module. Next, it sorts the entries in descending order. Finally, it
returns the first $k$ entries of the list as the final result.

Overall, the main take-away from this section is how 
the \forest{}-generated infrastructure and tight coupling
to \haskell{} facilitates construction
of remarkably terse queries over the combination of file contents,
file attributes and directory structure.  Exploratory data analysis
in this new programming paradigm is light-weight, easy and highly effective.
%how the tight coupling of \forest{} and \haskell{} lead to highly
%productive programming practice.  
\jnf{compare with the hand-written Python program Mike
  actually uses? Highlight difficulties of dealing with large number
  of huge files? dpw: it would be great to give some kind of comparison}
